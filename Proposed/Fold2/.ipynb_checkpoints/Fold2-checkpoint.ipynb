{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e7419d50-4127-49a5-b64b-a69626d359b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.models import Sequential\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f5dcba53-cae8-4dec-8222-0f99a5536a09",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Custom Self-Attention Layer\n",
    "class SelfAttention(layers.Layer):\n",
    "    def __init__(self, channels, **kwargs):\n",
    "        super(SelfAttention, self).__init__(**kwargs)\n",
    "        self.channels = channels\n",
    "        self.attention_dense = layers.Dense(channels, activation='sigmoid')\n",
    "\n",
    "    def call(self, inputs):\n",
    "        attention_weights = self.attention_dense(inputs)\n",
    "        return inputs * attention_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d4f59a1f-2773-4b1e-b132-c62dfd2798fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "class F1Score(tf.keras.metrics.Metric):\n",
    "    def __init__(self, name='f1_score', **kwargs):\n",
    "        super(F1Score, self).__init__(name=name, **kwargs)\n",
    "        self.precision = tf.keras.metrics.Precision()\n",
    "        self.recall = tf.keras.metrics.Recall()\n",
    "\n",
    "    def update_state(self, y_true, y_pred, sample_weight=None):\n",
    "        # Update the precision and recall for each batch\n",
    "        self.precision.update_state(y_true, y_pred, sample_weight)\n",
    "        self.recall.update_state(y_true, y_pred, sample_weight)\n",
    "\n",
    "    def result(self):\n",
    "        # Calculate F1 score as the harmonic mean of precision and recall\n",
    "        precision = self.precision.result()\n",
    "        recall = self.recall.result()\n",
    "        return 2 * (precision * recall) / (precision + recall + tf.keras.backend.epsilon())\n",
    "\n",
    "    def reset_states(self):\n",
    "        self.precision.reset_states()\n",
    "        self.recall.reset_states()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fcbdd017-0dbb-4a7a-8c1e-9ef785dda440",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 7126 images belonging to 6 classes.\n"
     ]
    }
   ],
   "source": [
    "# Data preparation (same as in your code)\n",
    "train_datagen = ImageDataGenerator(rescale=1./255)\n",
    "training_set1 = train_datagen.flow_from_directory(\n",
    "    \"Monkeypox/archive (60)/Augmented Images/Augmented Images/FOLDS_AUG/fold2_AUG/Train/\",\n",
    "    target_size=(64, 64),\n",
    "    batch_size=32,\n",
    "    class_mode='categorical',  # Use 'sparse' if your labels are integers (not one-hot encoded)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4ad79a2e-74e8-4345-8c59-8235e60f25b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 7126 images belonging to 6 classes.\n"
     ]
    }
   ],
   "source": [
    "test_datagen = ImageDataGenerator(rescale=1./255)\n",
    "test_set1 = test_datagen.flow_from_directory(\n",
    "    \"Monkeypox/archive (60)/Augmented Images/Augmented Images/FOLDS_AUG/fold2_AUG/Train/\",\n",
    "    target_size=(64, 64),\n",
    "    batch_size=32,\n",
    "    class_mode='categorical',\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c9103e21-a102-4479-985a-ab51dc124c76",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CNN model with Self-Attention and Bidirectional GRU\n",
    "cnn = Sequential()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "eb4e97ca-465d-4719-8d16-67a4fda17e05",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\KIIT\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\layers\\convolutional\\base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\KIIT\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\backend\\tensorflow\\core.py:204: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "cnn.add(layers.Conv2D(filters=32, padding=\"same\", kernel_size=3, activation='relu', strides=2, input_shape=[64, 64, 3]))\n",
    "cnn.add(SelfAttention(channels=32))\n",
    "cnn.add(layers.MaxPool2D(pool_size=2, strides=2))\n",
    "\n",
    "cnn.add(layers.Conv2D(filters=32, padding='same', kernel_size=3, activation='relu'))\n",
    "cnn.add(layers.MaxPool2D(pool_size=2, strides=2))\n",
    "\n",
    "# Ensure the correct reshaping before GRU\n",
    "cnn.add(layers.Reshape((-1, 32)))  # Reshape for GRU (batch_size, time_steps, features)\n",
    "\n",
    "# Bidirectional GRU layer\n",
    "cnn.add(layers.Bidirectional(layers.GRU(64, return_sequences=True)))\n",
    "\n",
    "cnn.add(layers.Flatten())\n",
    "cnn.add(layers.Dense(units=128, activation='relu'))\n",
    "cnn.add(layers.Dense(6, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a3b6a29f-9686-430d-9920-d0ccc3754f5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile the model with Precision, Recall, and custom F1 score\n",
    "cnn.compile(\n",
    "    optimizer='adam', \n",
    "    loss='categorical_crossentropy', \n",
    "    metrics=['accuracy', 'Precision', 'Recall', F1Score()]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "10e6b775-17c3-44c2-9046-1a9cb6d24cc5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                         </span>┃<span style=\"font-weight: bold\"> Output Shape                </span>┃<span style=\"font-weight: bold\">         Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
       "│ conv2d (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)          │             <span style=\"color: #00af00; text-decoration-color: #00af00\">896</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ self_attention (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">SelfAttention</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)          │           <span style=\"color: #00af00; text-decoration-color: #00af00\">1,056</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ max_pooling2d (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)          │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ conv2d_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)          │           <span style=\"color: #00af00; text-decoration-color: #00af00\">9,248</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ max_pooling2d_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)            │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ reshape (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Reshape</span>)                    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)              │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ bidirectional (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Bidirectional</span>)        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)             │          <span style=\"color: #00af00; text-decoration-color: #00af00\">37,632</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ flatten (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)                    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8192</span>)                │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)                 │       <span style=\"color: #00af00; text-decoration-color: #00af00\">1,048,704</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">6</span>)                   │             <span style=\"color: #00af00; text-decoration-color: #00af00\">774</span> │\n",
       "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
       "│ conv2d (\u001b[38;5;33mConv2D\u001b[0m)                      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m)          │             \u001b[38;5;34m896\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ self_attention (\u001b[38;5;33mSelfAttention\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m)          │           \u001b[38;5;34m1,056\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ max_pooling2d (\u001b[38;5;33mMaxPooling2D\u001b[0m)         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m32\u001b[0m)          │               \u001b[38;5;34m0\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ conv2d_1 (\u001b[38;5;33mConv2D\u001b[0m)                    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m32\u001b[0m)          │           \u001b[38;5;34m9,248\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ max_pooling2d_1 (\u001b[38;5;33mMaxPooling2D\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m32\u001b[0m)            │               \u001b[38;5;34m0\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ reshape (\u001b[38;5;33mReshape\u001b[0m)                    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m32\u001b[0m)              │               \u001b[38;5;34m0\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ bidirectional (\u001b[38;5;33mBidirectional\u001b[0m)        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m128\u001b[0m)             │          \u001b[38;5;34m37,632\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ flatten (\u001b[38;5;33mFlatten\u001b[0m)                    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8192\u001b[0m)                │               \u001b[38;5;34m0\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)                      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)                 │       \u001b[38;5;34m1,048,704\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_2 (\u001b[38;5;33mDense\u001b[0m)                      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m6\u001b[0m)                   │             \u001b[38;5;34m774\u001b[0m │\n",
       "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,098,310</span> (4.19 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m1,098,310\u001b[0m (4.19 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,098,310</span> (4.19 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m1,098,310\u001b[0m (4.19 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Model summary\n",
    "cnn.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b0eb2cf7-9125-456c-b8c8-833057a2542a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\KIIT\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\trainers\\data_adapters\\py_dataset_adapter.py:121: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
      "  self._warn_if_super_not_called()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "\u001b[1m223/223\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m92s\u001b[0m 298ms/step - Precision: 0.3649 - Recall: 0.0196 - accuracy: 0.3487 - f1_score: 0.0366 - loss: 1.6487 - val_Precision: 0.6469 - val_Recall: 0.1653 - val_accuracy: 0.4380 - val_f1_score: 0.2633 - val_loss: 1.4133\n",
      "Epoch 2/100\n",
      "\u001b[1m223/223\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 172ms/step - Precision: 0.6405 - Recall: 0.1867 - accuracy: 0.4545 - f1_score: 0.2881 - loss: 1.4088 - val_Precision: 0.6718 - val_Recall: 0.4217 - val_accuracy: 0.5568 - val_f1_score: 0.5181 - val_loss: 1.1491\n",
      "Epoch 3/100\n",
      "\u001b[1m223/223\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m36s\u001b[0m 162ms/step - Precision: 0.7357 - Recall: 0.4254 - accuracy: 0.5935 - f1_score: 0.5390 - loss: 1.0847 - val_Precision: 0.7899 - val_Recall: 0.5090 - val_accuracy: 0.6538 - val_f1_score: 0.6190 - val_loss: 0.9468\n",
      "Epoch 4/100\n",
      "\u001b[1m223/223\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 181ms/step - Precision: 0.8119 - Recall: 0.5746 - accuracy: 0.7021 - f1_score: 0.6727 - loss: 0.8343 - val_Precision: 0.8660 - val_Recall: 0.6603 - val_accuracy: 0.7678 - val_f1_score: 0.7493 - val_loss: 0.6471\n",
      "Epoch 5/100\n",
      "\u001b[1m223/223\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m57s\u001b[0m 258ms/step - Precision: 0.8519 - Recall: 0.6836 - accuracy: 0.7656 - f1_score: 0.7584 - loss: 0.6385 - val_Precision: 0.8562 - val_Recall: 0.7663 - val_accuracy: 0.8097 - val_f1_score: 0.8088 - val_loss: 0.5076\n",
      "Epoch 6/100\n",
      "\u001b[1m223/223\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m49s\u001b[0m 219ms/step - Precision: 0.8968 - Recall: 0.7987 - accuracy: 0.8437 - f1_score: 0.8449 - loss: 0.4382 - val_Precision: 0.9372 - val_Recall: 0.8378 - val_accuracy: 0.8882 - val_f1_score: 0.8847 - val_loss: 0.3480\n",
      "Epoch 7/100\n",
      "\u001b[1m223/223\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m46s\u001b[0m 206ms/step - Precision: 0.9204 - Recall: 0.8431 - accuracy: 0.8833 - f1_score: 0.8800 - loss: 0.3600 - val_Precision: 0.9475 - val_Recall: 0.8988 - val_accuracy: 0.9235 - val_f1_score: 0.9225 - val_loss: 0.2453\n",
      "Epoch 8/100\n",
      "\u001b[1m223/223\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m53s\u001b[0m 239ms/step - Precision: 0.9400 - Recall: 0.8991 - accuracy: 0.9184 - f1_score: 0.9191 - loss: 0.2477 - val_Precision: 0.9519 - val_Recall: 0.9256 - val_accuracy: 0.9388 - val_f1_score: 0.9386 - val_loss: 0.1881\n",
      "Epoch 9/100\n",
      "\u001b[1m223/223\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m52s\u001b[0m 234ms/step - Precision: 0.9480 - Recall: 0.9188 - accuracy: 0.9348 - f1_score: 0.9332 - loss: 0.1957 - val_Precision: 0.9582 - val_Recall: 0.9300 - val_accuracy: 0.9420 - val_f1_score: 0.9439 - val_loss: 0.1740\n",
      "Epoch 10/100\n",
      "\u001b[1m223/223\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m49s\u001b[0m 218ms/step - Precision: 0.9591 - Recall: 0.9427 - accuracy: 0.9522 - f1_score: 0.9508 - loss: 0.1514 - val_Precision: 0.9780 - val_Recall: 0.9627 - val_accuracy: 0.9691 - val_f1_score: 0.9703 - val_loss: 0.1039\n",
      "Epoch 11/100\n",
      "\u001b[1m223/223\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m44s\u001b[0m 197ms/step - Precision: 0.9755 - Recall: 0.9597 - accuracy: 0.9669 - f1_score: 0.9675 - loss: 0.1062 - val_Precision: 0.9673 - val_Recall: 0.9534 - val_accuracy: 0.9608 - val_f1_score: 0.9603 - val_loss: 0.1185\n",
      "Epoch 12/100\n",
      "\u001b[1m223/223\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 177ms/step - Precision: 0.9686 - Recall: 0.9579 - accuracy: 0.9647 - f1_score: 0.9633 - loss: 0.1018 - val_Precision: 0.9827 - val_Recall: 0.9728 - val_accuracy: 0.9782 - val_f1_score: 0.9777 - val_loss: 0.0748\n",
      "Epoch 13/100\n",
      "\u001b[1m223/223\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m49s\u001b[0m 218ms/step - Precision: 0.9748 - Recall: 0.9641 - accuracy: 0.9695 - f1_score: 0.9694 - loss: 0.0946 - val_Precision: 0.9920 - val_Recall: 0.9879 - val_accuracy: 0.9896 - val_f1_score: 0.9899 - val_loss: 0.0390\n",
      "Epoch 14/100\n",
      "\u001b[1m223/223\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m52s\u001b[0m 232ms/step - Precision: 0.9848 - Recall: 0.9803 - accuracy: 0.9827 - f1_score: 0.9825 - loss: 0.0588 - val_Precision: 0.9534 - val_Recall: 0.9426 - val_accuracy: 0.9481 - val_f1_score: 0.9480 - val_loss: 0.1503\n",
      "Epoch 15/100\n",
      "\u001b[1m223/223\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m58s\u001b[0m 261ms/step - Precision: 0.9688 - Recall: 0.9609 - accuracy: 0.9648 - f1_score: 0.9648 - loss: 0.0955 - val_Precision: 0.9817 - val_Recall: 0.9788 - val_accuracy: 0.9801 - val_f1_score: 0.9803 - val_loss: 0.0563\n",
      "Epoch 16/100\n",
      "\u001b[1m223/223\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m114s\u001b[0m 509ms/step - Precision: 0.9841 - Recall: 0.9798 - accuracy: 0.9825 - f1_score: 0.9820 - loss: 0.0502 - val_Precision: 0.9918 - val_Recall: 0.9902 - val_accuracy: 0.9906 - val_f1_score: 0.9910 - val_loss: 0.0318\n",
      "Epoch 17/100\n",
      "\u001b[1m223/223\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m93s\u001b[0m 418ms/step - Precision: 0.9851 - Recall: 0.9822 - accuracy: 0.9837 - f1_score: 0.9836 - loss: 0.0521 - val_Precision: 0.9829 - val_Recall: 0.9770 - val_accuracy: 0.9799 - val_f1_score: 0.9799 - val_loss: 0.0638\n",
      "Epoch 18/100\n",
      "\u001b[1m223/223\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m135s\u001b[0m 607ms/step - Precision: 0.9782 - Recall: 0.9705 - accuracy: 0.9739 - f1_score: 0.9744 - loss: 0.0780 - val_Precision: 0.9892 - val_Recall: 0.9865 - val_accuracy: 0.9872 - val_f1_score: 0.9878 - val_loss: 0.0444\n",
      "Epoch 19/100\n",
      "\u001b[1m223/223\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m135s\u001b[0m 602ms/step - Precision: 0.9867 - Recall: 0.9842 - accuracy: 0.9845 - f1_score: 0.9854 - loss: 0.0417 - val_Precision: 0.9954 - val_Recall: 0.9938 - val_accuracy: 0.9947 - val_f1_score: 0.9946 - val_loss: 0.0192\n",
      "Epoch 20/100\n",
      "\u001b[1m223/223\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m124s\u001b[0m 557ms/step - Precision: 0.9923 - Recall: 0.9913 - accuracy: 0.9920 - f1_score: 0.9918 - loss: 0.0247 - val_Precision: 0.9892 - val_Recall: 0.9869 - val_accuracy: 0.9884 - val_f1_score: 0.9881 - val_loss: 0.0412\n",
      "Epoch 21/100\n",
      "\u001b[1m223/223\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m128s\u001b[0m 576ms/step - Precision: 0.9899 - Recall: 0.9869 - accuracy: 0.9877 - f1_score: 0.9884 - loss: 0.0452 - val_Precision: 0.9934 - val_Recall: 0.9924 - val_accuracy: 0.9927 - val_f1_score: 0.9929 - val_loss: 0.0246\n",
      "Epoch 22/100\n",
      "\u001b[1m223/223\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m124s\u001b[0m 556ms/step - Precision: 0.9915 - Recall: 0.9900 - accuracy: 0.9907 - f1_score: 0.9907 - loss: 0.0314 - val_Precision: 0.9889 - val_Recall: 0.9871 - val_accuracy: 0.9882 - val_f1_score: 0.9880 - val_loss: 0.0361\n",
      "Epoch 23/100\n",
      "\u001b[1m223/223\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m118s\u001b[0m 528ms/step - Precision: 0.9878 - Recall: 0.9867 - accuracy: 0.9870 - f1_score: 0.9872 - loss: 0.0367 - val_Precision: 0.9907 - val_Recall: 0.9886 - val_accuracy: 0.9898 - val_f1_score: 0.9897 - val_loss: 0.0330\n",
      "Epoch 24/100\n",
      "\u001b[1m223/223\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m121s\u001b[0m 542ms/step - Precision: 0.9898 - Recall: 0.9884 - accuracy: 0.9887 - f1_score: 0.9891 - loss: 0.0339 - val_Precision: 0.9892 - val_Recall: 0.9878 - val_accuracy: 0.9884 - val_f1_score: 0.9885 - val_loss: 0.0372\n",
      "Epoch 25/100\n",
      "\u001b[1m223/223\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m112s\u001b[0m 501ms/step - Precision: 0.9913 - Recall: 0.9899 - accuracy: 0.9909 - f1_score: 0.9906 - loss: 0.0268 - val_Precision: 0.9827 - val_Recall: 0.9808 - val_accuracy: 0.9819 - val_f1_score: 0.9817 - val_loss: 0.0493\n",
      "Epoch 26/100\n",
      "\u001b[1m223/223\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m116s\u001b[0m 518ms/step - Precision: 0.9896 - Recall: 0.9881 - accuracy: 0.9885 - f1_score: 0.9889 - loss: 0.0323 - val_Precision: 0.9941 - val_Recall: 0.9927 - val_accuracy: 0.9931 - val_f1_score: 0.9934 - val_loss: 0.0199\n",
      "Epoch 27/100\n",
      "\u001b[1m223/223\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m48s\u001b[0m 213ms/step - Precision: 0.9874 - Recall: 0.9851 - accuracy: 0.9859 - f1_score: 0.9863 - loss: 0.0430 - val_Precision: 0.9892 - val_Recall: 0.9889 - val_accuracy: 0.9891 - val_f1_score: 0.9891 - val_loss: 0.0414\n",
      "Epoch 28/100\n",
      "\u001b[1m223/223\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m56s\u001b[0m 250ms/step - Precision: 0.9892 - Recall: 0.9871 - accuracy: 0.9880 - f1_score: 0.9881 - loss: 0.0410 - val_Precision: 0.9928 - val_Recall: 0.9916 - val_accuracy: 0.9921 - val_f1_score: 0.9922 - val_loss: 0.0246\n",
      "Epoch 29/100\n",
      "\u001b[1m223/223\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m52s\u001b[0m 233ms/step - Precision: 0.9788 - Recall: 0.9774 - accuracy: 0.9777 - f1_score: 0.9781 - loss: 0.0671 - val_Precision: 0.9933 - val_Recall: 0.9924 - val_accuracy: 0.9927 - val_f1_score: 0.9928 - val_loss: 0.0208\n",
      "Epoch 30/100\n",
      "\u001b[1m223/223\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m56s\u001b[0m 252ms/step - Precision: 0.9946 - Recall: 0.9934 - accuracy: 0.9946 - f1_score: 0.9940 - loss: 0.0183 - val_Precision: 0.9874 - val_Recall: 0.9858 - val_accuracy: 0.9865 - val_f1_score: 0.9866 - val_loss: 0.0385\n",
      "Epoch 31/100\n",
      "\u001b[1m223/223\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m59s\u001b[0m 265ms/step - Precision: 0.9918 - Recall: 0.9917 - accuracy: 0.9918 - f1_score: 0.9918 - loss: 0.0245 - val_Precision: 0.9961 - val_Recall: 0.9958 - val_accuracy: 0.9958 - val_f1_score: 0.9959 - val_loss: 0.0100\n",
      "Epoch 32/100\n",
      "\u001b[1m223/223\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m65s\u001b[0m 293ms/step - Precision: 0.9892 - Recall: 0.9888 - accuracy: 0.9888 - f1_score: 0.9890 - loss: 0.0393 - val_Precision: 0.9909 - val_Recall: 0.9893 - val_accuracy: 0.9896 - val_f1_score: 0.9901 - val_loss: 0.0339\n",
      "Epoch 33/100\n",
      "\u001b[1m223/223\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m63s\u001b[0m 283ms/step - Precision: 0.9924 - Recall: 0.9905 - accuracy: 0.9909 - f1_score: 0.9915 - loss: 0.0248 - val_Precision: 0.9987 - val_Recall: 0.9985 - val_accuracy: 0.9986 - val_f1_score: 0.9986 - val_loss: 0.0052\n",
      "Epoch 34/100\n",
      "\u001b[1m223/223\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m71s\u001b[0m 316ms/step - Precision: 0.9992 - Recall: 0.9988 - accuracy: 0.9988 - f1_score: 0.9990 - loss: 0.0032 - val_Precision: 0.9986 - val_Recall: 0.9986 - val_accuracy: 0.9986 - val_f1_score: 0.9986 - val_loss: 0.0059\n",
      "Epoch 35/100\n",
      "\u001b[1m223/223\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m67s\u001b[0m 302ms/step - Precision: 0.9939 - Recall: 0.9936 - accuracy: 0.9937 - f1_score: 0.9938 - loss: 0.0220 - val_Precision: 0.9859 - val_Recall: 0.9834 - val_accuracy: 0.9846 - val_f1_score: 0.9847 - val_loss: 0.0425\n",
      "Epoch 36/100\n",
      "\u001b[1m223/223\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m73s\u001b[0m 326ms/step - Precision: 0.9835 - Recall: 0.9822 - accuracy: 0.9825 - f1_score: 0.9829 - loss: 0.0550 - val_Precision: 0.9851 - val_Recall: 0.9841 - val_accuracy: 0.9843 - val_f1_score: 0.9846 - val_loss: 0.0465\n",
      "Epoch 37/100\n",
      "\u001b[1m223/223\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m66s\u001b[0m 296ms/step - Precision: 0.9844 - Recall: 0.9829 - accuracy: 0.9834 - f1_score: 0.9836 - loss: 0.0547 - val_Precision: 0.9928 - val_Recall: 0.9924 - val_accuracy: 0.9928 - val_f1_score: 0.9926 - val_loss: 0.0236\n",
      "Epoch 38/100\n",
      "\u001b[1m223/223\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m70s\u001b[0m 314ms/step - Precision: 0.9971 - Recall: 0.9971 - accuracy: 0.9971 - f1_score: 0.9971 - loss: 0.0102 - val_Precision: 0.9990 - val_Recall: 0.9989 - val_accuracy: 0.9989 - val_f1_score: 0.9989 - val_loss: 0.0039\n",
      "Epoch 39/100\n",
      "\u001b[1m223/223\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m69s\u001b[0m 310ms/step - Precision: 0.9988 - Recall: 0.9983 - accuracy: 0.9983 - f1_score: 0.9986 - loss: 0.0040 - val_Precision: 0.9996 - val_Recall: 0.9994 - val_accuracy: 0.9996 - val_f1_score: 0.9995 - val_loss: 0.0018\n",
      "Epoch 40/100\n",
      "\u001b[1m223/223\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m81s\u001b[0m 305ms/step - Precision: 0.9944 - Recall: 0.9939 - accuracy: 0.9942 - f1_score: 0.9941 - loss: 0.0161 - val_Precision: 0.9958 - val_Recall: 0.9954 - val_accuracy: 0.9958 - val_f1_score: 0.9956 - val_loss: 0.0136\n",
      "Epoch 41/100\n",
      "\u001b[1m223/223\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m71s\u001b[0m 319ms/step - Precision: 0.9997 - Recall: 0.9997 - accuracy: 0.9997 - f1_score: 0.9997 - loss: 0.0025 - val_Precision: 0.9907 - val_Recall: 0.9898 - val_accuracy: 0.9898 - val_f1_score: 0.9902 - val_loss: 0.0279\n",
      "Epoch 42/100\n",
      "\u001b[1m223/223\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m69s\u001b[0m 312ms/step - Precision: 0.9884 - Recall: 0.9875 - accuracy: 0.9879 - f1_score: 0.9880 - loss: 0.0412 - val_Precision: 0.9769 - val_Recall: 0.9743 - val_accuracy: 0.9756 - val_f1_score: 0.9756 - val_loss: 0.0682\n",
      "Epoch 43/100\n",
      "\u001b[1m223/223\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m67s\u001b[0m 298ms/step - Precision: 0.9789 - Recall: 0.9770 - accuracy: 0.9780 - f1_score: 0.9779 - loss: 0.0681 - val_Precision: 0.9937 - val_Recall: 0.9926 - val_accuracy: 0.9933 - val_f1_score: 0.9931 - val_loss: 0.0221\n",
      "Epoch 44/100\n",
      "\u001b[1m223/223\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m89s\u001b[0m 331ms/step - Precision: 0.9927 - Recall: 0.9922 - accuracy: 0.9923 - f1_score: 0.9925 - loss: 0.0227 - val_Precision: 0.9989 - val_Recall: 0.9987 - val_accuracy: 0.9989 - val_f1_score: 0.9988 - val_loss: 0.0042\n",
      "Epoch 45/100\n",
      "\u001b[1m223/223\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m79s\u001b[0m 319ms/step - Precision: 0.9981 - Recall: 0.9980 - accuracy: 0.9980 - f1_score: 0.9981 - loss: 0.0067 - val_Precision: 0.9976 - val_Recall: 0.9971 - val_accuracy: 0.9975 - val_f1_score: 0.9973 - val_loss: 0.0075\n",
      "Epoch 46/100\n",
      "\u001b[1m223/223\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m61s\u001b[0m 272ms/step - Precision: 0.9969 - Recall: 0.9969 - accuracy: 0.9969 - f1_score: 0.9969 - loss: 0.0089 - val_Precision: 0.9944 - val_Recall: 0.9940 - val_accuracy: 0.9942 - val_f1_score: 0.9942 - val_loss: 0.0182\n",
      "Epoch 47/100\n",
      "\u001b[1m223/223\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m68s\u001b[0m 303ms/step - Precision: 0.9906 - Recall: 0.9900 - accuracy: 0.9902 - f1_score: 0.9903 - loss: 0.0336 - val_Precision: 0.9905 - val_Recall: 0.9899 - val_accuracy: 0.9902 - val_f1_score: 0.9902 - val_loss: 0.0300\n",
      "Epoch 48/100\n",
      "\u001b[1m223/223\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m74s\u001b[0m 334ms/step - Precision: 0.9925 - Recall: 0.9924 - accuracy: 0.9925 - f1_score: 0.9924 - loss: 0.0228 - val_Precision: 0.9973 - val_Recall: 0.9971 - val_accuracy: 0.9973 - val_f1_score: 0.9972 - val_loss: 0.0108\n",
      "Epoch 49/100\n",
      "\u001b[1m223/223\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m120s\u001b[0m 539ms/step - Precision: 0.9955 - Recall: 0.9953 - accuracy: 0.9953 - f1_score: 0.9954 - loss: 0.0130 - val_Precision: 0.9969 - val_Recall: 0.9968 - val_accuracy: 0.9968 - val_f1_score: 0.9968 - val_loss: 0.0086\n",
      "Epoch 50/100\n",
      "\u001b[1m223/223\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m131s\u001b[0m 586ms/step - Precision: 0.9976 - Recall: 0.9975 - accuracy: 0.9975 - f1_score: 0.9975 - loss: 0.0077 - val_Precision: 0.9999 - val_Recall: 0.9999 - val_accuracy: 0.9999 - val_f1_score: 0.9999 - val_loss: 0.0011\n",
      "Epoch 51/100\n",
      "\u001b[1m223/223\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m128s\u001b[0m 574ms/step - Precision: 1.0000 - Recall: 1.0000 - accuracy: 1.0000 - f1_score: 1.0000 - loss: 4.8401e-04 - val_Precision: 0.9999 - val_Recall: 0.9997 - val_accuracy: 0.9997 - val_f1_score: 0.9998 - val_loss: 8.0372e-04\n",
      "Epoch 52/100\n",
      "\u001b[1m223/223\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m124s\u001b[0m 557ms/step - Precision: 0.9998 - Recall: 0.9998 - accuracy: 0.9998 - f1_score: 0.9998 - loss: 6.1388e-04 - val_Precision: 0.9999 - val_Recall: 0.9999 - val_accuracy: 0.9999 - val_f1_score: 0.9999 - val_loss: 3.1843e-04\n",
      "Epoch 53/100\n",
      "\u001b[1m223/223\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m120s\u001b[0m 535ms/step - Precision: 1.0000 - Recall: 1.0000 - accuracy: 1.0000 - f1_score: 1.0000 - loss: 1.2601e-04 - val_Precision: 0.9997 - val_Recall: 0.9996 - val_accuracy: 0.9996 - val_f1_score: 0.9996 - val_loss: 0.0012\n",
      "Epoch 54/100\n",
      "\u001b[1m223/223\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m141s\u001b[0m 633ms/step - Precision: 0.9798 - Recall: 0.9787 - accuracy: 0.9792 - f1_score: 0.9792 - loss: 0.0734 - val_Precision: 0.9762 - val_Recall: 0.9747 - val_accuracy: 0.9750 - val_f1_score: 0.9755 - val_loss: 0.0916\n",
      "Epoch 55/100\n",
      "\u001b[1m223/223\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m127s\u001b[0m 568ms/step - Precision: 0.9770 - Recall: 0.9744 - accuracy: 0.9752 - f1_score: 0.9757 - loss: 0.0871 - val_Precision: 0.9959 - val_Recall: 0.9958 - val_accuracy: 0.9958 - val_f1_score: 0.9959 - val_loss: 0.0226\n",
      "Epoch 56/100\n",
      "\u001b[1m223/223\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m125s\u001b[0m 561ms/step - Precision: 0.9935 - Recall: 0.9932 - accuracy: 0.9932 - f1_score: 0.9934 - loss: 0.0294 - val_Precision: 0.9935 - val_Recall: 0.9930 - val_accuracy: 0.9934 - val_f1_score: 0.9933 - val_loss: 0.0183\n",
      "Epoch 57/100\n",
      "\u001b[1m223/223\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m132s\u001b[0m 590ms/step - Precision: 0.9962 - Recall: 0.9961 - accuracy: 0.9961 - f1_score: 0.9962 - loss: 0.0115 - val_Precision: 0.9989 - val_Recall: 0.9989 - val_accuracy: 0.9989 - val_f1_score: 0.9989 - val_loss: 0.0030\n",
      "Epoch 58/100\n",
      "\u001b[1m223/223\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m109s\u001b[0m 439ms/step - Precision: 0.9996 - Recall: 0.9996 - accuracy: 0.9996 - f1_score: 0.9996 - loss: 0.0018 - val_Precision: 1.0000 - val_Recall: 1.0000 - val_accuracy: 1.0000 - val_f1_score: 1.0000 - val_loss: 4.0368e-04\n",
      "Epoch 59/100\n",
      "\u001b[1m223/223\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m136s\u001b[0m 611ms/step - Precision: 1.0000 - Recall: 1.0000 - accuracy: 1.0000 - f1_score: 1.0000 - loss: 4.2706e-04 - val_Precision: 1.0000 - val_Recall: 1.0000 - val_accuracy: 1.0000 - val_f1_score: 1.0000 - val_loss: 1.2269e-04\n",
      "Epoch 60/100\n",
      "\u001b[1m223/223\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m131s\u001b[0m 589ms/step - Precision: 1.0000 - Recall: 1.0000 - accuracy: 1.0000 - f1_score: 1.0000 - loss: 9.6601e-05 - val_Precision: 1.0000 - val_Recall: 1.0000 - val_accuracy: 1.0000 - val_f1_score: 1.0000 - val_loss: 8.0798e-05\n",
      "Epoch 61/100\n",
      "\u001b[1m223/223\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m140s\u001b[0m 630ms/step - Precision: 1.0000 - Recall: 1.0000 - accuracy: 1.0000 - f1_score: 1.0000 - loss: 8.2202e-05 - val_Precision: 1.0000 - val_Recall: 1.0000 - val_accuracy: 1.0000 - val_f1_score: 1.0000 - val_loss: 6.3347e-05\n",
      "Epoch 62/100\n",
      "\u001b[1m223/223\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m133s\u001b[0m 596ms/step - Precision: 1.0000 - Recall: 1.0000 - accuracy: 1.0000 - f1_score: 1.0000 - loss: 6.9312e-05 - val_Precision: 1.0000 - val_Recall: 1.0000 - val_accuracy: 1.0000 - val_f1_score: 1.0000 - val_loss: 5.4758e-05\n",
      "Epoch 63/100\n",
      "\u001b[1m223/223\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m123s\u001b[0m 553ms/step - Precision: 1.0000 - Recall: 1.0000 - accuracy: 1.0000 - f1_score: 1.0000 - loss: 5.3422e-05 - val_Precision: 1.0000 - val_Recall: 1.0000 - val_accuracy: 1.0000 - val_f1_score: 1.0000 - val_loss: 4.7423e-05\n",
      "Epoch 64/100\n",
      "\u001b[1m223/223\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m102s\u001b[0m 455ms/step - Precision: 1.0000 - Recall: 1.0000 - accuracy: 1.0000 - f1_score: 1.0000 - loss: 4.4661e-05 - val_Precision: 1.0000 - val_Recall: 1.0000 - val_accuracy: 1.0000 - val_f1_score: 1.0000 - val_loss: 4.0915e-05\n",
      "Epoch 65/100\n",
      "\u001b[1m223/223\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m157s\u001b[0m 703ms/step - Precision: 1.0000 - Recall: 1.0000 - accuracy: 1.0000 - f1_score: 1.0000 - loss: 4.6703e-05 - val_Precision: 1.0000 - val_Recall: 1.0000 - val_accuracy: 1.0000 - val_f1_score: 1.0000 - val_loss: 3.6639e-05\n",
      "Epoch 66/100\n",
      "\u001b[1m223/223\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m142s\u001b[0m 637ms/step - Precision: 1.0000 - Recall: 1.0000 - accuracy: 1.0000 - f1_score: 1.0000 - loss: 2.4844e-05 - val_Precision: 1.0000 - val_Recall: 1.0000 - val_accuracy: 1.0000 - val_f1_score: 1.0000 - val_loss: 2.3975e-05\n",
      "Epoch 70/100\n",
      "\u001b[1m223/223\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m114s\u001b[0m 510ms/step - Precision: 1.0000 - Recall: 1.0000 - accuracy: 1.0000 - f1_score: 1.0000 - loss: 2.0282e-05 - val_Precision: 1.0000 - val_Recall: 1.0000 - val_accuracy: 1.0000 - val_f1_score: 1.0000 - val_loss: 1.6240e-05\n",
      "Epoch 74/100\n",
      "\u001b[1m223/223\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m124s\u001b[0m 555ms/step - Precision: 1.0000 - Recall: 1.0000 - accuracy: 1.0000 - f1_score: 1.0000 - loss: 1.5846e-05 - val_Precision: 1.0000 - val_Recall: 1.0000 - val_accuracy: 1.0000 - val_f1_score: 1.0000 - val_loss: 1.5275e-05\n",
      "Epoch 75/100\n",
      "\u001b[1m223/223\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m129s\u001b[0m 578ms/step - Precision: 1.0000 - Recall: 1.0000 - accuracy: 1.0000 - f1_score: 1.0000 - loss: 1.7886e-05 - val_Precision: 1.0000 - val_Recall: 1.0000 - val_accuracy: 1.0000 - val_f1_score: 1.0000 - val_loss: 1.8032e-05\n",
      "Epoch 76/100\n",
      "\u001b[1m223/223\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m130s\u001b[0m 584ms/step - Precision: 1.0000 - Recall: 1.0000 - accuracy: 1.0000 - f1_score: 1.0000 - loss: 2.1733e-05 - val_Precision: 1.0000 - val_Recall: 1.0000 - val_accuracy: 1.0000 - val_f1_score: 1.0000 - val_loss: 1.5946e-05\n",
      "Epoch 77/100\n",
      "\u001b[1m223/223\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m136s\u001b[0m 613ms/step - Precision: 1.0000 - Recall: 1.0000 - accuracy: 1.0000 - f1_score: 1.0000 - loss: 1.2778e-05 - val_Precision: 1.0000 - val_Recall: 1.0000 - val_accuracy: 1.0000 - val_f1_score: 1.0000 - val_loss: 1.1856e-05\n",
      "Epoch 78/100\n",
      "\u001b[1m223/223\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m123s\u001b[0m 554ms/step - Precision: 1.0000 - Recall: 1.0000 - accuracy: 1.0000 - f1_score: 1.0000 - loss: 1.1093e-05 - val_Precision: 1.0000 - val_Recall: 1.0000 - val_accuracy: 1.0000 - val_f1_score: 1.0000 - val_loss: 1.0507e-05\n",
      "Epoch 79/100\n",
      "\u001b[1m223/223\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m118s\u001b[0m 531ms/step - Precision: 1.0000 - Recall: 1.0000 - accuracy: 1.0000 - f1_score: 1.0000 - loss: 1.0853e-05 - val_Precision: 1.0000 - val_Recall: 1.0000 - val_accuracy: 1.0000 - val_f1_score: 1.0000 - val_loss: 8.9469e-06\n",
      "Epoch 80/100\n",
      "\u001b[1m223/223\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m120s\u001b[0m 537ms/step - Precision: 1.0000 - Recall: 1.0000 - accuracy: 1.0000 - f1_score: 1.0000 - loss: 8.2996e-06 - val_Precision: 1.0000 - val_Recall: 1.0000 - val_accuracy: 1.0000 - val_f1_score: 1.0000 - val_loss: 8.2398e-06\n",
      "Epoch 81/100\n",
      "\u001b[1m223/223\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m130s\u001b[0m 582ms/step - Precision: 1.0000 - Recall: 1.0000 - accuracy: 1.0000 - f1_score: 1.0000 - loss: 8.1362e-06 - val_Precision: 1.0000 - val_Recall: 1.0000 - val_accuracy: 1.0000 - val_f1_score: 1.0000 - val_loss: 7.7703e-06\n",
      "Epoch 82/100\n",
      "\u001b[1m223/223\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m131s\u001b[0m 588ms/step - Precision: 1.0000 - Recall: 1.0000 - accuracy: 1.0000 - f1_score: 1.0000 - loss: 1.2765e-05 - val_Precision: 1.0000 - val_Recall: 1.0000 - val_accuracy: 1.0000 - val_f1_score: 1.0000 - val_loss: 6.7290e-06\n",
      "Epoch 83/100\n",
      "\u001b[1m223/223\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m120s\u001b[0m 537ms/step - Precision: 1.0000 - Recall: 1.0000 - accuracy: 1.0000 - f1_score: 1.0000 - loss: 6.1468e-06 - val_Precision: 1.0000 - val_Recall: 1.0000 - val_accuracy: 1.0000 - val_f1_score: 1.0000 - val_loss: 6.2195e-06\n",
      "Epoch 84/100\n",
      "\u001b[1m223/223\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m125s\u001b[0m 559ms/step - Precision: 1.0000 - Recall: 1.0000 - accuracy: 1.0000 - f1_score: 1.0000 - loss: 5.6562e-06 - val_Precision: 1.0000 - val_Recall: 1.0000 - val_accuracy: 1.0000 - val_f1_score: 1.0000 - val_loss: 5.7921e-06\n",
      "Epoch 85/100\n",
      "\u001b[1m223/223\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m98s\u001b[0m 436ms/step - Precision: 1.0000 - Recall: 1.0000 - accuracy: 1.0000 - f1_score: 1.0000 - loss: 6.2642e-06 - val_Precision: 1.0000 - val_Recall: 1.0000 - val_accuracy: 1.0000 - val_f1_score: 1.0000 - val_loss: 5.1252e-06\n",
      "Epoch 86/100\n",
      "\u001b[1m223/223\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m62s\u001b[0m 278ms/step - Precision: 1.0000 - Recall: 1.0000 - accuracy: 1.0000 - f1_score: 1.0000 - loss: 5.8080e-06 - val_Precision: 1.0000 - val_Recall: 1.0000 - val_accuracy: 1.0000 - val_f1_score: 1.0000 - val_loss: 4.7786e-06\n",
      "Epoch 87/100\n",
      "\u001b[1m223/223\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m67s\u001b[0m 301ms/step - Precision: 1.0000 - Recall: 1.0000 - accuracy: 1.0000 - f1_score: 1.0000 - loss: 8.6152e-06 - val_Precision: 1.0000 - val_Recall: 1.0000 - val_accuracy: 1.0000 - val_f1_score: 1.0000 - val_loss: 4.1086e-06\n",
      "Epoch 88/100\n",
      "\u001b[1m223/223\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m67s\u001b[0m 299ms/step - Precision: 1.0000 - Recall: 1.0000 - accuracy: 1.0000 - f1_score: 1.0000 - loss: 4.3083e-06 - val_Precision: 1.0000 - val_Recall: 1.0000 - val_accuracy: 1.0000 - val_f1_score: 1.0000 - val_loss: 3.9577e-06\n",
      "Epoch 89/100\n",
      "\u001b[1m223/223\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m78s\u001b[0m 350ms/step - Precision: 1.0000 - Recall: 1.0000 - accuracy: 1.0000 - f1_score: 1.0000 - loss: 4.4816e-06 - val_Precision: 1.0000 - val_Recall: 1.0000 - val_accuracy: 1.0000 - val_f1_score: 1.0000 - val_loss: 3.4996e-06\n",
      "Epoch 90/100\n",
      "\u001b[1m223/223\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m77s\u001b[0m 347ms/step - Precision: 1.0000 - Recall: 1.0000 - accuracy: 1.0000 - f1_score: 1.0000 - loss: 3.7826e-06 - val_Precision: 1.0000 - val_Recall: 1.0000 - val_accuracy: 1.0000 - val_f1_score: 1.0000 - val_loss: 3.1961e-06\n",
      "Epoch 91/100\n",
      "\u001b[1m223/223\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m125s\u001b[0m 558ms/step - Precision: 1.0000 - Recall: 1.0000 - accuracy: 1.0000 - f1_score: 1.0000 - loss: 2.8173e-06 - val_Precision: 1.0000 - val_Recall: 1.0000 - val_accuracy: 1.0000 - val_f1_score: 1.0000 - val_loss: 3.3321e-06\n",
      "Epoch 92/100\n",
      "\u001b[1m223/223\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m132s\u001b[0m 591ms/step - Precision: 1.0000 - Recall: 1.0000 - accuracy: 1.0000 - f1_score: 1.0000 - loss: 3.1652e-06 - val_Precision: 1.0000 - val_Recall: 1.0000 - val_accuracy: 1.0000 - val_f1_score: 1.0000 - val_loss: 2.3962e-06\n",
      "Epoch 93/100\n",
      "\u001b[1m223/223\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m136s\u001b[0m 610ms/step - Precision: 1.0000 - Recall: 1.0000 - accuracy: 1.0000 - f1_score: 1.0000 - loss: 2.7840e-06 - val_Precision: 1.0000 - val_Recall: 1.0000 - val_accuracy: 1.0000 - val_f1_score: 1.0000 - val_loss: 2.2387e-06\n",
      "Epoch 94/100\n",
      "\u001b[1m223/223\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m136s\u001b[0m 611ms/step - Precision: 1.0000 - Recall: 1.0000 - accuracy: 1.0000 - f1_score: 1.0000 - loss: 2.3889e-06 - val_Precision: 1.0000 - val_Recall: 1.0000 - val_accuracy: 1.0000 - val_f1_score: 1.0000 - val_loss: 2.0180e-06\n",
      "Epoch 95/100\n",
      "\u001b[1m223/223\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m131s\u001b[0m 590ms/step - Precision: 1.0000 - Recall: 1.0000 - accuracy: 1.0000 - f1_score: 1.0000 - loss: 2.0092e-06 - val_Precision: 1.0000 - val_Recall: 1.0000 - val_accuracy: 1.0000 - val_f1_score: 1.0000 - val_loss: 1.9387e-06\n",
      "Epoch 96/100\n",
      "\u001b[1m223/223\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m131s\u001b[0m 590ms/step - Precision: 1.0000 - Recall: 1.0000 - accuracy: 1.0000 - f1_score: 1.0000 - loss: 1.9201e-06 - val_Precision: 1.0000 - val_Recall: 1.0000 - val_accuracy: 1.0000 - val_f1_score: 1.0000 - val_loss: 1.7653e-06\n",
      "Epoch 97/100\n",
      "\u001b[1m223/223\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m140s\u001b[0m 630ms/step - Precision: 1.0000 - Recall: 1.0000 - accuracy: 1.0000 - f1_score: 1.0000 - loss: 1.9064e-06 - val_Precision: 1.0000 - val_Recall: 1.0000 - val_accuracy: 1.0000 - val_f1_score: 1.0000 - val_loss: 1.4469e-06\n",
      "Epoch 98/100\n",
      "\u001b[1m223/223\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m143s\u001b[0m 643ms/step - Precision: 1.0000 - Recall: 1.0000 - accuracy: 1.0000 - f1_score: 1.0000 - loss: 1.4444e-06 - val_Precision: 1.0000 - val_Recall: 1.0000 - val_accuracy: 1.0000 - val_f1_score: 1.0000 - val_loss: 1.5790e-06\n",
      "Epoch 99/100\n",
      "\u001b[1m223/223\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m205s\u001b[0m 655ms/step - Precision: 1.0000 - Recall: 1.0000 - accuracy: 1.0000 - f1_score: 1.0000 - loss: 1.3785e-06 - val_Precision: 1.0000 - val_Recall: 1.0000 - val_accuracy: 1.0000 - val_f1_score: 1.0000 - val_loss: 4.1839e-05\n",
      "Epoch 100/100\n",
      "\u001b[1m223/223\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m142s\u001b[0m 636ms/step - Precision: 0.9821 - Recall: 0.9808 - accuracy: 0.9811 - f1_score: 0.9814 - loss: 0.1080 - val_Precision: 0.9259 - val_Recall: 0.9151 - val_accuracy: 0.9206 - val_f1_score: 0.9205 - val_loss: 0.2861\n"
     ]
    }
   ],
   "source": [
    "# Train the model and capture the history\n",
    "history = cnn.fit(\n",
    "    training_set1,\n",
    "    validation_data=test_set1,\n",
    "    epochs=100\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "961cf171-5b8c-44d3-9595-ca0545e94182",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save Loss plot\n",
    "plt.figure()\n",
    "plt.plot(history.history['loss'], label='Train Loss')\n",
    "plt.plot(history.history['val_loss'], label='Validation Loss')\n",
    "plt.legend()\n",
    "plt.title(\"Loss\")\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.savefig('loss_plot_bigru.png')  # Save the plot as a PNG file\n",
    "plt.close()\n",
    "\n",
    "# Save Accuracy plot\n",
    "plt.figure()\n",
    "plt.plot(history.history['accuracy'], label='Train Accuracy')\n",
    "plt.plot(history.history['val_accuracy'], label='Validation Accuracy')\n",
    "plt.legend()\n",
    "plt.title(\"Accuracy\")\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.savefig('accuracy_plot_bigru.png')  # Save the plot as a PNG file\n",
    "plt.close()\n",
    "\n",
    "# Save Precision plot (Correct key for precision)\n",
    "plt.figure()\n",
    "plt.plot(history.history['Precision'], label='Train Precision')  # Corrected for precision\n",
    "plt.plot(history.history['val_Precision'], label='Validation Precision')  # Corrected for validation precision\n",
    "plt.legend()\n",
    "plt.title(\"Precision\")\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Precision')\n",
    "plt.savefig('precision_plot_bigru.png')  # Save the plot as a PNG file\n",
    "plt.close()\n",
    "\n",
    "# Save Recall plot (Correct key for recall)\n",
    "plt.figure()\n",
    "plt.plot(history.history['Recall'], label='Train Recall')  # Corrected for recall\n",
    "plt.plot(history.history['val_Recall'], label='Validation Recall')  # Corrected for validation recall\n",
    "plt.legend()\n",
    "plt.title(\"Recall\")\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Recall')\n",
    "plt.savefig('recall_plot_bigru.png')  # Save the plot as a PNG file\n",
    "plt.close()\n",
    "\n",
    "# Save F1 Score plot (Correct key for F1 score)\n",
    "plt.figure()\n",
    "plt.plot(history.history['f1_score'], label='Train F1 Score')  # Corrected for F1 score\n",
    "plt.plot(history.history['val_f1_score'], label='Validation F1 Score')  # Corrected for validation F1 score\n",
    "plt.legend()\n",
    "plt.title(\"F1 Score\")\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('F1 Score')\n",
    "plt.savefig('f1_score_plot_bigru.png')  # Save the plot as a PNG file\n",
    "plt.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1694bb3f-2583-46d1-b7c7-abf56bd72324",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

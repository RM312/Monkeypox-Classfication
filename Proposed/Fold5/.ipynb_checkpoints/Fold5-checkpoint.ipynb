{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4ed298ec-fe08-4927-9773-e1ddbc1d58c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.models import Sequential\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7236ffe3-2848-4da5-90b8-4a394ab283b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Custom Self-Attention Layer\n",
    "class SelfAttention(layers.Layer):\n",
    "    def __init__(self, channels, **kwargs):\n",
    "        super(SelfAttention, self).__init__(**kwargs)\n",
    "        self.channels = channels\n",
    "        self.attention_dense = layers.Dense(channels, activation='sigmoid')\n",
    "\n",
    "    def call(self, inputs):\n",
    "        attention_weights = self.attention_dense(inputs)\n",
    "        return inputs * attention_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "25063b71-c01e-4176-ba37-f1085c07a69b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class F1Score(tf.keras.metrics.Metric):\n",
    "    def __init__(self, name='f1_score', **kwargs):\n",
    "        super(F1Score, self).__init__(name=name, **kwargs)\n",
    "        self.precision = tf.keras.metrics.Precision()\n",
    "        self.recall = tf.keras.metrics.Recall()\n",
    "\n",
    "    def update_state(self, y_true, y_pred, sample_weight=None):\n",
    "        # Update the precision and recall for each batch\n",
    "        self.precision.update_state(y_true, y_pred, sample_weight)\n",
    "        self.recall.update_state(y_true, y_pred, sample_weight)\n",
    "\n",
    "    def result(self):\n",
    "        # Calculate F1 score as the harmonic mean of precision and recall\n",
    "        precision = self.precision.result()\n",
    "        recall = self.recall.result()\n",
    "        return 2 * (precision * recall) / (precision + recall + tf.keras.backend.epsilon())\n",
    "\n",
    "    def reset_states(self):\n",
    "        self.precision.reset_states()\n",
    "        self.recall.reset_states()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ef2a7fde-8da4-4670-b8b3-ca1de58d9441",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 7532 images belonging to 6 classes.\n"
     ]
    }
   ],
   "source": [
    "# Data preparation (same as in your code)\n",
    "train_datagen = ImageDataGenerator(rescale=1./255)\n",
    "training_set1 = train_datagen.flow_from_directory(\n",
    "    \"Monkeypox/archive (60)/Augmented Images/Augmented Images/FOLDS_AUG/fold5_AUG/Train/\",\n",
    "    target_size=(64, 64),\n",
    "    batch_size=32,\n",
    "    class_mode='categorical',  # Use 'sparse' if your labels are integers (not one-hot encoded)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "91306f36-f1aa-4213-b9cf-32d16c2325c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 7532 images belonging to 6 classes.\n"
     ]
    }
   ],
   "source": [
    "test_datagen = ImageDataGenerator(rescale=1./255)\n",
    "test_set1 = test_datagen.flow_from_directory(\n",
    "    \"Monkeypox/archive (60)/Augmented Images/Augmented Images/FOLDS_AUG/fold5_AUG/Train/\",\n",
    "    target_size=(64, 64),\n",
    "    batch_size=32,\n",
    "    class_mode='categorical',\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "eda5c3b5-f9a6-44ee-a300-44b930f29544",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CNN model with Self-Attention and Bidirectional GRU\n",
    "cnn = Sequential()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "90be1c45-7028-4aca-aa02-0b7e5829797c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\KIIT\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\layers\\convolutional\\base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\KIIT\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\backend\\tensorflow\\core.py:204: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "cnn.add(layers.Conv2D(filters=32, padding=\"same\", kernel_size=3, activation='relu', strides=2, input_shape=[64, 64, 3]))\n",
    "cnn.add(SelfAttention(channels=32))\n",
    "cnn.add(layers.MaxPool2D(pool_size=2, strides=2))\n",
    "\n",
    "cnn.add(layers.Conv2D(filters=32, padding='same', kernel_size=3, activation='relu'))\n",
    "cnn.add(layers.MaxPool2D(pool_size=2, strides=2))\n",
    "\n",
    "# Ensure the correct reshaping before GRU\n",
    "cnn.add(layers.Reshape((-1, 32)))  # Reshape for GRU (batch_size, time_steps, features)\n",
    "\n",
    "# Bidirectional GRU layer\n",
    "cnn.add(layers.Bidirectional(layers.GRU(64, return_sequences=True)))\n",
    "\n",
    "cnn.add(layers.Flatten())\n",
    "cnn.add(layers.Dense(units=128, activation='relu'))\n",
    "cnn.add(layers.Dense(6, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0554a1ef-b893-428e-ac9c-1851782f3b21",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile the model with Precision, Recall, and custom F1 score\n",
    "cnn.compile(\n",
    "    optimizer='adam', \n",
    "    loss='categorical_crossentropy', \n",
    "    metrics=['accuracy', 'Precision', 'Recall', F1Score()]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "fb1bf5fe-0642-4a1a-a6d2-ca7011071864",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                         </span>┃<span style=\"font-weight: bold\"> Output Shape                </span>┃<span style=\"font-weight: bold\">         Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
       "│ conv2d (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)          │             <span style=\"color: #00af00; text-decoration-color: #00af00\">896</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ self_attention (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">SelfAttention</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)          │           <span style=\"color: #00af00; text-decoration-color: #00af00\">1,056</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ max_pooling2d (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)          │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ conv2d_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)          │           <span style=\"color: #00af00; text-decoration-color: #00af00\">9,248</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ max_pooling2d_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)            │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ reshape (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Reshape</span>)                    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)              │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ bidirectional (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Bidirectional</span>)        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)             │          <span style=\"color: #00af00; text-decoration-color: #00af00\">37,632</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ flatten (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)                    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8192</span>)                │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)                 │       <span style=\"color: #00af00; text-decoration-color: #00af00\">1,048,704</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">6</span>)                   │             <span style=\"color: #00af00; text-decoration-color: #00af00\">774</span> │\n",
       "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
       "│ conv2d (\u001b[38;5;33mConv2D\u001b[0m)                      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m)          │             \u001b[38;5;34m896\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ self_attention (\u001b[38;5;33mSelfAttention\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m)          │           \u001b[38;5;34m1,056\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ max_pooling2d (\u001b[38;5;33mMaxPooling2D\u001b[0m)         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m32\u001b[0m)          │               \u001b[38;5;34m0\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ conv2d_1 (\u001b[38;5;33mConv2D\u001b[0m)                    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m32\u001b[0m)          │           \u001b[38;5;34m9,248\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ max_pooling2d_1 (\u001b[38;5;33mMaxPooling2D\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m32\u001b[0m)            │               \u001b[38;5;34m0\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ reshape (\u001b[38;5;33mReshape\u001b[0m)                    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m32\u001b[0m)              │               \u001b[38;5;34m0\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ bidirectional (\u001b[38;5;33mBidirectional\u001b[0m)        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m128\u001b[0m)             │          \u001b[38;5;34m37,632\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ flatten (\u001b[38;5;33mFlatten\u001b[0m)                    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8192\u001b[0m)                │               \u001b[38;5;34m0\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)                      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)                 │       \u001b[38;5;34m1,048,704\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_2 (\u001b[38;5;33mDense\u001b[0m)                      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m6\u001b[0m)                   │             \u001b[38;5;34m774\u001b[0m │\n",
       "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,098,310</span> (4.19 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m1,098,310\u001b[0m (4.19 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,098,310</span> (4.19 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m1,098,310\u001b[0m (4.19 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Model summary\n",
    "cnn.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "93eadcf1-c7a6-43e3-8b45-234fb6d95cfb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\KIIT\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\trainers\\data_adapters\\py_dataset_adapter.py:121: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
      "  self._warn_if_super_not_called()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "\u001b[1m236/236\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m215s\u001b[0m 771ms/step - Precision: 0.4730 - Recall: 0.0758 - accuracy: 0.4087 - f1_score: 0.1291 - loss: 1.5748 - val_Precision: 0.6437 - val_Recall: 0.3432 - val_accuracy: 0.5166 - val_f1_score: 0.4477 - val_loss: 1.3160\n",
      "Epoch 2/100\n",
      "\u001b[1m236/236\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m160s\u001b[0m 678ms/step - Precision: 0.6770 - Recall: 0.3212 - accuracy: 0.5271 - f1_score: 0.4350 - loss: 1.2686 - val_Precision: 0.8120 - val_Recall: 0.3721 - val_accuracy: 0.6228 - val_f1_score: 0.5104 - val_loss: 1.0435\n",
      "Epoch 3/100\n",
      "\u001b[1m236/236\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m145s\u001b[0m 613ms/step - Precision: 0.7635 - Recall: 0.4587 - accuracy: 0.6255 - f1_score: 0.5719 - loss: 1.0162 - val_Precision: 0.8230 - val_Recall: 0.5526 - val_accuracy: 0.6948 - val_f1_score: 0.6612 - val_loss: 0.8585\n",
      "Epoch 4/100\n",
      "\u001b[1m236/236\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m132s\u001b[0m 561ms/step - Precision: 0.8136 - Recall: 0.6132 - accuracy: 0.7159 - f1_score: 0.6990 - loss: 0.7848 - val_Precision: 0.8661 - val_Recall: 0.7260 - val_accuracy: 0.7947 - val_f1_score: 0.7899 - val_loss: 0.5969\n",
      "Epoch 5/100\n",
      "\u001b[1m236/236\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m129s\u001b[0m 544ms/step - Precision: 0.8562 - Recall: 0.7318 - accuracy: 0.7979 - f1_score: 0.7891 - loss: 0.5872 - val_Precision: 0.9042 - val_Recall: 0.8196 - val_accuracy: 0.8623 - val_f1_score: 0.8598 - val_loss: 0.4063\n",
      "Epoch 6/100\n",
      "\u001b[1m236/236\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m141s\u001b[0m 596ms/step - Precision: 0.9020 - Recall: 0.8207 - accuracy: 0.8651 - f1_score: 0.8594 - loss: 0.4178 - val_Precision: 0.9087 - val_Recall: 0.8335 - val_accuracy: 0.8687 - val_f1_score: 0.8695 - val_loss: 0.3784\n",
      "Epoch 7/100\n",
      "\u001b[1m236/236\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m138s\u001b[0m 582ms/step - Precision: 0.9111 - Recall: 0.8532 - accuracy: 0.8796 - f1_score: 0.8812 - loss: 0.3407 - val_Precision: 0.9252 - val_Recall: 0.8735 - val_accuracy: 0.8987 - val_f1_score: 0.8986 - val_loss: 0.3065\n",
      "Epoch 8/100\n",
      "\u001b[1m236/236\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m134s\u001b[0m 569ms/step - Precision: 0.9392 - Recall: 0.8897 - accuracy: 0.9118 - f1_score: 0.9137 - loss: 0.2574 - val_Precision: 0.9626 - val_Recall: 0.9399 - val_accuracy: 0.9498 - val_f1_score: 0.9511 - val_loss: 0.1610\n",
      "Epoch 9/100\n",
      "\u001b[1m236/236\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m128s\u001b[0m 541ms/step - Precision: 0.9551 - Recall: 0.9281 - accuracy: 0.9390 - f1_score: 0.9414 - loss: 0.1707 - val_Precision: 0.9571 - val_Recall: 0.9291 - val_accuracy: 0.9428 - val_f1_score: 0.9429 - val_loss: 0.1673\n",
      "Epoch 10/100\n",
      "\u001b[1m236/236\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m62s\u001b[0m 260ms/step - Precision: 0.9616 - Recall: 0.9435 - accuracy: 0.9522 - f1_score: 0.9524 - loss: 0.1448 - val_Precision: 0.9798 - val_Recall: 0.9668 - val_accuracy: 0.9738 - val_f1_score: 0.9733 - val_loss: 0.0880\n",
      "Epoch 11/100\n",
      "\u001b[1m236/236\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m57s\u001b[0m 241ms/step - Precision: 0.9746 - Recall: 0.9616 - accuracy: 0.9678 - f1_score: 0.9681 - loss: 0.1088 - val_Precision: 0.9699 - val_Recall: 0.9542 - val_accuracy: 0.9604 - val_f1_score: 0.9620 - val_loss: 0.1181\n",
      "Epoch 12/100\n",
      "\u001b[1m236/236\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m64s\u001b[0m 272ms/step - Precision: 0.9737 - Recall: 0.9604 - accuracy: 0.9681 - f1_score: 0.9670 - loss: 0.1134 - val_Precision: 0.9724 - val_Recall: 0.9638 - val_accuracy: 0.9679 - val_f1_score: 0.9681 - val_loss: 0.1000\n",
      "Epoch 13/100\n",
      "\u001b[1m236/236\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m67s\u001b[0m 282ms/step - Precision: 0.9700 - Recall: 0.9599 - accuracy: 0.9640 - f1_score: 0.9649 - loss: 0.1025 - val_Precision: 0.9627 - val_Recall: 0.9534 - val_accuracy: 0.9586 - val_f1_score: 0.9580 - val_loss: 0.1219\n",
      "Epoch 14/100\n",
      "\u001b[1m236/236\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m70s\u001b[0m 297ms/step - Precision: 0.9818 - Recall: 0.9735 - accuracy: 0.9773 - f1_score: 0.9776 - loss: 0.0704 - val_Precision: 0.9900 - val_Recall: 0.9869 - val_accuracy: 0.9887 - val_f1_score: 0.9884 - val_loss: 0.0395\n",
      "Epoch 15/100\n",
      "\u001b[1m236/236\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m73s\u001b[0m 308ms/step - Precision: 0.9874 - Recall: 0.9832 - accuracy: 0.9853 - f1_score: 0.9853 - loss: 0.0456 - val_Precision: 0.9758 - val_Recall: 0.9704 - val_accuracy: 0.9737 - val_f1_score: 0.9731 - val_loss: 0.0830\n",
      "Epoch 16/100\n",
      "\u001b[1m236/236\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m76s\u001b[0m 322ms/step - Precision: 0.9713 - Recall: 0.9642 - accuracy: 0.9676 - f1_score: 0.9678 - loss: 0.1038 - val_Precision: 0.9875 - val_Recall: 0.9857 - val_accuracy: 0.9865 - val_f1_score: 0.9866 - val_loss: 0.0409\n",
      "Epoch 17/100\n",
      "\u001b[1m236/236\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m78s\u001b[0m 329ms/step - Precision: 0.9863 - Recall: 0.9824 - accuracy: 0.9849 - f1_score: 0.9844 - loss: 0.0483 - val_Precision: 0.9811 - val_Recall: 0.9790 - val_accuracy: 0.9805 - val_f1_score: 0.9801 - val_loss: 0.0651\n",
      "Epoch 18/100\n",
      "\u001b[1m236/236\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m72s\u001b[0m 306ms/step - Precision: 0.9849 - Recall: 0.9806 - accuracy: 0.9830 - f1_score: 0.9827 - loss: 0.0579 - val_Precision: 0.9752 - val_Recall: 0.9729 - val_accuracy: 0.9740 - val_f1_score: 0.9741 - val_loss: 0.0805\n",
      "Epoch 19/100\n",
      "\u001b[1m236/236\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m77s\u001b[0m 327ms/step - Precision: 0.9874 - Recall: 0.9845 - accuracy: 0.9860 - f1_score: 0.9860 - loss: 0.0434 - val_Precision: 0.9907 - val_Recall: 0.9888 - val_accuracy: 0.9896 - val_f1_score: 0.9898 - val_loss: 0.0317\n",
      "Epoch 20/100\n",
      "\u001b[1m236/236\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m87s\u001b[0m 370ms/step - Precision: 0.9863 - Recall: 0.9843 - accuracy: 0.9854 - f1_score: 0.9853 - loss: 0.0391 - val_Precision: 0.9686 - val_Recall: 0.9664 - val_accuracy: 0.9675 - val_f1_score: 0.9675 - val_loss: 0.0960\n",
      "Epoch 21/100\n",
      "\u001b[1m236/236\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m70s\u001b[0m 296ms/step - Precision: 0.9840 - Recall: 0.9810 - accuracy: 0.9831 - f1_score: 0.9825 - loss: 0.0517 - val_Precision: 0.9863 - val_Recall: 0.9822 - val_accuracy: 0.9839 - val_f1_score: 0.9842 - val_loss: 0.0459\n",
      "Epoch 22/100\n",
      "\u001b[1m236/236\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m88s\u001b[0m 319ms/step - Precision: 0.9912 - Recall: 0.9881 - accuracy: 0.9900 - f1_score: 0.9896 - loss: 0.0325 - val_Precision: 0.9919 - val_Recall: 0.9904 - val_accuracy: 0.9911 - val_f1_score: 0.9912 - val_loss: 0.0263\n",
      "Epoch 23/100\n",
      "\u001b[1m236/236\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m83s\u001b[0m 325ms/step - Precision: 0.9936 - Recall: 0.9914 - accuracy: 0.9915 - f1_score: 0.9925 - loss: 0.0289 - val_Precision: 0.9884 - val_Recall: 0.9867 - val_accuracy: 0.9875 - val_f1_score: 0.9876 - val_loss: 0.0371\n",
      "Epoch 24/100\n",
      "\u001b[1m236/236\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m75s\u001b[0m 318ms/step - Precision: 0.9864 - Recall: 0.9826 - accuracy: 0.9845 - f1_score: 0.9845 - loss: 0.0438 - val_Precision: 0.9819 - val_Recall: 0.9777 - val_accuracy: 0.9790 - val_f1_score: 0.9798 - val_loss: 0.0631\n",
      "Epoch 25/100\n",
      "\u001b[1m236/236\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m83s\u001b[0m 324ms/step - Precision: 0.9845 - Recall: 0.9831 - accuracy: 0.9836 - f1_score: 0.9838 - loss: 0.0471 - val_Precision: 0.9936 - val_Recall: 0.9931 - val_accuracy: 0.9932 - val_f1_score: 0.9934 - val_loss: 0.0221\n",
      "Epoch 26/100\n",
      "\u001b[1m236/236\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m77s\u001b[0m 323ms/step - Precision: 0.9919 - Recall: 0.9900 - accuracy: 0.9900 - f1_score: 0.9909 - loss: 0.0300 - val_Precision: 0.9984 - val_Recall: 0.9979 - val_accuracy: 0.9980 - val_f1_score: 0.9981 - val_loss: 0.0071\n",
      "Epoch 27/100\n",
      "\u001b[1m236/236\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m88s\u001b[0m 373ms/step - Precision: 0.9975 - Recall: 0.9972 - accuracy: 0.9973 - f1_score: 0.9974 - loss: 0.0085 - val_Precision: 0.9999 - val_Recall: 0.9996 - val_accuracy: 0.9997 - val_f1_score: 0.9997 - val_loss: 0.0025\n",
      "Epoch 28/100\n",
      "\u001b[1m236/236\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m76s\u001b[0m 320ms/step - Precision: 0.9989 - Recall: 0.9986 - accuracy: 0.9987 - f1_score: 0.9987 - loss: 0.0058 - val_Precision: 0.9943 - val_Recall: 0.9934 - val_accuracy: 0.9938 - val_f1_score: 0.9938 - val_loss: 0.0186\n",
      "Epoch 29/100\n",
      "\u001b[1m236/236\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m80s\u001b[0m 338ms/step - Precision: 0.9850 - Recall: 0.9833 - accuracy: 0.9843 - f1_score: 0.9841 - loss: 0.0417 - val_Precision: 0.9670 - val_Recall: 0.9656 - val_accuracy: 0.9663 - val_f1_score: 0.9663 - val_loss: 0.1252\n",
      "Epoch 30/100\n",
      "\u001b[1m236/236\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m158s\u001b[0m 671ms/step - Precision: 0.9722 - Recall: 0.9685 - accuracy: 0.9696 - f1_score: 0.9704 - loss: 0.0935 - val_Precision: 0.9930 - val_Recall: 0.9922 - val_accuracy: 0.9926 - val_f1_score: 0.9926 - val_loss: 0.0233\n",
      "Epoch 31/100\n",
      "\u001b[1m236/236\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m144s\u001b[0m 610ms/step - Precision: 0.9940 - Recall: 0.9939 - accuracy: 0.9940 - f1_score: 0.9940 - loss: 0.0222 - val_Precision: 0.9977 - val_Recall: 0.9976 - val_accuracy: 0.9977 - val_f1_score: 0.9977 - val_loss: 0.0070\n",
      "Epoch 32/100\n",
      "\u001b[1m236/236\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m144s\u001b[0m 610ms/step - Precision: 0.9977 - Recall: 0.9972 - accuracy: 0.9972 - f1_score: 0.9975 - loss: 0.0072 - val_Precision: 0.9988 - val_Recall: 0.9985 - val_accuracy: 0.9985 - val_f1_score: 0.9987 - val_loss: 0.0062\n",
      "Epoch 33/100\n",
      "\u001b[1m236/236\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m165s\u001b[0m 699ms/step - Precision: 0.9981 - Recall: 0.9978 - accuracy: 0.9978 - f1_score: 0.9980 - loss: 0.0076 - val_Precision: 0.9961 - val_Recall: 0.9959 - val_accuracy: 0.9961 - val_f1_score: 0.9960 - val_loss: 0.0119\n",
      "Epoch 34/100\n",
      "\u001b[1m236/236\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m138s\u001b[0m 583ms/step - Precision: 0.9936 - Recall: 0.9929 - accuracy: 0.9930 - f1_score: 0.9932 - loss: 0.0216 - val_Precision: 0.9674 - val_Recall: 0.9644 - val_accuracy: 0.9652 - val_f1_score: 0.9659 - val_loss: 0.1145\n",
      "Epoch 35/100\n",
      "\u001b[1m236/236\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m151s\u001b[0m 639ms/step - Precision: 0.9669 - Recall: 0.9633 - accuracy: 0.9642 - f1_score: 0.9651 - loss: 0.1092 - val_Precision: 0.9942 - val_Recall: 0.9936 - val_accuracy: 0.9939 - val_f1_score: 0.9939 - val_loss: 0.0196\n",
      "Epoch 36/100\n",
      "\u001b[1m236/236\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m160s\u001b[0m 678ms/step - Precision: 0.9909 - Recall: 0.9898 - accuracy: 0.9908 - f1_score: 0.9903 - loss: 0.0298 - val_Precision: 0.9928 - val_Recall: 0.9922 - val_accuracy: 0.9924 - val_f1_score: 0.9925 - val_loss: 0.0207\n",
      "Epoch 37/100\n",
      "\u001b[1m236/236\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m129s\u001b[0m 544ms/step - Precision: 0.9938 - Recall: 0.9934 - accuracy: 0.9938 - f1_score: 0.9936 - loss: 0.0178 - val_Precision: 0.9936 - val_Recall: 0.9928 - val_accuracy: 0.9932 - val_f1_score: 0.9932 - val_loss: 0.0203\n",
      "Epoch 38/100\n",
      "\u001b[1m236/236\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m99s\u001b[0m 419ms/step - Precision: 0.9960 - Recall: 0.9956 - accuracy: 0.9960 - f1_score: 0.9958 - loss: 0.0152 - val_Precision: 0.9988 - val_Recall: 0.9988 - val_accuracy: 0.9988 - val_f1_score: 0.9988 - val_loss: 0.0036\n",
      "Epoch 39/100\n",
      "\u001b[1m236/236\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m124s\u001b[0m 526ms/step - Precision: 0.9954 - Recall: 0.9954 - accuracy: 0.9954 - f1_score: 0.9954 - loss: 0.0146 - val_Precision: 0.9976 - val_Recall: 0.9975 - val_accuracy: 0.9975 - val_f1_score: 0.9975 - val_loss: 0.0092\n",
      "Epoch 40/100\n",
      "\u001b[1m236/236\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m137s\u001b[0m 579ms/step - Precision: 0.9927 - Recall: 0.9924 - accuracy: 0.9924 - f1_score: 0.9926 - loss: 0.0233 - val_Precision: 0.9923 - val_Recall: 0.9916 - val_accuracy: 0.9922 - val_f1_score: 0.9920 - val_loss: 0.0292\n",
      "Epoch 41/100\n",
      "\u001b[1m236/236\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m146s\u001b[0m 615ms/step - Precision: 0.9925 - Recall: 0.9911 - accuracy: 0.9917 - f1_score: 0.9918 - loss: 0.0359 - val_Precision: 0.9884 - val_Recall: 0.9871 - val_accuracy: 0.9879 - val_f1_score: 0.9878 - val_loss: 0.0378\n",
      "Epoch 42/100\n",
      "\u001b[1m236/236\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m125s\u001b[0m 530ms/step - Precision: 0.9932 - Recall: 0.9915 - accuracy: 0.9924 - f1_score: 0.9924 - loss: 0.0258 - val_Precision: 0.9964 - val_Recall: 0.9960 - val_accuracy: 0.9964 - val_f1_score: 0.9962 - val_loss: 0.0145\n",
      "Epoch 43/100\n",
      "\u001b[1m236/236\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m138s\u001b[0m 586ms/step - Precision: 0.9994 - Recall: 0.9991 - accuracy: 0.9994 - f1_score: 0.9992 - loss: 0.0047 - val_Precision: 0.9983 - val_Recall: 0.9983 - val_accuracy: 0.9983 - val_f1_score: 0.9983 - val_loss: 0.0061\n",
      "Epoch 44/100\n",
      "\u001b[1m236/236\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m146s\u001b[0m 619ms/step - Precision: 0.9985 - Recall: 0.9977 - accuracy: 0.9985 - f1_score: 0.9981 - loss: 0.0045 - val_Precision: 0.9876 - val_Recall: 0.9869 - val_accuracy: 0.9874 - val_f1_score: 0.9872 - val_loss: 0.0461\n",
      "Epoch 45/100\n",
      "\u001b[1m236/236\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m178s\u001b[0m 753ms/step - Precision: 0.9934 - Recall: 0.9923 - accuracy: 0.9931 - f1_score: 0.9929 - loss: 0.0224 - val_Precision: 0.9903 - val_Recall: 0.9898 - val_accuracy: 0.9899 - val_f1_score: 0.9900 - val_loss: 0.0353\n",
      "Epoch 46/100\n",
      "\u001b[1m236/236\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m150s\u001b[0m 636ms/step - Precision: 0.9853 - Recall: 0.9847 - accuracy: 0.9848 - f1_score: 0.9850 - loss: 0.0558 - val_Precision: 0.9686 - val_Recall: 0.9672 - val_accuracy: 0.9677 - val_f1_score: 0.9679 - val_loss: 0.1250\n",
      "Epoch 47/100\n",
      "\u001b[1m236/236\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m140s\u001b[0m 594ms/step - Precision: 0.9808 - Recall: 0.9794 - accuracy: 0.9798 - f1_score: 0.9801 - loss: 0.0628 - val_Precision: 0.9934 - val_Recall: 0.9931 - val_accuracy: 0.9931 - val_f1_score: 0.9932 - val_loss: 0.0224\n",
      "Epoch 48/100\n",
      "\u001b[1m236/236\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m154s\u001b[0m 652ms/step - Precision: 0.9945 - Recall: 0.9942 - accuracy: 0.9945 - f1_score: 0.9943 - loss: 0.0206 - val_Precision: 0.9969 - val_Recall: 0.9969 - val_accuracy: 0.9969 - val_f1_score: 0.9969 - val_loss: 0.0093\n",
      "Epoch 49/100\n",
      "\u001b[1m236/236\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m136s\u001b[0m 577ms/step - Precision: 0.9929 - Recall: 0.9918 - accuracy: 0.9928 - f1_score: 0.9924 - loss: 0.0219 - val_Precision: 0.9916 - val_Recall: 0.9914 - val_accuracy: 0.9914 - val_f1_score: 0.9915 - val_loss: 0.0353\n",
      "Epoch 51/100\n",
      "\u001b[1m236/236\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m126s\u001b[0m 535ms/step - Precision: 0.9908 - Recall: 0.9903 - accuracy: 0.9906 - f1_score: 0.9906 - loss: 0.0306 - val_Precision: 0.9952 - val_Recall: 0.9947 - val_accuracy: 0.9948 - val_f1_score: 0.9950 - val_loss: 0.0167\n",
      "Epoch 52/100\n",
      "\u001b[1m236/236\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m116s\u001b[0m 491ms/step - Precision: 0.9956 - Recall: 0.9951 - accuracy: 0.9953 - f1_score: 0.9954 - loss: 0.0228 - val_Precision: 0.9993 - val_Recall: 0.9993 - val_accuracy: 0.9993 - val_f1_score: 0.9993 - val_loss: 0.0026\n",
      "Epoch 53/100\n",
      "\u001b[1m236/236\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m152s\u001b[0m 643ms/step - Precision: 0.9985 - Recall: 0.9982 - accuracy: 0.9985 - f1_score: 0.9983 - loss: 0.0045 - val_Precision: 0.9954 - val_Recall: 0.9951 - val_accuracy: 0.9951 - val_f1_score: 0.9952 - val_loss: 0.0154\n",
      "Epoch 54/100\n",
      "\u001b[1m236/236\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m143s\u001b[0m 606ms/step - Precision: 0.9949 - Recall: 0.9948 - accuracy: 0.9949 - f1_score: 0.9948 - loss: 0.0149 - val_Precision: 0.9950 - val_Recall: 0.9950 - val_accuracy: 0.9950 - val_f1_score: 0.9950 - val_loss: 0.0145\n",
      "Epoch 55/100\n",
      "\u001b[1m236/236\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m138s\u001b[0m 585ms/step - Precision: 0.9878 - Recall: 0.9872 - accuracy: 0.9876 - f1_score: 0.9875 - loss: 0.0413 - val_Precision: 0.9716 - val_Recall: 0.9688 - val_accuracy: 0.9701 - val_f1_score: 0.9702 - val_loss: 0.0988\n",
      "Epoch 56/100\n",
      "\u001b[1m236/236\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m129s\u001b[0m 548ms/step - Precision: 0.9805 - Recall: 0.9797 - accuracy: 0.9803 - f1_score: 0.9801 - loss: 0.0739 - val_Precision: 0.9887 - val_Recall: 0.9878 - val_accuracy: 0.9886 - val_f1_score: 0.9882 - val_loss: 0.0390\n",
      "Epoch 57/100\n",
      "\u001b[1m236/236\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m144s\u001b[0m 609ms/step - Precision: 0.9959 - Recall: 0.9959 - accuracy: 0.9959 - f1_score: 0.9959 - loss: 0.0202 - val_Precision: 0.9995 - val_Recall: 0.9995 - val_accuracy: 0.9995 - val_f1_score: 0.9995 - val_loss: 0.0053\n",
      "Epoch 58/100\n",
      "\u001b[1m236/236\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m143s\u001b[0m 604ms/step - Precision: 0.9972 - Recall: 0.9970 - accuracy: 0.9970 - f1_score: 0.9971 - loss: 0.0184 - val_Precision: 0.9999 - val_Recall: 0.9999 - val_accuracy: 0.9999 - val_f1_score: 0.9999 - val_loss: 0.0010\n",
      "Epoch 59/100\n",
      "\u001b[1m236/236\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m143s\u001b[0m 604ms/step - Precision: 1.0000 - Recall: 1.0000 - accuracy: 1.0000 - f1_score: 1.0000 - loss: 5.3395e-04 - val_Precision: 0.9999 - val_Recall: 0.9999 - val_accuracy: 0.9999 - val_f1_score: 0.9999 - val_loss: 6.5067e-04\n",
      "Epoch 60/100\n",
      "\u001b[1m236/236\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m139s\u001b[0m 590ms/step - Precision: 1.0000 - Recall: 0.9999 - accuracy: 0.9999 - f1_score: 1.0000 - loss: 6.7368e-04 - val_Precision: 0.9999 - val_Recall: 0.9999 - val_accuracy: 0.9999 - val_f1_score: 0.9999 - val_loss: 6.4348e-04\n",
      "Epoch 61/100\n",
      "\u001b[1m236/236\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m146s\u001b[0m 616ms/step - Precision: 1.0000 - Recall: 1.0000 - accuracy: 1.0000 - f1_score: 1.0000 - loss: 4.4317e-04 - val_Precision: 1.0000 - val_Recall: 1.0000 - val_accuracy: 1.0000 - val_f1_score: 1.0000 - val_loss: 1.4353e-04\n",
      "Epoch 62/100\n",
      "\u001b[1m236/236\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m145s\u001b[0m 613ms/step - Precision: 1.0000 - Recall: 1.0000 - accuracy: 1.0000 - f1_score: 1.0000 - loss: 6.9804e-05 - val_Precision: 0.9999 - val_Recall: 0.9999 - val_accuracy: 0.9999 - val_f1_score: 0.9999 - val_loss: 2.4801e-04\n",
      "Epoch 63/100\n",
      "\u001b[1m236/236\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m93s\u001b[0m 392ms/step - Precision: 1.0000 - Recall: 1.0000 - accuracy: 1.0000 - f1_score: 1.0000 - loss: 1.4069e-04 - val_Precision: 0.9999 - val_Recall: 0.9999 - val_accuracy: 0.9999 - val_f1_score: 0.9999 - val_loss: 5.6178e-04\n",
      "Epoch 64/100\n",
      "\u001b[1m236/236\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m67s\u001b[0m 282ms/step - Precision: 1.0000 - Recall: 0.9998 - accuracy: 1.0000 - f1_score: 0.9999 - loss: 2.8472e-04 - val_Precision: 0.9999 - val_Recall: 0.9999 - val_accuracy: 0.9999 - val_f1_score: 0.9999 - val_loss: 1.8897e-04\n",
      "Epoch 65/100\n",
      "\u001b[1m236/236\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m83s\u001b[0m 350ms/step - Precision: 0.9996 - Recall: 0.9995 - accuracy: 0.9995 - f1_score: 0.9995 - loss: 0.0012 - val_Precision: 0.9999 - val_Recall: 0.9999 - val_accuracy: 0.9999 - val_f1_score: 0.9999 - val_loss: 5.6177e-04\n",
      "Epoch 66/100\n",
      "\u001b[1m236/236\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m75s\u001b[0m 315ms/step - Precision: 0.9973 - Recall: 0.9971 - accuracy: 0.9972 - f1_score: 0.9972 - loss: 0.0112 - val_Precision: 0.9247 - val_Recall: 0.9226 - val_accuracy: 0.9234 - val_f1_score: 0.9236 - val_loss: 0.3917\n",
      "Epoch 67/100\n",
      "\u001b[1m236/236\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m81s\u001b[0m 341ms/step - Precision: 0.9458 - Recall: 0.9409 - accuracy: 0.9434 - f1_score: 0.9434 - loss: 0.2466 - val_Precision: 0.9951 - val_Recall: 0.9946 - val_accuracy: 0.9950 - val_f1_score: 0.9948 - val_loss: 0.0164\n",
      "Epoch 68/100\n",
      "\u001b[1m236/236\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m125s\u001b[0m 529ms/step - Precision: 0.9975 - Recall: 0.9961 - accuracy: 0.9964 - f1_score: 0.9968 - loss: 0.0113 - val_Precision: 0.9981 - val_Recall: 0.9979 - val_accuracy: 0.9980 - val_f1_score: 0.9980 - val_loss: 0.0055\n",
      "Epoch 69/100\n",
      "\u001b[1m236/236\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m158s\u001b[0m 672ms/step - Precision: 0.9970 - Recall: 0.9970 - accuracy: 0.9970 - f1_score: 0.9970 - loss: 0.0077 - val_Precision: 0.9996 - val_Recall: 0.9995 - val_accuracy: 0.9995 - val_f1_score: 0.9995 - val_loss: 0.0018\n",
      "Epoch 70/100\n",
      "\u001b[1m236/236\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m151s\u001b[0m 641ms/step - Precision: 1.0000 - Recall: 1.0000 - accuracy: 1.0000 - f1_score: 1.0000 - loss: 9.7202e-04 - val_Precision: 0.9999 - val_Recall: 0.9999 - val_accuracy: 0.9999 - val_f1_score: 0.9999 - val_loss: 4.6754e-04\n",
      "Epoch 71/100\n",
      "\u001b[1m236/236\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m147s\u001b[0m 621ms/step - Precision: 1.0000 - Recall: 1.0000 - accuracy: 1.0000 - f1_score: 1.0000 - loss: 2.3789e-04 - val_Precision: 0.9999 - val_Recall: 0.9999 - val_accuracy: 0.9999 - val_f1_score: 0.9999 - val_loss: 8.0317e-04\n",
      "Epoch 72/100\n",
      "\u001b[1m236/236\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m165s\u001b[0m 697ms/step - Precision: 0.9981 - Recall: 0.9981 - accuracy: 0.9981 - f1_score: 0.9981 - loss: 0.0075 - val_Precision: 0.9993 - val_Recall: 0.9993 - val_accuracy: 0.9993 - val_f1_score: 0.9993 - val_loss: 0.0020\n",
      "Epoch 73/100\n",
      "\u001b[1m236/236\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m111s\u001b[0m 470ms/step - Precision: 0.9999 - Recall: 0.9999 - accuracy: 0.9999 - f1_score: 0.9999 - loss: 0.0010 - val_Precision: 0.9997 - val_Recall: 0.9996 - val_accuracy: 0.9996 - val_f1_score: 0.9997 - val_loss: 0.0012\n",
      "Epoch 74/100\n",
      "\u001b[1m236/236\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m140s\u001b[0m 593ms/step - Precision: 0.9991 - Recall: 0.9988 - accuracy: 0.9991 - f1_score: 0.9989 - loss: 0.0031 - val_Precision: 0.9997 - val_Recall: 0.9996 - val_accuracy: 0.9996 - val_f1_score: 0.9997 - val_loss: 0.0014\n",
      "Epoch 75/100\n",
      "\u001b[1m236/236\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m130s\u001b[0m 551ms/step - Precision: 0.9920 - Recall: 0.9910 - accuracy: 0.9914 - f1_score: 0.9915 - loss: 0.0300 - val_Precision: 0.9750 - val_Recall: 0.9736 - val_accuracy: 0.9741 - val_f1_score: 0.9743 - val_loss: 0.0940\n",
      "Epoch 76/100\n",
      "\u001b[1m236/236\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m143s\u001b[0m 606ms/step - Precision: 0.9805 - Recall: 0.9793 - accuracy: 0.9800 - f1_score: 0.9799 - loss: 0.0795 - val_Precision: 0.9899 - val_Recall: 0.9894 - val_accuracy: 0.9895 - val_f1_score: 0.9896 - val_loss: 0.0278\n",
      "Epoch 77/100\n",
      "\u001b[1m236/236\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m148s\u001b[0m 627ms/step - Precision: 0.9949 - Recall: 0.9942 - accuracy: 0.9943 - f1_score: 0.9945 - loss: 0.0167 - val_Precision: 0.9992 - val_Recall: 0.9989 - val_accuracy: 0.9991 - val_f1_score: 0.9991 - val_loss: 0.0030\n",
      "Epoch 78/100\n",
      "\u001b[1m236/236\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m96s\u001b[0m 408ms/step - Precision: 0.9995 - Recall: 0.9995 - accuracy: 0.9995 - f1_score: 0.9995 - loss: 0.0019 - val_Precision: 1.0000 - val_Recall: 1.0000 - val_accuracy: 1.0000 - val_f1_score: 1.0000 - val_loss: 3.0904e-04\n",
      "Epoch 79/100\n",
      "\u001b[1m236/236\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m154s\u001b[0m 461ms/step - Precision: 0.9999 - Recall: 0.9999 - accuracy: 0.9999 - f1_score: 0.9999 - loss: 6.4687e-04 - val_Precision: 0.9999 - val_Recall: 0.9999 - val_accuracy: 0.9999 - val_f1_score: 0.9999 - val_loss: 5.9371e-04\n",
      "Epoch 80/100\n",
      "\u001b[1m236/236\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m155s\u001b[0m 659ms/step - Precision: 0.9999 - Recall: 0.9999 - accuracy: 0.9999 - f1_score: 0.9999 - loss: 9.1486e-04 - val_Precision: 0.9999 - val_Recall: 0.9999 - val_accuracy: 0.9999 - val_f1_score: 0.9999 - val_loss: 3.2596e-04\n",
      "Epoch 81/100\n",
      "\u001b[1m236/236\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m113s\u001b[0m 478ms/step - Precision: 0.9995 - Recall: 0.9995 - accuracy: 0.9995 - f1_score: 0.9995 - loss: 8.5959e-04 - val_Precision: 1.0000 - val_Recall: 1.0000 - val_accuracy: 1.0000 - val_f1_score: 1.0000 - val_loss: 8.7533e-05\n",
      "Epoch 82/100\n",
      "\u001b[1m236/236\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m120s\u001b[0m 507ms/step - Precision: 1.0000 - Recall: 1.0000 - accuracy: 1.0000 - f1_score: 1.0000 - loss: 1.1548e-04 - val_Precision: 1.0000 - val_Recall: 1.0000 - val_accuracy: 1.0000 - val_f1_score: 1.0000 - val_loss: 7.9093e-05\n",
      "Epoch 83/100\n",
      "\u001b[1m236/236\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m120s\u001b[0m 510ms/step - Precision: 1.0000 - Recall: 1.0000 - accuracy: 1.0000 - f1_score: 1.0000 - loss: 1.7356e-04 - val_Precision: 1.0000 - val_Recall: 1.0000 - val_accuracy: 1.0000 - val_f1_score: 1.0000 - val_loss: 4.8117e-05\n",
      "Epoch 84/100\n",
      "\u001b[1m236/236\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m111s\u001b[0m 469ms/step - Precision: 1.0000 - Recall: 1.0000 - accuracy: 1.0000 - f1_score: 1.0000 - loss: 3.6293e-05 - val_Precision: 1.0000 - val_Recall: 1.0000 - val_accuracy: 1.0000 - val_f1_score: 1.0000 - val_loss: 1.1773e-04\n",
      "Epoch 85/100\n",
      "\u001b[1m236/236\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m109s\u001b[0m 461ms/step - Precision: 1.0000 - Recall: 1.0000 - accuracy: 1.0000 - f1_score: 1.0000 - loss: 3.8156e-05 - val_Precision: 0.9999 - val_Recall: 0.9999 - val_accuracy: 0.9999 - val_f1_score: 0.9999 - val_loss: 3.5508e-04\n",
      "Epoch 86/100\n",
      "\u001b[1m236/236\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m105s\u001b[0m 445ms/step - Precision: 0.9995 - Recall: 0.9995 - accuracy: 0.9995 - f1_score: 0.9995 - loss: 0.0016 - val_Precision: 0.9997 - val_Recall: 0.9997 - val_accuracy: 0.9997 - val_f1_score: 0.9997 - val_loss: 0.0012\n",
      "Epoch 87/100\n",
      "\u001b[1m236/236\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m104s\u001b[0m 441ms/step - Precision: 0.9830 - Recall: 0.9818 - accuracy: 0.9822 - f1_score: 0.9824 - loss: 0.0763 - val_Precision: 0.9743 - val_Recall: 0.9707 - val_accuracy: 0.9719 - val_f1_score: 0.9725 - val_loss: 0.0927\n",
      "Epoch 88/100\n",
      "\u001b[1m236/236\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m97s\u001b[0m 412ms/step - Precision: 0.9793 - Recall: 0.9779 - accuracy: 0.9782 - f1_score: 0.9786 - loss: 0.0744 - val_Precision: 0.9965 - val_Recall: 0.9961 - val_accuracy: 0.9963 - val_f1_score: 0.9963 - val_loss: 0.0105\n",
      "Epoch 89/100\n",
      "\u001b[1m236/236\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m116s\u001b[0m 494ms/step - Precision: 0.9948 - Recall: 0.9948 - accuracy: 0.9948 - f1_score: 0.9948 - loss: 0.0163 - val_Precision: 0.9967 - val_Recall: 0.9964 - val_accuracy: 0.9965 - val_f1_score: 0.9965 - val_loss: 0.0096\n",
      "Epoch 90/100\n",
      "\u001b[1m236/236\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m113s\u001b[0m 478ms/step - Precision: 0.9967 - Recall: 0.9966 - accuracy: 0.9967 - f1_score: 0.9967 - loss: 0.0080 - val_Precision: 0.9999 - val_Recall: 0.9999 - val_accuracy: 0.9999 - val_f1_score: 0.9999 - val_loss: 5.5083e-04\n",
      "Epoch 91/100\n",
      "\u001b[1m236/236\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m104s\u001b[0m 439ms/step - Precision: 0.9998 - Recall: 0.9998 - accuracy: 0.9998 - f1_score: 0.9998 - loss: 5.2823e-04 - val_Precision: 1.0000 - val_Recall: 1.0000 - val_accuracy: 1.0000 - val_f1_score: 1.0000 - val_loss: 2.4997e-04\n",
      "Epoch 92/100\n",
      "\u001b[1m236/236\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m89s\u001b[0m 376ms/step - Precision: 1.0000 - Recall: 1.0000 - accuracy: 1.0000 - f1_score: 1.0000 - loss: 1.9034e-04 - val_Precision: 1.0000 - val_Recall: 1.0000 - val_accuracy: 1.0000 - val_f1_score: 1.0000 - val_loss: 8.3775e-05\n",
      "Epoch 93/100\n",
      "\u001b[1m236/236\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m109s\u001b[0m 461ms/step - Precision: 1.0000 - Recall: 1.0000 - accuracy: 1.0000 - f1_score: 1.0000 - loss: 7.8195e-05 - val_Precision: 1.0000 - val_Recall: 1.0000 - val_accuracy: 1.0000 - val_f1_score: 1.0000 - val_loss: 1.0073e-04\n",
      "Epoch 94/100\n",
      "\u001b[1m236/236\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m107s\u001b[0m 454ms/step - Precision: 1.0000 - Recall: 1.0000 - accuracy: 1.0000 - f1_score: 1.0000 - loss: 1.0018e-04 - val_Precision: 1.0000 - val_Recall: 1.0000 - val_accuracy: 1.0000 - val_f1_score: 1.0000 - val_loss: 4.6336e-05\n",
      "Epoch 95/100\n",
      "\u001b[1m236/236\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m93s\u001b[0m 394ms/step - Precision: 1.0000 - Recall: 1.0000 - accuracy: 1.0000 - f1_score: 1.0000 - loss: 5.8555e-05 - val_Precision: 1.0000 - val_Recall: 1.0000 - val_accuracy: 1.0000 - val_f1_score: 1.0000 - val_loss: 3.8145e-05\n",
      "Epoch 96/100\n",
      "\u001b[1m236/236\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m105s\u001b[0m 444ms/step - Precision: 1.0000 - Recall: 1.0000 - accuracy: 1.0000 - f1_score: 1.0000 - loss: 3.6635e-05 - val_Precision: 1.0000 - val_Recall: 1.0000 - val_accuracy: 1.0000 - val_f1_score: 1.0000 - val_loss: 3.3470e-05\n",
      "Epoch 97/100\n",
      "\u001b[1m236/236\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m103s\u001b[0m 435ms/step - Precision: 1.0000 - Recall: 1.0000 - accuracy: 1.0000 - f1_score: 1.0000 - loss: 2.6974e-05 - val_Precision: 1.0000 - val_Recall: 1.0000 - val_accuracy: 1.0000 - val_f1_score: 1.0000 - val_loss: 2.9209e-05\n",
      "Epoch 98/100\n",
      "\u001b[1m236/236\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m123s\u001b[0m 522ms/step - Precision: 1.0000 - Recall: 1.0000 - accuracy: 1.0000 - f1_score: 1.0000 - loss: 3.0992e-05 - val_Precision: 1.0000 - val_Recall: 1.0000 - val_accuracy: 1.0000 - val_f1_score: 1.0000 - val_loss: 2.6250e-05\n",
      "Epoch 99/100\n",
      "\u001b[1m236/236\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m112s\u001b[0m 476ms/step - Precision: 1.0000 - Recall: 1.0000 - accuracy: 1.0000 - f1_score: 1.0000 - loss: 1.9040e-05 - val_Precision: 1.0000 - val_Recall: 1.0000 - val_accuracy: 1.0000 - val_f1_score: 1.0000 - val_loss: 2.3338e-05\n"
     ]
    }
   ],
   "source": [
    "# Train the model and capture the history\n",
    "history = cnn.fit(\n",
    "    training_set1,\n",
    "    validation_data=test_set1,\n",
    "    epochs=100\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "202f43ba-2f18-4f79-8e24-6271bccdbc6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save Loss plot\n",
    "plt.figure()\n",
    "plt.plot(history.history['loss'], label='Train Loss')\n",
    "plt.plot(history.history['val_loss'], label='Validation Loss')\n",
    "plt.legend()\n",
    "plt.title(\"Loss\")\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.savefig('loss_plot_bigru.png')  # Save the plot as a PNG file\n",
    "plt.close()\n",
    "\n",
    "# Save Accuracy plot\n",
    "plt.figure()\n",
    "plt.plot(history.history['accuracy'], label='Train Accuracy')\n",
    "plt.plot(history.history['val_accuracy'], label='Validation Accuracy')\n",
    "plt.legend()\n",
    "plt.title(\"Accuracy\")\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.savefig('accuracy_plot_bigru.png')  # Save the plot as a PNG file\n",
    "plt.close()\n",
    "\n",
    "# Save Precision plot (Correct key for precision)\n",
    "plt.figure()\n",
    "plt.plot(history.history['Precision'], label='Train Precision')  # Corrected for precision\n",
    "plt.plot(history.history['val_Precision'], label='Validation Precision')  # Corrected for validation precision\n",
    "plt.legend()\n",
    "plt.title(\"Precision\")\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Precision')\n",
    "plt.savefig('precision_plot_bigru.png')  # Save the plot as a PNG file\n",
    "plt.close()\n",
    "\n",
    "# Save Recall plot (Correct key for recall)\n",
    "plt.figure()\n",
    "plt.plot(history.history['Recall'], label='Train Recall')  # Corrected for recall\n",
    "plt.plot(history.history['val_Recall'], label='Validation Recall')  # Corrected for validation recall\n",
    "plt.legend()\n",
    "plt.title(\"Recall\")\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Recall')\n",
    "plt.savefig('recall_plot_bigru.png')  # Save the plot as a PNG file\n",
    "plt.close()\n",
    "\n",
    "# Save F1 Score plot (Correct key for F1 score)\n",
    "plt.figure()\n",
    "plt.plot(history.history['f1_score'], label='Train F1 Score')  # Corrected for F1 score\n",
    "plt.plot(history.history['val_f1_score'], label='Validation F1 Score')  # Corrected for validation F1 score\n",
    "plt.legend()\n",
    "plt.title(\"F1 Score\")\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('F1 Score')\n",
    "plt.savefig('f1_score_plot_bigru.png')  # Save the plot as a PNG file\n",
    "plt.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19a9838c-4745-4e15-acc9-73b60b8e39b4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9afefdf8-392f-4911-9514-b3461e0e5e82",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.models import Sequential\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "803d4eaa-8ae7-4a58-9412-ebc7ca6bc2a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Custom Self-Attention Layer\n",
    "class SelfAttention(layers.Layer):\n",
    "    def __init__(self, channels, **kwargs):\n",
    "        super(SelfAttention, self).__init__(**kwargs)\n",
    "        self.channels = channels\n",
    "        self.attention_dense = layers.Dense(channels, activation='sigmoid')\n",
    "\n",
    "    def call(self, inputs):\n",
    "        attention_weights = self.attention_dense(inputs)\n",
    "        return inputs * attention_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4bce11ab-fd4c-4d2d-b57c-fe0fa72830eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "class F1Score(tf.keras.metrics.Metric):\n",
    "    def __init__(self, name='f1_score', **kwargs):\n",
    "        super(F1Score, self).__init__(name=name, **kwargs)\n",
    "        self.precision = tf.keras.metrics.Precision()\n",
    "        self.recall = tf.keras.metrics.Recall()\n",
    "\n",
    "    def update_state(self, y_true, y_pred, sample_weight=None):\n",
    "        # Update the precision and recall for each batch\n",
    "        self.precision.update_state(y_true, y_pred, sample_weight)\n",
    "        self.recall.update_state(y_true, y_pred, sample_weight)\n",
    "\n",
    "    def result(self):\n",
    "        # Calculate F1 score as the harmonic mean of precision and recall\n",
    "        precision = self.precision.result()\n",
    "        recall = self.recall.result()\n",
    "        return 2 * (precision * recall) / (precision + recall + tf.keras.backend.epsilon())\n",
    "\n",
    "    def reset_states(self):\n",
    "        self.precision.reset_states()\n",
    "        self.recall.reset_states()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "471f9349-8599-4c59-bd5d-8ad6f8700577",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 7336 images belonging to 6 classes.\n"
     ]
    }
   ],
   "source": [
    "# Data preparation (same as in your code)\n",
    "train_datagen = ImageDataGenerator(rescale=1./255)\n",
    "training_set1 = train_datagen.flow_from_directory(\n",
    "    \"Monkeypox/archive (60)/Augmented Images/Augmented Images/FOLDS_AUG/fold4_AUG/Train/\",\n",
    "    target_size=(64, 64),\n",
    "    batch_size=32,\n",
    "    class_mode='categorical',  # Use 'sparse' if your labels are integers (not one-hot encoded)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "af5c1862-567d-45d7-896b-67c2ba7368ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 7336 images belonging to 6 classes.\n"
     ]
    }
   ],
   "source": [
    "test_datagen = ImageDataGenerator(rescale=1./255)\n",
    "test_set1 = test_datagen.flow_from_directory(\n",
    "    \"Monkeypox/archive (60)/Augmented Images/Augmented Images/FOLDS_AUG/fold4_AUG/Train/\",\n",
    "    target_size=(64, 64),\n",
    "    batch_size=32,\n",
    "    class_mode='categorical',\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "999c8dc4-168b-41b7-9c88-6bb8ea075545",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CNN model with Self-Attention and Bidirectional GRU\n",
    "cnn = Sequential()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "607067db-e859-4f24-b8df-e8e94dd5b4bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\KIIT\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\layers\\convolutional\\base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\KIIT\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\backend\\tensorflow\\core.py:204: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "cnn.add(layers.Conv2D(filters=32, padding=\"same\", kernel_size=3, activation='relu', strides=2, input_shape=[64, 64, 3]))\n",
    "cnn.add(SelfAttention(channels=32))\n",
    "cnn.add(layers.MaxPool2D(pool_size=2, strides=2))\n",
    "\n",
    "cnn.add(layers.Conv2D(filters=32, padding='same', kernel_size=3, activation='relu'))\n",
    "cnn.add(layers.MaxPool2D(pool_size=2, strides=2))\n",
    "\n",
    "# Ensure the correct reshaping before GRU\n",
    "cnn.add(layers.Reshape((-1, 32)))  # Reshape for GRU (batch_size, time_steps, features)\n",
    "\n",
    "# Bidirectional GRU layer\n",
    "cnn.add(layers.Bidirectional(layers.GRU(64, return_sequences=True)))\n",
    "\n",
    "cnn.add(layers.Flatten())\n",
    "cnn.add(layers.Dense(units=128, activation='relu'))\n",
    "cnn.add(layers.Dense(6, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a3196e26-1e8d-47e5-8b15-46d02bfd8113",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile the model with Precision, Recall, and custom F1 score\n",
    "cnn.compile(\n",
    "    optimizer='adam', \n",
    "    loss='categorical_crossentropy', \n",
    "    metrics=['accuracy', 'Precision', 'Recall', F1Score()]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "fc1419b2-7c51-4ad8-b302-62588e790195",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                         </span>┃<span style=\"font-weight: bold\"> Output Shape                </span>┃<span style=\"font-weight: bold\">         Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
       "│ conv2d (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)          │             <span style=\"color: #00af00; text-decoration-color: #00af00\">896</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ self_attention (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">SelfAttention</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)          │           <span style=\"color: #00af00; text-decoration-color: #00af00\">1,056</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ max_pooling2d (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)          │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ conv2d_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)          │           <span style=\"color: #00af00; text-decoration-color: #00af00\">9,248</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ max_pooling2d_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)            │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ reshape (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Reshape</span>)                    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)              │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ bidirectional (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Bidirectional</span>)        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)             │          <span style=\"color: #00af00; text-decoration-color: #00af00\">37,632</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ flatten (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)                    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8192</span>)                │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)                 │       <span style=\"color: #00af00; text-decoration-color: #00af00\">1,048,704</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">6</span>)                   │             <span style=\"color: #00af00; text-decoration-color: #00af00\">774</span> │\n",
       "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
       "│ conv2d (\u001b[38;5;33mConv2D\u001b[0m)                      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m)          │             \u001b[38;5;34m896\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ self_attention (\u001b[38;5;33mSelfAttention\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m)          │           \u001b[38;5;34m1,056\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ max_pooling2d (\u001b[38;5;33mMaxPooling2D\u001b[0m)         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m32\u001b[0m)          │               \u001b[38;5;34m0\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ conv2d_1 (\u001b[38;5;33mConv2D\u001b[0m)                    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m32\u001b[0m)          │           \u001b[38;5;34m9,248\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ max_pooling2d_1 (\u001b[38;5;33mMaxPooling2D\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m32\u001b[0m)            │               \u001b[38;5;34m0\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ reshape (\u001b[38;5;33mReshape\u001b[0m)                    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m32\u001b[0m)              │               \u001b[38;5;34m0\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ bidirectional (\u001b[38;5;33mBidirectional\u001b[0m)        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m128\u001b[0m)             │          \u001b[38;5;34m37,632\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ flatten (\u001b[38;5;33mFlatten\u001b[0m)                    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8192\u001b[0m)                │               \u001b[38;5;34m0\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)                      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)                 │       \u001b[38;5;34m1,048,704\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_2 (\u001b[38;5;33mDense\u001b[0m)                      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m6\u001b[0m)                   │             \u001b[38;5;34m774\u001b[0m │\n",
       "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,098,310</span> (4.19 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m1,098,310\u001b[0m (4.19 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,098,310</span> (4.19 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m1,098,310\u001b[0m (4.19 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Model summary\n",
    "cnn.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4cb9f4a7-a1af-4725-8846-b5eb89ba4d1f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\KIIT\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\trainers\\data_adapters\\py_dataset_adapter.py:121: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
      "  self._warn_if_super_not_called()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "\u001b[1m230/230\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m193s\u001b[0m 717ms/step - Precision: 0.4440 - Recall: 0.0590 - accuracy: 0.3815 - f1_score: 0.1032 - loss: 1.5984 - val_Precision: 0.5781 - val_Recall: 0.3291 - val_accuracy: 0.4911 - val_f1_score: 0.4194 - val_loss: 1.3639\n",
      "Epoch 2/100\n",
      "\u001b[1m230/230\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m172s\u001b[0m 747ms/step - Precision: 0.6667 - Recall: 0.2995 - accuracy: 0.5207 - f1_score: 0.4127 - loss: 1.2747 - val_Precision: 0.6634 - val_Recall: 0.4740 - val_accuracy: 0.5748 - val_f1_score: 0.5529 - val_loss: 1.1149\n",
      "Epoch 3/100\n",
      "\u001b[1m230/230\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m160s\u001b[0m 693ms/step - Precision: 0.7320 - Recall: 0.4543 - accuracy: 0.6140 - f1_score: 0.5604 - loss: 1.0345 - val_Precision: 0.7644 - val_Recall: 0.6352 - val_accuracy: 0.6927 - val_f1_score: 0.6939 - val_loss: 0.8440\n",
      "Epoch 4/100\n",
      "\u001b[1m230/230\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m156s\u001b[0m 680ms/step - Precision: 0.8180 - Recall: 0.6254 - accuracy: 0.7254 - f1_score: 0.7088 - loss: 0.7624 - val_Precision: 0.8731 - val_Recall: 0.7116 - val_accuracy: 0.7985 - val_f1_score: 0.7841 - val_loss: 0.5986\n",
      "Epoch 5/100\n",
      "\u001b[1m230/230\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m147s\u001b[0m 638ms/step - Precision: 0.8610 - Recall: 0.7280 - accuracy: 0.7959 - f1_score: 0.7889 - loss: 0.5764 - val_Precision: 0.9087 - val_Recall: 0.7381 - val_accuracy: 0.8292 - val_f1_score: 0.8146 - val_loss: 0.5154\n",
      "Epoch 6/100\n",
      "\u001b[1m230/230\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m150s\u001b[0m 651ms/step - Precision: 0.8871 - Recall: 0.7952 - accuracy: 0.8459 - f1_score: 0.8386 - loss: 0.4533 - val_Precision: 0.9153 - val_Recall: 0.8576 - val_accuracy: 0.8879 - val_f1_score: 0.8855 - val_loss: 0.3268\n",
      "Epoch 7/100\n",
      "\u001b[1m230/230\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m144s\u001b[0m 626ms/step - Precision: 0.9169 - Recall: 0.8541 - accuracy: 0.8874 - f1_score: 0.8844 - loss: 0.3321 - val_Precision: 0.9312 - val_Recall: 0.8776 - val_accuracy: 0.9035 - val_f1_score: 0.9036 - val_loss: 0.2685\n",
      "Epoch 8/100\n",
      "\u001b[1m230/230\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m151s\u001b[0m 656ms/step - Precision: 0.9358 - Recall: 0.8943 - accuracy: 0.9141 - f1_score: 0.9146 - loss: 0.2509 - val_Precision: 0.9590 - val_Recall: 0.9213 - val_accuracy: 0.9414 - val_f1_score: 0.9398 - val_loss: 0.1887\n",
      "Epoch 9/100\n",
      "\u001b[1m230/230\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m97s\u001b[0m 423ms/step - Precision: 0.9523 - Recall: 0.9249 - accuracy: 0.9376 - f1_score: 0.9384 - loss: 0.1856 - val_Precision: 0.9621 - val_Recall: 0.9415 - val_accuracy: 0.9505 - val_f1_score: 0.9517 - val_loss: 0.1510\n",
      "Epoch 10/100\n",
      "\u001b[1m230/230\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m64s\u001b[0m 281ms/step - Precision: 0.9590 - Recall: 0.9365 - accuracy: 0.9479 - f1_score: 0.9476 - loss: 0.1494 - val_Precision: 0.9696 - val_Recall: 0.9522 - val_accuracy: 0.9607 - val_f1_score: 0.9608 - val_loss: 0.1245\n",
      "Epoch 11/100\n",
      "\u001b[1m230/230\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m67s\u001b[0m 293ms/step - Precision: 0.9637 - Recall: 0.9482 - accuracy: 0.9566 - f1_score: 0.9559 - loss: 0.1329 - val_Precision: 0.9672 - val_Recall: 0.9520 - val_accuracy: 0.9595 - val_f1_score: 0.9595 - val_loss: 0.1215\n",
      "Epoch 12/100\n",
      "\u001b[1m230/230\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m72s\u001b[0m 312ms/step - Precision: 0.9675 - Recall: 0.9541 - accuracy: 0.9599 - f1_score: 0.9607 - loss: 0.1161 - val_Precision: 0.9694 - val_Recall: 0.9614 - val_accuracy: 0.9648 - val_f1_score: 0.9654 - val_loss: 0.1022\n",
      "Epoch 13/100\n",
      "\u001b[1m230/230\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m75s\u001b[0m 327ms/step - Precision: 0.9764 - Recall: 0.9706 - accuracy: 0.9743 - f1_score: 0.9735 - loss: 0.0823 - val_Precision: 0.9386 - val_Recall: 0.9288 - val_accuracy: 0.9332 - val_f1_score: 0.9337 - val_loss: 0.2137\n",
      "Epoch 14/100\n",
      "\u001b[1m230/230\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m83s\u001b[0m 359ms/step - Precision: 0.9653 - Recall: 0.9571 - accuracy: 0.9611 - f1_score: 0.9612 - loss: 0.1076 - val_Precision: 0.9844 - val_Recall: 0.9786 - val_accuracy: 0.9813 - val_f1_score: 0.9815 - val_loss: 0.0653\n",
      "Epoch 15/100\n",
      "\u001b[1m230/230\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m84s\u001b[0m 365ms/step - Precision: 0.9775 - Recall: 0.9728 - accuracy: 0.9763 - f1_score: 0.9752 - loss: 0.0776 - val_Precision: 0.9828 - val_Recall: 0.9793 - val_accuracy: 0.9813 - val_f1_score: 0.9810 - val_loss: 0.0552\n",
      "Epoch 16/100\n",
      "\u001b[1m230/230\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m90s\u001b[0m 390ms/step - Precision: 0.9760 - Recall: 0.9732 - accuracy: 0.9750 - f1_score: 0.9746 - loss: 0.0707 - val_Precision: 0.9674 - val_Recall: 0.9517 - val_accuracy: 0.9594 - val_f1_score: 0.9595 - val_loss: 0.1212\n",
      "Epoch 17/100\n",
      "\u001b[1m230/230\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m87s\u001b[0m 377ms/step - Precision: 0.9713 - Recall: 0.9641 - accuracy: 0.9686 - f1_score: 0.9677 - loss: 0.0982 - val_Precision: 0.9810 - val_Recall: 0.9771 - val_accuracy: 0.9790 - val_f1_score: 0.9790 - val_loss: 0.0607\n",
      "Epoch 18/100\n",
      "\u001b[1m230/230\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m80s\u001b[0m 347ms/step - Precision: 0.9869 - Recall: 0.9843 - accuracy: 0.9857 - f1_score: 0.9856 - loss: 0.0407 - val_Precision: 0.9960 - val_Recall: 0.9955 - val_accuracy: 0.9955 - val_f1_score: 0.9958 - val_loss: 0.0152\n",
      "Epoch 19/100\n",
      "\u001b[1m230/230\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m79s\u001b[0m 344ms/step - Precision: 0.9952 - Recall: 0.9952 - accuracy: 0.9952 - f1_score: 0.9952 - loss: 0.0187 - val_Precision: 0.9984 - val_Recall: 0.9978 - val_accuracy: 0.9984 - val_f1_score: 0.9981 - val_loss: 0.0073\n",
      "Epoch 20/100\n",
      "\u001b[1m230/230\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m77s\u001b[0m 334ms/step - Precision: 0.9956 - Recall: 0.9947 - accuracy: 0.9949 - f1_score: 0.9951 - loss: 0.0153 - val_Precision: 0.9981 - val_Recall: 0.9975 - val_accuracy: 0.9977 - val_f1_score: 0.9978 - val_loss: 0.0103\n",
      "Epoch 21/100\n",
      "\u001b[1m230/230\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m92s\u001b[0m 378ms/step - Precision: 0.9967 - Recall: 0.9956 - accuracy: 0.9958 - f1_score: 0.9961 - loss: 0.0126 - val_Precision: 0.9978 - val_Recall: 0.9973 - val_accuracy: 0.9977 - val_f1_score: 0.9975 - val_loss: 0.0079\n",
      "Epoch 22/100\n",
      "\u001b[1m230/230\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m88s\u001b[0m 384ms/step - Precision: 0.9932 - Recall: 0.9928 - accuracy: 0.9931 - f1_score: 0.9930 - loss: 0.0203 - val_Precision: 0.9670 - val_Recall: 0.9617 - val_accuracy: 0.9636 - val_f1_score: 0.9643 - val_loss: 0.1038\n",
      "Epoch 23/100\n",
      "\u001b[1m230/230\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m81s\u001b[0m 352ms/step - Precision: 0.9571 - Recall: 0.9532 - accuracy: 0.9553 - f1_score: 0.9551 - loss: 0.1406 - val_Precision: 0.9896 - val_Recall: 0.9885 - val_accuracy: 0.9891 - val_f1_score: 0.9891 - val_loss: 0.0338\n",
      "Epoch 24/100\n",
      "\u001b[1m230/230\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m78s\u001b[0m 337ms/step - Precision: 0.9830 - Recall: 0.9808 - accuracy: 0.9821 - f1_score: 0.9819 - loss: 0.0490 - val_Precision: 0.9936 - val_Recall: 0.9932 - val_accuracy: 0.9935 - val_f1_score: 0.9934 - val_loss: 0.0211\n",
      "Epoch 25/100\n",
      "\u001b[1m230/230\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m83s\u001b[0m 362ms/step - Precision: 0.9948 - Recall: 0.9941 - accuracy: 0.9941 - f1_score: 0.9944 - loss: 0.0169 - val_Precision: 0.9986 - val_Recall: 0.9985 - val_accuracy: 0.9986 - val_f1_score: 0.9986 - val_loss: 0.0082\n",
      "Epoch 26/100\n",
      "\u001b[1m230/230\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m83s\u001b[0m 360ms/step - Precision: 0.9960 - Recall: 0.9951 - accuracy: 0.9958 - f1_score: 0.9956 - loss: 0.0171 - val_Precision: 0.9954 - val_Recall: 0.9948 - val_accuracy: 0.9951 - val_f1_score: 0.9951 - val_loss: 0.0161\n",
      "Epoch 27/100\n",
      "\u001b[1m230/230\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m93s\u001b[0m 406ms/step - Precision: 0.9976 - Recall: 0.9972 - accuracy: 0.9977 - f1_score: 0.9974 - loss: 0.0088 - val_Precision: 0.9895 - val_Recall: 0.9884 - val_accuracy: 0.9891 - val_f1_score: 0.9890 - val_loss: 0.0456\n",
      "Epoch 28/100\n",
      "\u001b[1m230/230\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m161s\u001b[0m 700ms/step - Precision: 0.9866 - Recall: 0.9844 - accuracy: 0.9856 - f1_score: 0.9855 - loss: 0.0477 - val_Precision: 0.9855 - val_Recall: 0.9841 - val_accuracy: 0.9847 - val_f1_score: 0.9848 - val_loss: 0.0443\n",
      "Epoch 29/100\n",
      "\u001b[1m230/230\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m156s\u001b[0m 676ms/step - Precision: 0.9692 - Recall: 0.9664 - accuracy: 0.9678 - f1_score: 0.9678 - loss: 0.0970 - val_Precision: 0.9842 - val_Recall: 0.9827 - val_accuracy: 0.9834 - val_f1_score: 0.9834 - val_loss: 0.0461\n",
      "Epoch 30/100\n",
      "\u001b[1m230/230\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m160s\u001b[0m 695ms/step - Precision: 0.9907 - Recall: 0.9903 - accuracy: 0.9904 - f1_score: 0.9905 - loss: 0.0306 - val_Precision: 0.9902 - val_Recall: 0.9883 - val_accuracy: 0.9894 - val_f1_score: 0.9892 - val_loss: 0.0318\n",
      "Epoch 31/100\n",
      "\u001b[1m230/230\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m151s\u001b[0m 658ms/step - Precision: 0.9914 - Recall: 0.9902 - accuracy: 0.9910 - f1_score: 0.9908 - loss: 0.0305 - val_Precision: 0.9660 - val_Recall: 0.9614 - val_accuracy: 0.9639 - val_f1_score: 0.9637 - val_loss: 0.1153\n",
      "Epoch 32/100\n",
      "\u001b[1m230/230\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m175s\u001b[0m 762ms/step - Precision: 0.9847 - Recall: 0.9828 - accuracy: 0.9836 - f1_score: 0.9838 - loss: 0.0583 - val_Precision: 0.9978 - val_Recall: 0.9978 - val_accuracy: 0.9978 - val_f1_score: 0.9978 - val_loss: 0.0068\n",
      "Epoch 33/100\n",
      "\u001b[1m230/230\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m157s\u001b[0m 682ms/step - Precision: 0.9979 - Recall: 0.9976 - accuracy: 0.9976 - f1_score: 0.9978 - loss: 0.0071 - val_Precision: 0.9955 - val_Recall: 0.9954 - val_accuracy: 0.9955 - val_f1_score: 0.9954 - val_loss: 0.0257\n",
      "Epoch 34/100\n",
      "\u001b[1m230/230\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m157s\u001b[0m 682ms/step - Precision: 0.9958 - Recall: 0.9955 - accuracy: 0.9957 - f1_score: 0.9957 - loss: 0.0171 - val_Precision: 0.9859 - val_Recall: 0.9846 - val_accuracy: 0.9851 - val_f1_score: 0.9853 - val_loss: 0.0413\n",
      "Epoch 35/100\n",
      "\u001b[1m230/230\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m117s\u001b[0m 509ms/step - Precision: 0.9905 - Recall: 0.9896 - accuracy: 0.9902 - f1_score: 0.9901 - loss: 0.0299 - val_Precision: 0.9851 - val_Recall: 0.9824 - val_accuracy: 0.9832 - val_f1_score: 0.9838 - val_loss: 0.0521\n",
      "Epoch 36/100\n",
      "\u001b[1m230/230\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m147s\u001b[0m 640ms/step - Precision: 0.9906 - Recall: 0.9898 - accuracy: 0.9900 - f1_score: 0.9902 - loss: 0.0310 - val_Precision: 0.9812 - val_Recall: 0.9791 - val_accuracy: 0.9805 - val_f1_score: 0.9801 - val_loss: 0.0576\n",
      "Epoch 37/100\n",
      "\u001b[1m230/230\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m155s\u001b[0m 676ms/step - Precision: 0.9857 - Recall: 0.9835 - accuracy: 0.9846 - f1_score: 0.9846 - loss: 0.0465 - val_Precision: 0.9963 - val_Recall: 0.9962 - val_accuracy: 0.9962 - val_f1_score: 0.9963 - val_loss: 0.0101\n",
      "Epoch 38/100\n",
      "\u001b[1m230/230\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m152s\u001b[0m 660ms/step - Precision: 0.9909 - Recall: 0.9904 - accuracy: 0.9906 - f1_score: 0.9907 - loss: 0.0257 - val_Precision: 0.9978 - val_Recall: 0.9974 - val_accuracy: 0.9978 - val_f1_score: 0.9976 - val_loss: 0.0066\n",
      "Epoch 39/100\n",
      "\u001b[1m230/230\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m142s\u001b[0m 619ms/step - Precision: 0.9974 - Recall: 0.9966 - accuracy: 0.9969 - f1_score: 0.9970 - loss: 0.0113 - val_Precision: 0.9875 - val_Recall: 0.9871 - val_accuracy: 0.9872 - val_f1_score: 0.9873 - val_loss: 0.0308\n",
      "Epoch 40/100\n",
      "\u001b[1m230/230\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m158s\u001b[0m 689ms/step - Precision: 0.9891 - Recall: 0.9887 - accuracy: 0.9890 - f1_score: 0.9889 - loss: 0.0295 - val_Precision: 0.9892 - val_Recall: 0.9891 - val_accuracy: 0.9891 - val_f1_score: 0.9892 - val_loss: 0.0286\n",
      "Epoch 41/100\n",
      "\u001b[1m230/230\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m153s\u001b[0m 664ms/step - Precision: 0.9873 - Recall: 0.9861 - accuracy: 0.9865 - f1_score: 0.9867 - loss: 0.0414 - val_Precision: 0.9971 - val_Recall: 0.9970 - val_accuracy: 0.9971 - val_f1_score: 0.9971 - val_loss: 0.0082\n",
      "Epoch 42/100\n",
      "\u001b[1m230/230\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m187s\u001b[0m 813ms/step - Precision: 0.9969 - Recall: 0.9959 - accuracy: 0.9959 - f1_score: 0.9964 - loss: 0.0109 - val_Precision: 0.9950 - val_Recall: 0.9947 - val_accuracy: 0.9950 - val_f1_score: 0.9948 - val_loss: 0.0154\n",
      "Epoch 44/100\n",
      "\u001b[1m230/230\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m151s\u001b[0m 653ms/step - Precision: 0.9838 - Recall: 0.9829 - accuracy: 0.9829 - f1_score: 0.9833 - loss: 0.0601 - val_Precision: 0.9864 - val_Recall: 0.9858 - val_accuracy: 0.9860 - val_f1_score: 0.9861 - val_loss: 0.0441\n",
      "Epoch 45/100\n",
      "\u001b[1m230/230\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m180s\u001b[0m 780ms/step - Precision: 0.9782 - Recall: 0.9769 - accuracy: 0.9774 - f1_score: 0.9776 - loss: 0.0818 - val_Precision: 0.9974 - val_Recall: 0.9971 - val_accuracy: 0.9973 - val_f1_score: 0.9973 - val_loss: 0.0085\n",
      "Epoch 46/100\n",
      "\u001b[1m230/230\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m164s\u001b[0m 711ms/step - Precision: 0.9957 - Recall: 0.9955 - accuracy: 0.9955 - f1_score: 0.9956 - loss: 0.0139 - val_Precision: 0.9956 - val_Recall: 0.9955 - val_accuracy: 0.9955 - val_f1_score: 0.9956 - val_loss: 0.0137\n",
      "Epoch 47/100\n",
      "\u001b[1m230/230\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m140s\u001b[0m 610ms/step - Precision: 0.9962 - Recall: 0.9962 - accuracy: 0.9962 - f1_score: 0.9962 - loss: 0.0069 - val_Precision: 0.9993 - val_Recall: 0.9992 - val_accuracy: 0.9993 - val_f1_score: 0.9993 - val_loss: 0.0030\n",
      "Epoch 48/100\n",
      "\u001b[1m230/230\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m132s\u001b[0m 573ms/step - Precision: 0.9999 - Recall: 0.9991 - accuracy: 0.9999 - f1_score: 0.9995 - loss: 0.0022 - val_Precision: 1.0000 - val_Recall: 1.0000 - val_accuracy: 1.0000 - val_f1_score: 1.0000 - val_loss: 3.7918e-04\n",
      "Epoch 49/100\n",
      "\u001b[1m230/230\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m151s\u001b[0m 660ms/step - Precision: 1.0000 - Recall: 1.0000 - accuracy: 1.0000 - f1_score: 1.0000 - loss: 2.5031e-04 - val_Precision: 1.0000 - val_Recall: 1.0000 - val_accuracy: 1.0000 - val_f1_score: 1.0000 - val_loss: 1.2515e-04\n",
      "Epoch 50/100\n",
      "\u001b[1m230/230\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m142s\u001b[0m 618ms/step - Precision: 1.0000 - Recall: 1.0000 - accuracy: 1.0000 - f1_score: 1.0000 - loss: 1.4541e-04 - val_Precision: 1.0000 - val_Recall: 1.0000 - val_accuracy: 1.0000 - val_f1_score: 1.0000 - val_loss: 1.0244e-04\n",
      "Epoch 51/100\n",
      "\u001b[1m230/230\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m163s\u001b[0m 709ms/step - Precision: 1.0000 - Recall: 1.0000 - accuracy: 1.0000 - f1_score: 1.0000 - loss: 9.1187e-05 - val_Precision: 1.0000 - val_Recall: 1.0000 - val_accuracy: 1.0000 - val_f1_score: 1.0000 - val_loss: 6.6603e-05\n",
      "Epoch 52/100\n",
      "\u001b[1m230/230\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m146s\u001b[0m 633ms/step - Precision: 1.0000 - Recall: 1.0000 - accuracy: 1.0000 - f1_score: 1.0000 - loss: 6.2101e-05 - val_Precision: 1.0000 - val_Recall: 1.0000 - val_accuracy: 1.0000 - val_f1_score: 1.0000 - val_loss: 5.5014e-05\n",
      "Epoch 53/100\n",
      "\u001b[1m230/230\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m144s\u001b[0m 624ms/step - Precision: 1.0000 - Recall: 1.0000 - accuracy: 1.0000 - f1_score: 1.0000 - loss: 5.5867e-05 - val_Precision: 1.0000 - val_Recall: 1.0000 - val_accuracy: 1.0000 - val_f1_score: 1.0000 - val_loss: 4.7620e-05\n",
      "Epoch 54/100\n",
      "\u001b[1m230/230\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m152s\u001b[0m 659ms/step - Precision: 1.0000 - Recall: 1.0000 - accuracy: 1.0000 - f1_score: 1.0000 - loss: 5.0414e-05 - val_Precision: 1.0000 - val_Recall: 1.0000 - val_accuracy: 1.0000 - val_f1_score: 1.0000 - val_loss: 4.1310e-05\n",
      "Epoch 55/100\n",
      "\u001b[1m230/230\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m150s\u001b[0m 654ms/step - Precision: 1.0000 - Recall: 1.0000 - accuracy: 1.0000 - f1_score: 1.0000 - loss: 3.6609e-05 - val_Precision: 1.0000 - val_Recall: 1.0000 - val_accuracy: 1.0000 - val_f1_score: 1.0000 - val_loss: 3.6253e-05\n",
      "Epoch 56/100\n",
      "\u001b[1m230/230\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m150s\u001b[0m 651ms/step - Precision: 1.0000 - Recall: 1.0000 - accuracy: 1.0000 - f1_score: 1.0000 - loss: 3.3498e-05 - val_Precision: 1.0000 - val_Recall: 1.0000 - val_accuracy: 1.0000 - val_f1_score: 1.0000 - val_loss: 3.2049e-05\n",
      "Epoch 57/100\n",
      "\u001b[1m230/230\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m157s\u001b[0m 683ms/step - Precision: 1.0000 - Recall: 1.0000 - accuracy: 1.0000 - f1_score: 1.0000 - loss: 3.0941e-05 - val_Precision: 1.0000 - val_Recall: 1.0000 - val_accuracy: 1.0000 - val_f1_score: 1.0000 - val_loss: 2.8345e-05\n",
      "Epoch 58/100\n",
      "\u001b[1m230/230\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m136s\u001b[0m 589ms/step - Precision: 1.0000 - Recall: 1.0000 - accuracy: 1.0000 - f1_score: 1.0000 - loss: 3.1702e-05 - val_Precision: 1.0000 - val_Recall: 1.0000 - val_accuracy: 1.0000 - val_f1_score: 1.0000 - val_loss: 2.4930e-05\n",
      "Epoch 59/100\n",
      "\u001b[1m230/230\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m74s\u001b[0m 323ms/step - Precision: 1.0000 - Recall: 1.0000 - accuracy: 1.0000 - f1_score: 1.0000 - loss: 2.2977e-05 - val_Precision: 1.0000 - val_Recall: 1.0000 - val_accuracy: 1.0000 - val_f1_score: 1.0000 - val_loss: 2.2200e-05\n",
      "Epoch 60/100\n",
      "\u001b[1m230/230\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m83s\u001b[0m 361ms/step - Precision: 1.0000 - Recall: 1.0000 - accuracy: 1.0000 - f1_score: 1.0000 - loss: 2.1861e-05 - val_Precision: 1.0000 - val_Recall: 1.0000 - val_accuracy: 1.0000 - val_f1_score: 1.0000 - val_loss: 1.9638e-05\n",
      "Epoch 61/100\n",
      "\u001b[1m230/230\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m80s\u001b[0m 348ms/step - Precision: 1.0000 - Recall: 1.0000 - accuracy: 1.0000 - f1_score: 1.0000 - loss: 2.1349e-05 - val_Precision: 1.0000 - val_Recall: 1.0000 - val_accuracy: 1.0000 - val_f1_score: 1.0000 - val_loss: 1.7593e-05\n",
      "Epoch 62/100\n",
      "\u001b[1m230/230\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m90s\u001b[0m 392ms/step - Precision: 1.0000 - Recall: 1.0000 - accuracy: 1.0000 - f1_score: 1.0000 - loss: 1.8805e-05 - val_Precision: 1.0000 - val_Recall: 1.0000 - val_accuracy: 1.0000 - val_f1_score: 1.0000 - val_loss: 1.5722e-05\n",
      "Epoch 63/100\n",
      "\u001b[1m230/230\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m137s\u001b[0m 595ms/step - Precision: 1.0000 - Recall: 1.0000 - accuracy: 1.0000 - f1_score: 1.0000 - loss: 1.5069e-05 - val_Precision: 1.0000 - val_Recall: 1.0000 - val_accuracy: 1.0000 - val_f1_score: 1.0000 - val_loss: 1.4188e-05\n",
      "Epoch 64/100\n",
      "\u001b[1m230/230\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m158s\u001b[0m 688ms/step - Precision: 1.0000 - Recall: 1.0000 - accuracy: 1.0000 - f1_score: 1.0000 - loss: 1.4317e-05 - val_Precision: 1.0000 - val_Recall: 1.0000 - val_accuracy: 1.0000 - val_f1_score: 1.0000 - val_loss: 1.2724e-05\n",
      "Epoch 65/100\n",
      "\u001b[1m230/230\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m164s\u001b[0m 713ms/step - Precision: 1.0000 - Recall: 1.0000 - accuracy: 1.0000 - f1_score: 1.0000 - loss: 1.1894e-05 - val_Precision: 1.0000 - val_Recall: 1.0000 - val_accuracy: 1.0000 - val_f1_score: 1.0000 - val_loss: 1.1452e-05\n",
      "Epoch 66/100\n",
      "\u001b[1m230/230\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m186s\u001b[0m 807ms/step - Precision: 1.0000 - Recall: 1.0000 - accuracy: 1.0000 - f1_score: 1.0000 - loss: 1.1342e-05 - val_Precision: 1.0000 - val_Recall: 1.0000 - val_accuracy: 1.0000 - val_f1_score: 1.0000 - val_loss: 1.0216e-05\n",
      "Epoch 67/100\n",
      "\u001b[1m230/230\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m224s\u001b[0m 973ms/step - Precision: 1.0000 - Recall: 1.0000 - accuracy: 1.0000 - f1_score: 1.0000 - loss: 9.2211e-06 - val_Precision: 1.0000 - val_Recall: 1.0000 - val_accuracy: 1.0000 - val_f1_score: 1.0000 - val_loss: 9.2027e-06\n",
      "Epoch 68/100\n",
      "\u001b[1m230/230\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m178s\u001b[0m 770ms/step - Precision: 1.0000 - Recall: 1.0000 - accuracy: 1.0000 - f1_score: 1.0000 - loss: 9.6524e-06 - val_Precision: 1.0000 - val_Recall: 1.0000 - val_accuracy: 1.0000 - val_f1_score: 1.0000 - val_loss: 8.2776e-06\n",
      "Epoch 69/100\n",
      "\u001b[1m230/230\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m132s\u001b[0m 572ms/step - Precision: 1.0000 - Recall: 1.0000 - accuracy: 1.0000 - f1_score: 1.0000 - loss: 7.6359e-06 - val_Precision: 1.0000 - val_Recall: 1.0000 - val_accuracy: 1.0000 - val_f1_score: 1.0000 - val_loss: 7.5044e-06\n",
      "Epoch 70/100\n",
      "\u001b[1m230/230\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m166s\u001b[0m 718ms/step - Precision: 1.0000 - Recall: 1.0000 - accuracy: 1.0000 - f1_score: 1.0000 - loss: 8.6091e-06 - val_Precision: 1.0000 - val_Recall: 1.0000 - val_accuracy: 1.0000 - val_f1_score: 1.0000 - val_loss: 6.7590e-06\n",
      "Epoch 71/100\n",
      "\u001b[1m230/230\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m136s\u001b[0m 590ms/step - Precision: 1.0000 - Recall: 1.0000 - accuracy: 1.0000 - f1_score: 1.0000 - loss: 7.1193e-06 - val_Precision: 1.0000 - val_Recall: 1.0000 - val_accuracy: 1.0000 - val_f1_score: 1.0000 - val_loss: 6.1327e-06\n",
      "Epoch 72/100\n",
      "\u001b[1m230/230\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m90s\u001b[0m 392ms/step - Precision: 1.0000 - Recall: 1.0000 - accuracy: 1.0000 - f1_score: 1.0000 - loss: 6.1923e-06 - val_Precision: 1.0000 - val_Recall: 1.0000 - val_accuracy: 1.0000 - val_f1_score: 1.0000 - val_loss: 5.4802e-06\n",
      "Epoch 73/100\n",
      "\u001b[1m230/230\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m116s\u001b[0m 506ms/step - Precision: 1.0000 - Recall: 1.0000 - accuracy: 1.0000 - f1_score: 1.0000 - loss: 5.1630e-06 - val_Precision: 1.0000 - val_Recall: 1.0000 - val_accuracy: 1.0000 - val_f1_score: 1.0000 - val_loss: 4.9536e-06\n",
      "Epoch 74/100\n",
      "\u001b[1m230/230\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m118s\u001b[0m 511ms/step - Precision: 1.0000 - Recall: 1.0000 - accuracy: 1.0000 - f1_score: 1.0000 - loss: 5.2101e-06 - val_Precision: 1.0000 - val_Recall: 1.0000 - val_accuracy: 1.0000 - val_f1_score: 1.0000 - val_loss: 4.4754e-06\n",
      "Epoch 75/100\n",
      "\u001b[1m230/230\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m120s\u001b[0m 521ms/step - Precision: 1.0000 - Recall: 1.0000 - accuracy: 1.0000 - f1_score: 1.0000 - loss: 4.7567e-06 - val_Precision: 1.0000 - val_Recall: 1.0000 - val_accuracy: 1.0000 - val_f1_score: 1.0000 - val_loss: 4.0135e-06\n",
      "Epoch 76/100\n",
      "\u001b[1m230/230\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m119s\u001b[0m 516ms/step - Precision: 1.0000 - Recall: 1.0000 - accuracy: 1.0000 - f1_score: 1.0000 - loss: 3.7615e-06 - val_Precision: 1.0000 - val_Recall: 1.0000 - val_accuracy: 1.0000 - val_f1_score: 1.0000 - val_loss: 3.6470e-06\n",
      "Epoch 77/100\n",
      "\u001b[1m230/230\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m170s\u001b[0m 736ms/step - Precision: 1.0000 - Recall: 1.0000 - accuracy: 1.0000 - f1_score: 1.0000 - loss: 3.6376e-06 - val_Precision: 1.0000 - val_Recall: 1.0000 - val_accuracy: 1.0000 - val_f1_score: 1.0000 - val_loss: 3.2862e-06\n",
      "Epoch 78/100\n",
      "\u001b[1m230/230\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m128s\u001b[0m 555ms/step - Precision: 1.0000 - Recall: 1.0000 - accuracy: 1.0000 - f1_score: 1.0000 - loss: 3.2332e-06 - val_Precision: 1.0000 - val_Recall: 1.0000 - val_accuracy: 1.0000 - val_f1_score: 1.0000 - val_loss: 3.0156e-06\n",
      "Epoch 79/100\n",
      "\u001b[1m230/230\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m116s\u001b[0m 506ms/step - Precision: 1.0000 - Recall: 1.0000 - accuracy: 1.0000 - f1_score: 1.0000 - loss: 2.6771e-06 - val_Precision: 1.0000 - val_Recall: 1.0000 - val_accuracy: 1.0000 - val_f1_score: 1.0000 - val_loss: 2.6464e-06\n",
      "Epoch 80/100\n",
      "\u001b[1m230/230\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m114s\u001b[0m 493ms/step - Precision: 1.0000 - Recall: 1.0000 - accuracy: 1.0000 - f1_score: 1.0000 - loss: 2.3281e-06 - val_Precision: 1.0000 - val_Recall: 1.0000 - val_accuracy: 1.0000 - val_f1_score: 1.0000 - val_loss: 2.4134e-06\n",
      "Epoch 81/100\n",
      "\u001b[1m230/230\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m107s\u001b[0m 465ms/step - Precision: 1.0000 - Recall: 1.0000 - accuracy: 1.0000 - f1_score: 1.0000 - loss: 2.2971e-06 - val_Precision: 1.0000 - val_Recall: 1.0000 - val_accuracy: 1.0000 - val_f1_score: 1.0000 - val_loss: 2.1178e-06\n",
      "Epoch 82/100\n",
      "\u001b[1m230/230\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m116s\u001b[0m 506ms/step - Precision: 1.0000 - Recall: 1.0000 - accuracy: 1.0000 - f1_score: 1.0000 - loss: 1.8616e-06 - val_Precision: 1.0000 - val_Recall: 1.0000 - val_accuracy: 1.0000 - val_f1_score: 1.0000 - val_loss: 1.8995e-06\n",
      "Epoch 83/100\n",
      "\u001b[1m230/230\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m132s\u001b[0m 573ms/step - Precision: 1.0000 - Recall: 1.0000 - accuracy: 1.0000 - f1_score: 1.0000 - loss: 1.9312e-06 - val_Precision: 1.0000 - val_Recall: 1.0000 - val_accuracy: 1.0000 - val_f1_score: 1.0000 - val_loss: 1.7082e-06\n",
      "Epoch 84/100\n",
      "\u001b[1m230/230\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m117s\u001b[0m 509ms/step - Precision: 1.0000 - Recall: 1.0000 - accuracy: 1.0000 - f1_score: 1.0000 - loss: 1.7182e-06 - val_Precision: 1.0000 - val_Recall: 1.0000 - val_accuracy: 1.0000 - val_f1_score: 1.0000 - val_loss: 1.5218e-06\n",
      "Epoch 85/100\n",
      "\u001b[1m230/230\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m104s\u001b[0m 451ms/step - Precision: 1.0000 - Recall: 1.0000 - accuracy: 1.0000 - f1_score: 1.0000 - loss: 1.3765e-06 - val_Precision: 1.0000 - val_Recall: 1.0000 - val_accuracy: 1.0000 - val_f1_score: 1.0000 - val_loss: 1.3606e-06\n",
      "Epoch 86/100\n",
      "\u001b[1m230/230\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m112s\u001b[0m 488ms/step - Precision: 1.0000 - Recall: 1.0000 - accuracy: 1.0000 - f1_score: 1.0000 - loss: 1.4568e-06 - val_Precision: 1.0000 - val_Recall: 1.0000 - val_accuracy: 1.0000 - val_f1_score: 1.0000 - val_loss: 1.2479e-06\n",
      "Epoch 87/100\n",
      "\u001b[1m230/230\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m154s\u001b[0m 669ms/step - Precision: 1.0000 - Recall: 1.0000 - accuracy: 1.0000 - f1_score: 1.0000 - loss: 1.1859e-06 - val_Precision: 1.0000 - val_Recall: 1.0000 - val_accuracy: 1.0000 - val_f1_score: 1.0000 - val_loss: 1.0900e-06\n",
      "Epoch 88/100\n",
      "\u001b[1m230/230\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m109s\u001b[0m 474ms/step - Precision: 1.0000 - Recall: 1.0000 - accuracy: 1.0000 - f1_score: 1.0000 - loss: 1.1133e-06 - val_Precision: 1.0000 - val_Recall: 1.0000 - val_accuracy: 1.0000 - val_f1_score: 1.0000 - val_loss: 9.9346e-07\n",
      "Epoch 89/100\n",
      "\u001b[1m230/230\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m112s\u001b[0m 486ms/step - Precision: 1.0000 - Recall: 1.0000 - accuracy: 1.0000 - f1_score: 1.0000 - loss: 9.3360e-07 - val_Precision: 1.0000 - val_Recall: 1.0000 - val_accuracy: 1.0000 - val_f1_score: 1.0000 - val_loss: 8.8295e-07\n",
      "Epoch 90/100\n",
      "\u001b[1m230/230\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m122s\u001b[0m 529ms/step - Precision: 1.0000 - Recall: 1.0000 - accuracy: 1.0000 - f1_score: 1.0000 - loss: 8.8976e-07 - val_Precision: 1.0000 - val_Recall: 1.0000 - val_accuracy: 1.0000 - val_f1_score: 1.0000 - val_loss: 7.9575e-07\n",
      "Epoch 91/100\n",
      "\u001b[1m230/230\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m158s\u001b[0m 686ms/step - Precision: 1.0000 - Recall: 1.0000 - accuracy: 1.0000 - f1_score: 1.0000 - loss: 7.7500e-07 - val_Precision: 1.0000 - val_Recall: 1.0000 - val_accuracy: 1.0000 - val_f1_score: 1.0000 - val_loss: 7.2927e-07\n",
      "Epoch 92/100\n",
      "\u001b[1m230/230\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m90s\u001b[0m 393ms/step - Precision: 1.0000 - Recall: 1.0000 - accuracy: 1.0000 - f1_score: 1.0000 - loss: 6.0347e-07 - val_Precision: 1.0000 - val_Recall: 1.0000 - val_accuracy: 1.0000 - val_f1_score: 1.0000 - val_loss: 5.7740e-07\n",
      "Epoch 94/100\n",
      "\u001b[1m230/230\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m74s\u001b[0m 324ms/step - Precision: 1.0000 - Recall: 1.0000 - accuracy: 1.0000 - f1_score: 1.0000 - loss: 5.0531e-07 - val_Precision: 1.0000 - val_Recall: 1.0000 - val_accuracy: 1.0000 - val_f1_score: 1.0000 - val_loss: 4.4889e-07\n",
      "Epoch 96/100\n",
      "\u001b[1m230/230\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m75s\u001b[0m 328ms/step - Precision: 1.0000 - Recall: 1.0000 - accuracy: 1.0000 - f1_score: 1.0000 - loss: 4.7945e-07 - val_Precision: 1.0000 - val_Recall: 1.0000 - val_accuracy: 1.0000 - val_f1_score: 1.0000 - val_loss: 3.9640e-07\n",
      "Epoch 97/100\n",
      "\u001b[1m230/230\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m44s\u001b[0m 190ms/step - Precision: 1.0000 - Recall: 1.0000 - accuracy: 1.0000 - f1_score: 1.0000 - loss: 3.9182e-07 - val_Precision: 1.0000 - val_Recall: 1.0000 - val_accuracy: 1.0000 - val_f1_score: 1.0000 - val_loss: 3.5626e-07\n",
      "Epoch 98/100\n",
      "\u001b[1m230/230\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 180ms/step - Precision: 1.0000 - Recall: 1.0000 - accuracy: 1.0000 - f1_score: 1.0000 - loss: 3.8696e-07 - val_Precision: 1.0000 - val_Recall: 1.0000 - val_accuracy: 1.0000 - val_f1_score: 1.0000 - val_loss: 3.2665e-07\n",
      "Epoch 99/100\n",
      "\u001b[1m230/230\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 182ms/step - Precision: 1.0000 - Recall: 1.0000 - accuracy: 1.0000 - f1_score: 1.0000 - loss: 3.3820e-07 - val_Precision: 1.0000 - val_Recall: 1.0000 - val_accuracy: 1.0000 - val_f1_score: 1.0000 - val_loss: 2.8291e-07\n",
      "Epoch 100/100\n",
      "\u001b[1m230/230\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 180ms/step - Precision: 1.0000 - Recall: 1.0000 - accuracy: 1.0000 - f1_score: 1.0000 - loss: 2.7371e-07 - val_Precision: 1.0000 - val_Recall: 1.0000 - val_accuracy: 1.0000 - val_f1_score: 1.0000 - val_loss: 2.5143e-07\n"
     ]
    }
   ],
   "source": [
    "# Train the model and capture the history\n",
    "history = cnn.fit(\n",
    "    training_set1,\n",
    "    validation_data=test_set1,\n",
    "    epochs=100\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "71829355-6e5d-4d8b-815c-fc11eb765079",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save Loss plot\n",
    "plt.figure()\n",
    "plt.plot(history.history['loss'], label='Train Loss')\n",
    "plt.plot(history.history['val_loss'], label='Validation Loss')\n",
    "plt.legend()\n",
    "plt.title(\"Loss\")\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.savefig('loss_plot_bigru.png')  # Save the plot as a PNG file\n",
    "plt.close()\n",
    "\n",
    "# Save Accuracy plot\n",
    "plt.figure()\n",
    "plt.plot(history.history['accuracy'], label='Train Accuracy')\n",
    "plt.plot(history.history['val_accuracy'], label='Validation Accuracy')\n",
    "plt.legend()\n",
    "plt.title(\"Accuracy\")\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.savefig('accuracy_plot_bigru.png')  # Save the plot as a PNG file\n",
    "plt.close()\n",
    "\n",
    "# Save Precision plot (Correct key for precision)\n",
    "plt.figure()\n",
    "plt.plot(history.history['Precision'], label='Train Precision')  # Corrected for precision\n",
    "plt.plot(history.history['val_Precision'], label='Validation Precision')  # Corrected for validation precision\n",
    "plt.legend()\n",
    "plt.title(\"Precision\")\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Precision')\n",
    "plt.savefig('precision_plot_bigru.png')  # Save the plot as a PNG file\n",
    "plt.close()\n",
    "\n",
    "# Save Recall plot (Correct key for recall)\n",
    "plt.figure()\n",
    "plt.plot(history.history['Recall'], label='Train Recall')  # Corrected for recall\n",
    "plt.plot(history.history['val_Recall'], label='Validation Recall')  # Corrected for validation recall\n",
    "plt.legend()\n",
    "plt.title(\"Recall\")\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Recall')\n",
    "plt.savefig('recall_plot_bigru.png')  # Save the plot as a PNG file\n",
    "plt.close()\n",
    "\n",
    "# Save F1 Score plot (Correct key for F1 score)\n",
    "plt.figure()\n",
    "plt.plot(history.history['f1_score'], label='Train F1 Score')  # Corrected for F1 score\n",
    "plt.plot(history.history['val_f1_score'], label='Validation F1 Score')  # Corrected for validation F1 score\n",
    "plt.legend()\n",
    "plt.title(\"F1 Score\")\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('F1 Score')\n",
    "plt.savefig('f1_score_plot_bigru.png')  # Save the plot as a PNG file\n",
    "plt.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b298970-a6c6-4407-b1c7-fcde003cc508",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

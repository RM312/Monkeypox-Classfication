{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7e753be5-3442-46a6-9bea-331bb9681b02",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout, Bidirectional, GRU, Reshape\n",
    "from tensorflow.keras.metrics import Precision, Recall\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7c028ec9-b908-45b0-a4f7-96ec6a69458a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class F1Score(tf.keras.metrics.Metric):\n",
    "    def __init__(self, name='f1_score', **kwargs):\n",
    "        super(F1Score, self).__init__(name=name, **kwargs)\n",
    "        self.precision = tf.keras.metrics.Precision()\n",
    "        self.recall = tf.keras.metrics.Recall()\n",
    "\n",
    "    def update_state(self, y_true, y_pred, sample_weight=None):\n",
    "        # Convert probabilities to binary labels (threshold at 0.5)\n",
    "        y_pred = tf.cast(y_pred >= 0.5, tf.float32)\n",
    "        self.precision.update_state(y_true, y_pred, sample_weight)\n",
    "        self.recall.update_state(y_true, y_pred, sample_weight)\n",
    "\n",
    "    def result(self):\n",
    "        precision = self.precision.result()\n",
    "        recall = self.recall.result()\n",
    "        return 2 * (precision * recall) / (precision + recall + tf.keras.backend.epsilon())\n",
    "\n",
    "    def reset_states(self):\n",
    "        self.precision.reset_states()\n",
    "        self.recall.reset_states()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d7b9bb62-fdcf-47ee-aabe-389de41d1901",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Self-Attention Layer\n",
    "class SelfAttention(tf.keras.layers.Layer):\n",
    "    def __init__(self, **kwargs):\n",
    "        super(SelfAttention, self).__init__(**kwargs)\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        self.W_query = self.add_weight(shape=(input_shape[-1], input_shape[-1]), initializer='random_normal', trainable=True)\n",
    "        self.W_key = self.add_weight(shape=(input_shape[-1], input_shape[-1]), initializer='random_normal', trainable=True)\n",
    "        self.W_value = self.add_weight(shape=(input_shape[-1], input_shape[-1]), initializer='random_normal', trainable=True)\n",
    "        self.attention = tf.keras.layers.Attention()\n",
    "\n",
    "    def call(self, inputs):\n",
    "        query = tf.matmul(inputs, self.W_query)\n",
    "        key = tf.matmul(inputs, self.W_key)\n",
    "        value = tf.matmul(inputs, self.W_value)\n",
    "        attention_output = self.attention([query, key, value])\n",
    "        return attention_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3a54fc9d-92ff-4e73-8648-b6a53bd43026",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up data generators\n",
    "train_datagen = ImageDataGenerator(rescale=1./255)\n",
    "test_datagen = ImageDataGenerator(rescale=1./255)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "01d00ce8-c6a8-4040-82ba-7b4f6232dc52",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set paths for your dataset\n",
    "train_directory = r'Monkeypox/Kaggle MP images/archive (2)/Augmented Images/Augmented Images/'  # Update with the correct path for training images\n",
    "test_directory = r'Monkeypox/Kaggle MP images/archive (2)/Augmented Images/Augmented Images/'  # Update with the correct path for testing images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8751c2ad-33f7-442c-8b99-e6fb8b5bf4df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 3192 images belonging to 2 classes.\n",
      "Found 3192 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "# Image data generators for training and testing\n",
    "training_set = train_datagen.flow_from_directory(\n",
    "    train_directory,\n",
    "    target_size=(64, 64),  # Change target size to 64x64\n",
    "    batch_size=32,\n",
    "    class_mode='binary'  # Change based on your dataset (e.g., 'binary', 'categorical', 'sparse')\n",
    ")\n",
    "\n",
    "test_set = test_datagen.flow_from_directory(\n",
    "    test_directory,\n",
    "    target_size=(64, 64),  # Change target size to 64x64\n",
    "    batch_size=32,\n",
    "    class_mode='binary'  # Change based on your dataset (e.g., 'binary', 'categorical', 'sparse')\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "27afd31f-6264-4473-8261-99bcb8e088d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model Definition with CNN + Self-Attention + Bidirectional GRU\n",
    "model = Sequential()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "eb1de5d7-cdf3-4c6b-9d82-deec98eb899f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\KIIT\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\layers\\convolutional\\base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "# Add a Conv2D layer to process images\n",
    "model.add(Conv2D(32, (3, 3), activation='relu', input_shape=(64, 64, 3)))  # Input shape changed to (64, 64, 3)\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "aeb26689-3c1e-495f-883b-ee6ec27995c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add more Conv2D and MaxPooling layers as needed\n",
    "model.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c46305a2-b219-4ab6-a505-366f7b59f725",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reshape to make it compatible with GRU layer\n",
    "model.add(Reshape((-1, 64)))  # Reshape to (batch_size, timesteps, features) for GRU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ce8eee9f-13a8-4ae4-9d94-40ce19fd62dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\KIIT\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\backend\\tensorflow\\core.py:204: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Add Self-Attention Layer\n",
    "model.add(SelfAttention())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "bddc1e17-67d8-47a2-8d7f-760b7f12fa2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add Bidirectional GRU layers\n",
    "model.add(Bidirectional(GRU(64, activation='relu', return_sequences=False)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "785afad0-e4ea-48c3-89a8-630114041021",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add Dropout and Dense layers for classification\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(1, activation='sigmoid'))  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f007edca-3769-45db-8f56-665c294af6fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile the model with custom F1 score and other metrics\n",
    "model.compile(\n",
    "    optimizer='adam',\n",
    "    loss='binary_crossentropy',  \n",
    "    metrics=['accuracy', Precision(), Recall(), F1Score()]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7d4c2a2b-8dcd-40a4-a5a7-9fabeb7d0650",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                         </span>┃<span style=\"font-weight: bold\"> Output Shape                </span>┃<span style=\"font-weight: bold\">         Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
       "│ conv2d (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">62</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">62</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)          │             <span style=\"color: #00af00; text-decoration-color: #00af00\">896</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ max_pooling2d (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">31</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">31</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)          │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ conv2d_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">29</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">29</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)          │          <span style=\"color: #00af00; text-decoration-color: #00af00\">18,496</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ max_pooling2d_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)          │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ reshape (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Reshape</span>)                    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">196</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ self_attention (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">SelfAttention</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">196</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │          <span style=\"color: #00af00; text-decoration-color: #00af00\">12,288</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ bidirectional (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Bidirectional</span>)        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)                 │          <span style=\"color: #00af00; text-decoration-color: #00af00\">49,920</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dropout (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)                 │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)                   │             <span style=\"color: #00af00; text-decoration-color: #00af00\">129</span> │\n",
       "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
       "│ conv2d (\u001b[38;5;33mConv2D\u001b[0m)                      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m62\u001b[0m, \u001b[38;5;34m62\u001b[0m, \u001b[38;5;34m32\u001b[0m)          │             \u001b[38;5;34m896\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ max_pooling2d (\u001b[38;5;33mMaxPooling2D\u001b[0m)         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m31\u001b[0m, \u001b[38;5;34m31\u001b[0m, \u001b[38;5;34m32\u001b[0m)          │               \u001b[38;5;34m0\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ conv2d_1 (\u001b[38;5;33mConv2D\u001b[0m)                    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m29\u001b[0m, \u001b[38;5;34m29\u001b[0m, \u001b[38;5;34m64\u001b[0m)          │          \u001b[38;5;34m18,496\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ max_pooling2d_1 (\u001b[38;5;33mMaxPooling2D\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m64\u001b[0m)          │               \u001b[38;5;34m0\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ reshape (\u001b[38;5;33mReshape\u001b[0m)                    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m196\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │               \u001b[38;5;34m0\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ self_attention (\u001b[38;5;33mSelfAttention\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m196\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │          \u001b[38;5;34m12,288\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ bidirectional (\u001b[38;5;33mBidirectional\u001b[0m)        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)                 │          \u001b[38;5;34m49,920\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dropout (\u001b[38;5;33mDropout\u001b[0m)                    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)                 │               \u001b[38;5;34m0\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense (\u001b[38;5;33mDense\u001b[0m)                        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)                   │             \u001b[38;5;34m129\u001b[0m │\n",
       "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">81,729</span> (319.25 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m81,729\u001b[0m (319.25 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">81,729</span> (319.25 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m81,729\u001b[0m (319.25 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "38be2a56-f82b-4fc2-a016-66df3cae5512",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\KIIT\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\trainers\\data_adapters\\py_dataset_adapter.py:121: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
      "  self._warn_if_super_not_called()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 127ms/step - accuracy: 0.5718 - f1_score: 0.7033 - loss: 0.6784 - precision: 0.5763 - recall: 0.9122 - val_accuracy: 0.6143 - val_f1_score: 0.7343 - val_loss: 0.6517 - val_precision: 0.5929 - val_recall: 0.9643\n",
      "Epoch 2/100\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 150ms/step - accuracy: 0.6427 - f1_score: 0.7260 - loss: 0.6451 - precision: 0.6352 - recall: 0.8490 - val_accuracy: 0.6472 - val_f1_score: 0.6734 - val_loss: 0.6325 - val_precision: 0.6894 - val_recall: 0.6582\n",
      "Epoch 3/100\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 158ms/step - accuracy: 0.6802 - f1_score: 0.7428 - loss: 0.6219 - precision: 0.6751 - recall: 0.8285 - val_accuracy: 0.6591 - val_f1_score: 0.7478 - val_loss: 0.6298 - val_precision: 0.6325 - val_recall: 0.9144\n",
      "Epoch 4/100\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 154ms/step - accuracy: 0.6665 - f1_score: 0.7385 - loss: 0.6255 - precision: 0.6536 - recall: 0.8500 - val_accuracy: 0.6404 - val_f1_score: 0.7447 - val_loss: 0.6409 - val_precision: 0.6127 - val_recall: 0.9490\n",
      "Epoch 5/100\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 196ms/step - accuracy: 0.6655 - f1_score: 0.7353 - loss: 0.6303 - precision: 0.6512 - recall: 0.8457 - val_accuracy: 0.6858 - val_f1_score: 0.7561 - val_loss: 0.6110 - val_precision: 0.6620 - val_recall: 0.8815\n",
      "Epoch 6/100\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 307ms/step - accuracy: 0.6686 - f1_score: 0.7373 - loss: 0.6126 - precision: 0.6532 - recall: 0.8467 - val_accuracy: 0.6870 - val_f1_score: 0.7478 - val_loss: 0.6014 - val_precision: 0.6741 - val_recall: 0.8396\n",
      "Epoch 7/100\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 190ms/step - accuracy: 0.6887 - f1_score: 0.7509 - loss: 0.6090 - precision: 0.6752 - recall: 0.8458 - val_accuracy: 0.6830 - val_f1_score: 0.7615 - val_loss: 0.6097 - val_precision: 0.6516 - val_recall: 0.9161\n",
      "Epoch 8/100\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 191ms/step - accuracy: 0.6690 - f1_score: 0.7415 - loss: 0.6166 - precision: 0.6577 - recall: 0.8504 - val_accuracy: 0.6425 - val_f1_score: 0.7463 - val_loss: 0.6304 - val_precision: 0.6140 - val_recall: 0.9512\n",
      "Epoch 9/100\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 327ms/step - accuracy: 0.6581 - f1_score: 0.7420 - loss: 0.6257 - precision: 0.6415 - recall: 0.8821 - val_accuracy: 0.6845 - val_f1_score: 0.7266 - val_loss: 0.5959 - val_precision: 0.6972 - val_recall: 0.7585\n",
      "Epoch 10/100\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 394ms/step - accuracy: 0.6958 - f1_score: 0.7503 - loss: 0.5928 - precision: 0.6740 - recall: 0.8470 - val_accuracy: 0.7080 - val_f1_score: 0.7669 - val_loss: 0.5687 - val_precision: 0.6862 - val_recall: 0.8690\n",
      "Epoch 11/100\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m36s\u001b[0m 360ms/step - accuracy: 0.6904 - f1_score: 0.7507 - loss: 0.5869 - precision: 0.6733 - recall: 0.8485 - val_accuracy: 0.7102 - val_f1_score: 0.7686 - val_loss: 0.5704 - val_precision: 0.6879 - val_recall: 0.8707\n",
      "Epoch 12/100\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 209ms/step - accuracy: 0.7191 - f1_score: 0.7819 - loss: 0.5616 - precision: 0.6946 - recall: 0.8943 - val_accuracy: 0.6971 - val_f1_score: 0.7664 - val_loss: 0.5723 - val_precision: 0.6678 - val_recall: 0.8991\n",
      "Epoch 13/100\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 166ms/step - accuracy: 0.7059 - f1_score: 0.7776 - loss: 0.5667 - precision: 0.6847 - recall: 0.9001 - val_accuracy: 0.7155 - val_f1_score: 0.7761 - val_loss: 0.5679 - val_precision: 0.6867 - val_recall: 0.8923\n",
      "Epoch 14/100\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 174ms/step - accuracy: 0.7106 - f1_score: 0.7741 - loss: 0.5651 - precision: 0.6843 - recall: 0.8912 - val_accuracy: 0.7212 - val_f1_score: 0.7765 - val_loss: 0.5449 - val_precision: 0.6970 - val_recall: 0.8764\n",
      "Epoch 15/100\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 181ms/step - accuracy: 0.7294 - f1_score: 0.7929 - loss: 0.5508 - precision: 0.7019 - recall: 0.9117 - val_accuracy: 0.7256 - val_f1_score: 0.7892 - val_loss: 0.5569 - val_precision: 0.6856 - val_recall: 0.9297\n",
      "Epoch 16/100\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 187ms/step - accuracy: 0.7191 - f1_score: 0.7728 - loss: 0.5445 - precision: 0.6910 - recall: 0.8772 - val_accuracy: 0.7256 - val_f1_score: 0.7881 - val_loss: 0.5344 - val_precision: 0.6873 - val_recall: 0.9235\n",
      "Epoch 17/100\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 189ms/step - accuracy: 0.7027 - f1_score: 0.7658 - loss: 0.5530 - precision: 0.6690 - recall: 0.8955 - val_accuracy: 0.7321 - val_f1_score: 0.7960 - val_loss: 0.5557 - val_precision: 0.6873 - val_recall: 0.9456\n",
      "Epoch 18/100\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 200ms/step - accuracy: 0.7304 - f1_score: 0.7857 - loss: 0.5371 - precision: 0.7039 - recall: 0.8897 - val_accuracy: 0.7415 - val_f1_score: 0.8032 - val_loss: 0.5164 - val_precision: 0.6933 - val_recall: 0.9546\n",
      "Epoch 19/100\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 173ms/step - accuracy: 0.7340 - f1_score: 0.7898 - loss: 0.5313 - precision: 0.7026 - recall: 0.9023 - val_accuracy: 0.7547 - val_f1_score: 0.8080 - val_loss: 0.5029 - val_precision: 0.7119 - val_recall: 0.9342\n",
      "Epoch 20/100\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 285ms/step - accuracy: 0.7422 - f1_score: 0.8004 - loss: 0.5150 - precision: 0.7035 - recall: 0.9286 - val_accuracy: 0.7597 - val_f1_score: 0.8101 - val_loss: 0.4854 - val_precision: 0.7191 - val_recall: 0.9274\n",
      "Epoch 21/100\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m36s\u001b[0m 359ms/step - accuracy: 0.7593 - f1_score: 0.8101 - loss: 0.4914 - precision: 0.7180 - recall: 0.9295 - val_accuracy: 0.7462 - val_f1_score: 0.8024 - val_loss: 0.5238 - val_precision: 0.7042 - val_recall: 0.9325\n",
      "Epoch 22/100\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 343ms/step - accuracy: 0.7484 - f1_score: 0.8042 - loss: 0.5153 - precision: 0.7118 - recall: 0.9243 - val_accuracy: 0.7691 - val_f1_score: 0.8201 - val_loss: 0.4699 - val_precision: 0.7201 - val_recall: 0.9524\n",
      "Epoch 23/100\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 377ms/step - accuracy: 0.7478 - f1_score: 0.8031 - loss: 0.5041 - precision: 0.7108 - recall: 0.9233 - val_accuracy: 0.7641 - val_f1_score: 0.8044 - val_loss: 0.4660 - val_precision: 0.7424 - val_recall: 0.8776\n",
      "Epoch 24/100\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 354ms/step - accuracy: 0.7740 - f1_score: 0.8227 - loss: 0.4862 - precision: 0.7346 - recall: 0.9355 - val_accuracy: 0.7519 - val_f1_score: 0.8153 - val_loss: 0.5026 - val_precision: 0.6926 - val_recall: 0.9909\n",
      "Epoch 25/100\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 189ms/step - accuracy: 0.7469 - f1_score: 0.8060 - loss: 0.4978 - precision: 0.7018 - recall: 0.9467 - val_accuracy: 0.7509 - val_f1_score: 0.8028 - val_loss: 0.4928 - val_precision: 0.7137 - val_recall: 0.9172\n",
      "Epoch 26/100\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 163ms/step - accuracy: 0.7652 - f1_score: 0.8134 - loss: 0.4847 - precision: 0.7250 - recall: 0.9265 - val_accuracy: 0.7747 - val_f1_score: 0.8221 - val_loss: 0.4429 - val_precision: 0.7295 - val_recall: 0.9416\n",
      "Epoch 27/100\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 162ms/step - accuracy: 0.7647 - f1_score: 0.8132 - loss: 0.4658 - precision: 0.7268 - recall: 0.9232 - val_accuracy: 0.7904 - val_f1_score: 0.8349 - val_loss: 0.4342 - val_precision: 0.7394 - val_recall: 0.9586\n",
      "Epoch 28/100\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 193ms/step - accuracy: 0.7831 - f1_score: 0.8290 - loss: 0.4420 - precision: 0.7416 - recall: 0.9401 - val_accuracy: 0.7979 - val_f1_score: 0.8289 - val_loss: 0.4324 - val_precision: 0.7791 - val_recall: 0.8855\n",
      "Epoch 29/100\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 201ms/step - accuracy: 0.8051 - f1_score: 0.8400 - loss: 0.4145 - precision: 0.7697 - recall: 0.9248 - val_accuracy: 0.8023 - val_f1_score: 0.8434 - val_loss: 0.4095 - val_precision: 0.7501 - val_recall: 0.9632\n",
      "Epoch 30/100\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 234ms/step - accuracy: 0.7950 - f1_score: 0.8356 - loss: 0.4357 - precision: 0.7554 - recall: 0.9352 - val_accuracy: 0.7920 - val_f1_score: 0.8228 - val_loss: 0.4343 - val_precision: 0.7772 - val_recall: 0.8741\n",
      "Epoch 31/100\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 378ms/step - accuracy: 0.8054 - f1_score: 0.8405 - loss: 0.4241 - precision: 0.7700 - recall: 0.9258 - val_accuracy: 0.8205 - val_f1_score: 0.8561 - val_loss: 0.3843 - val_precision: 0.7686 - val_recall: 0.9660\n",
      "Epoch 32/100\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 320ms/step - accuracy: 0.8083 - f1_score: 0.8417 - loss: 0.4091 - precision: 0.7700 - recall: 0.9283 - val_accuracy: 0.8205 - val_f1_score: 0.8542 - val_loss: 0.3872 - val_precision: 0.7748 - val_recall: 0.9518\n",
      "Epoch 33/100\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 366ms/step - accuracy: 0.8108 - f1_score: 0.8467 - loss: 0.4056 - precision: 0.7680 - recall: 0.9435 - val_accuracy: 0.8189 - val_f1_score: 0.8469 - val_loss: 0.3964 - val_precision: 0.7947 - val_recall: 0.9065\n",
      "Epoch 34/100\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 229ms/step - accuracy: 0.8012 - f1_score: 0.8413 - loss: 0.4415 - precision: 0.7620 - recall: 0.9396 - val_accuracy: 0.8305 - val_f1_score: 0.8588 - val_loss: 0.3804 - val_precision: 0.7958 - val_recall: 0.9325\n",
      "Epoch 35/100\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 169ms/step - accuracy: 0.8304 - f1_score: 0.8609 - loss: 0.3773 - precision: 0.7959 - recall: 0.9381 - val_accuracy: 0.8456 - val_f1_score: 0.8655 - val_loss: 0.3440 - val_precision: 0.8343 - val_recall: 0.8991\n",
      "Epoch 36/100\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 173ms/step - accuracy: 0.8482 - f1_score: 0.8731 - loss: 0.3504 - precision: 0.8218 - recall: 0.9321 - val_accuracy: 0.8280 - val_f1_score: 0.8420 - val_loss: 0.3688 - val_precision: 0.8551 - val_recall: 0.8294\n",
      "Epoch 37/100\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 178ms/step - accuracy: 0.8307 - f1_score: 0.8544 - loss: 0.3908 - precision: 0.8054 - recall: 0.9109 - val_accuracy: 0.8462 - val_f1_score: 0.8764 - val_loss: 0.3439 - val_precision: 0.7884 - val_recall: 0.9864\n",
      "Epoch 38/100\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 184ms/step - accuracy: 0.8376 - f1_score: 0.8645 - loss: 0.3590 - precision: 0.8029 - recall: 0.9366 - val_accuracy: 0.8650 - val_f1_score: 0.8859 - val_loss: 0.3110 - val_precision: 0.8311 - val_recall: 0.9484\n",
      "Epoch 39/100\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 177ms/step - accuracy: 0.8371 - f1_score: 0.8615 - loss: 0.3636 - precision: 0.8007 - recall: 0.9325 - val_accuracy: 0.8311 - val_f1_score: 0.8472 - val_loss: 0.3703 - val_precision: 0.8474 - val_recall: 0.8469\n",
      "Epoch 40/100\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 208ms/step - accuracy: 0.8479 - f1_score: 0.8685 - loss: 0.3640 - precision: 0.8218 - recall: 0.9212 - val_accuracy: 0.8434 - val_f1_score: 0.8734 - val_loss: 0.3396 - val_precision: 0.7891 - val_recall: 0.9779\n",
      "Epoch 41/100\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 396ms/step - accuracy: 0.8397 - f1_score: 0.8663 - loss: 0.3580 - precision: 0.8079 - recall: 0.9340 - val_accuracy: 0.8575 - val_f1_score: 0.8820 - val_loss: 0.3266 - val_precision: 0.8130 - val_recall: 0.9637\n",
      "Epoch 42/100\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 411ms/step - accuracy: 0.8613 - f1_score: 0.8817 - loss: 0.3289 - precision: 0.8340 - recall: 0.9355 - val_accuracy: 0.8672 - val_f1_score: 0.8862 - val_loss: 0.3117 - val_precision: 0.8415 - val_recall: 0.9359\n",
      "Epoch 43/100\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m47s\u001b[0m 471ms/step - accuracy: 0.8615 - f1_score: 0.8824 - loss: 0.3139 - precision: 0.8425 - recall: 0.9268 - val_accuracy: 0.8734 - val_f1_score: 0.8917 - val_loss: 0.3013 - val_precision: 0.8459 - val_recall: 0.9427\n",
      "Epoch 44/100\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m44s\u001b[0m 438ms/step - accuracy: 0.8339 - f1_score: 0.8579 - loss: 0.3634 - precision: 0.8109 - recall: 0.9111 - val_accuracy: 0.8596 - val_f1_score: 0.8774 - val_loss: 0.3290 - val_precision: 0.8481 - val_recall: 0.9087\n",
      "Epoch 45/100\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 407ms/step - accuracy: 0.8574 - f1_score: 0.8725 - loss: 0.3317 - precision: 0.8236 - recall: 0.9280 - val_accuracy: 0.8725 - val_f1_score: 0.8911 - val_loss: 0.3048 - val_precision: 0.8435 - val_recall: 0.9444\n",
      "Epoch 46/100\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 425ms/step - accuracy: 0.8696 - f1_score: 0.8900 - loss: 0.3031 - precision: 0.8539 - recall: 0.9295 - val_accuracy: 0.8622 - val_f1_score: 0.8855 - val_loss: 0.3226 - val_precision: 0.8186 - val_recall: 0.9643\n",
      "Epoch 47/100\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 410ms/step - accuracy: 0.8659 - f1_score: 0.8859 - loss: 0.3204 - precision: 0.8411 - recall: 0.9359 - val_accuracy: 0.8675 - val_f1_score: 0.8831 - val_loss: 0.3098 - val_precision: 0.8618 - val_recall: 0.9053\n",
      "Epoch 48/100\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 383ms/step - accuracy: 0.8706 - f1_score: 0.8890 - loss: 0.3096 - precision: 0.8490 - recall: 0.9332 - val_accuracy: 0.8540 - val_f1_score: 0.8813 - val_loss: 0.3304 - val_precision: 0.8002 - val_recall: 0.9807\n",
      "Epoch 49/100\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 340ms/step - accuracy: 0.8702 - f1_score: 0.8908 - loss: 0.3101 - precision: 0.8368 - recall: 0.9525 - val_accuracy: 0.8640 - val_f1_score: 0.8835 - val_loss: 0.3218 - val_precision: 0.8393 - val_recall: 0.9325\n",
      "Epoch 50/100\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 170ms/step - accuracy: 0.8720 - f1_score: 0.8924 - loss: 0.3046 - precision: 0.8410 - recall: 0.9505 - val_accuracy: 0.8966 - val_f1_score: 0.9111 - val_loss: 0.2515 - val_precision: 0.8681 - val_recall: 0.9586\n",
      "Epoch 51/100\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 167ms/step - accuracy: 0.8834 - f1_score: 0.9000 - loss: 0.2794 - precision: 0.8468 - recall: 0.9610 - val_accuracy: 0.9007 - val_f1_score: 0.9153 - val_loss: 0.2385 - val_precision: 0.8656 - val_recall: 0.9711\n",
      "Epoch 52/100\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 182ms/step - accuracy: 0.8931 - f1_score: 0.9102 - loss: 0.2669 - precision: 0.8706 - recall: 0.9536 - val_accuracy: 0.8816 - val_f1_score: 0.9009 - val_loss: 0.2803 - val_precision: 0.8377 - val_recall: 0.9745\n",
      "Epoch 53/100\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 189ms/step - accuracy: 0.8785 - f1_score: 0.8945 - loss: 0.2742 - precision: 0.8487 - recall: 0.9458 - val_accuracy: 0.9095 - val_f1_score: 0.9211 - val_loss: 0.2245 - val_precision: 0.8884 - val_recall: 0.9563\n",
      "Epoch 54/100\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 187ms/step - accuracy: 0.9049 - f1_score: 0.9170 - loss: 0.2407 - precision: 0.8785 - recall: 0.9591 - val_accuracy: 0.8994 - val_f1_score: 0.9105 - val_loss: 0.2441 - val_precision: 0.8962 - val_recall: 0.9252\n",
      "Epoch 55/100\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 186ms/step - accuracy: 0.8952 - f1_score: 0.9067 - loss: 0.2591 - precision: 0.8665 - recall: 0.9508 - val_accuracy: 0.9104 - val_f1_score: 0.9213 - val_loss: 0.2222 - val_precision: 0.8956 - val_recall: 0.9484\n",
      "Epoch 56/100\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 209ms/step - accuracy: 0.9044 - f1_score: 0.9172 - loss: 0.2577 - precision: 0.8859 - recall: 0.9511 - val_accuracy: 0.9048 - val_f1_score: 0.9148 - val_loss: 0.2330 - val_precision: 0.9051 - val_recall: 0.9246\n",
      "Epoch 57/100\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 219ms/step - accuracy: 0.9021 - f1_score: 0.9155 - loss: 0.2398 - precision: 0.8808 - recall: 0.9532 - val_accuracy: 0.8991 - val_f1_score: 0.9106 - val_loss: 0.2390 - val_precision: 0.8927 - val_recall: 0.9291\n",
      "Epoch 58/100\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 217ms/step - accuracy: 0.8998 - f1_score: 0.9128 - loss: 0.2492 - precision: 0.8833 - recall: 0.9444 - val_accuracy: 0.9236 - val_f1_score: 0.9333 - val_loss: 0.1947 - val_precision: 0.9013 - val_recall: 0.9677\n",
      "Epoch 59/100\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 218ms/step - accuracy: 0.9108 - f1_score: 0.9202 - loss: 0.2197 - precision: 0.8848 - recall: 0.9587 - val_accuracy: 0.8907 - val_f1_score: 0.9068 - val_loss: 0.2583 - val_precision: 0.8571 - val_recall: 0.9626\n",
      "Epoch 60/100\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 206ms/step - accuracy: 0.8973 - f1_score: 0.9141 - loss: 0.2413 - precision: 0.8678 - recall: 0.9658 - val_accuracy: 0.9057 - val_f1_score: 0.9185 - val_loss: 0.2551 - val_precision: 0.8796 - val_recall: 0.9609\n",
      "Epoch 61/100\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 198ms/step - accuracy: 0.9084 - f1_score: 0.9217 - loss: 0.2290 - precision: 0.8887 - recall: 0.9573 - val_accuracy: 0.9245 - val_f1_score: 0.9341 - val_loss: 0.1899 - val_precision: 0.9023 - val_recall: 0.9683\n",
      "Epoch 62/100\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 218ms/step - accuracy: 0.8897 - f1_score: 0.9029 - loss: 0.2558 - precision: 0.8620 - recall: 0.9480 - val_accuracy: 0.9314 - val_f1_score: 0.9397 - val_loss: 0.1736 - val_precision: 0.9138 - val_recall: 0.9671\n",
      "Epoch 63/100\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 211ms/step - accuracy: 0.9164 - f1_score: 0.9248 - loss: 0.2089 - precision: 0.8977 - recall: 0.9537 - val_accuracy: 0.8957 - val_f1_score: 0.9109 - val_loss: 0.2728 - val_precision: 0.8623 - val_recall: 0.9654\n",
      "Epoch 64/100\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 236ms/step - accuracy: 0.8984 - f1_score: 0.9099 - loss: 0.2648 - precision: 0.8749 - recall: 0.9480 - val_accuracy: 0.9054 - val_f1_score: 0.9203 - val_loss: 0.2271 - val_precision: 0.8612 - val_recall: 0.9881\n",
      "Epoch 65/100\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 405ms/step - accuracy: 0.9092 - f1_score: 0.9216 - loss: 0.2262 - precision: 0.8847 - recall: 0.9621 - val_accuracy: 0.9104 - val_f1_score: 0.9247 - val_loss: 0.2070 - val_precision: 0.8630 - val_recall: 0.9960\n",
      "Epoch 66/100\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 170ms/step - accuracy: 0.9119 - f1_score: 0.9229 - loss: 0.2170 - precision: 0.8879 - recall: 0.9608 - val_accuracy: 0.9298 - val_f1_score: 0.9388 - val_loss: 0.1831 - val_precision: 0.9057 - val_recall: 0.9745\n",
      "Epoch 67/100\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 171ms/step - accuracy: 0.9260 - f1_score: 0.9340 - loss: 0.1987 - precision: 0.9099 - recall: 0.9597 - val_accuracy: 0.9283 - val_f1_score: 0.9359 - val_loss: 0.1850 - val_precision: 0.9247 - val_recall: 0.9473\n",
      "Epoch 68/100\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 186ms/step - accuracy: 0.8961 - f1_score: 0.9106 - loss: 0.2601 - precision: 0.8797 - recall: 0.9438 - val_accuracy: 0.9386 - val_f1_score: 0.9467 - val_loss: 0.1619 - val_precision: 0.9105 - val_recall: 0.9858\n",
      "Epoch 69/100\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 198ms/step - accuracy: 0.9283 - f1_score: 0.9376 - loss: 0.1887 - precision: 0.9042 - recall: 0.9738 - val_accuracy: 0.9330 - val_f1_score: 0.9416 - val_loss: 0.1787 - val_precision: 0.9083 - val_recall: 0.9773\n",
      "Epoch 70/100\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 196ms/step - accuracy: 0.9179 - f1_score: 0.9275 - loss: 0.2021 - precision: 0.9019 - recall: 0.9546 - val_accuracy: 0.9076 - val_f1_score: 0.9165 - val_loss: 0.2382 - val_precision: 0.9152 - val_recall: 0.9178\n",
      "Epoch 71/100\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 185ms/step - accuracy: 0.9174 - f1_score: 0.9273 - loss: 0.1953 - precision: 0.8938 - recall: 0.9636 - val_accuracy: 0.9342 - val_f1_score: 0.9433 - val_loss: 0.1695 - val_precision: 0.9009 - val_recall: 0.9898\n",
      "Epoch 72/100\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 206ms/step - accuracy: 0.9333 - f1_score: 0.9404 - loss: 0.1685 - precision: 0.9113 - recall: 0.9715 - val_accuracy: 0.9383 - val_f1_score: 0.9465 - val_loss: 0.1555 - val_precision: 0.9091 - val_recall: 0.9870\n",
      "Epoch 73/100\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 201ms/step - accuracy: 0.9213 - f1_score: 0.9296 - loss: 0.1994 - precision: 0.8955 - recall: 0.9666 - val_accuracy: 0.8853 - val_f1_score: 0.9045 - val_loss: 0.3110 - val_precision: 0.8380 - val_recall: 0.9824\n",
      "Epoch 74/100\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 204ms/step - accuracy: 0.8371 - f1_score: 0.8553 - loss: 0.3995 - precision: 0.8156 - recall: 0.9005 - val_accuracy: 0.9051 - val_f1_score: 0.9200 - val_loss: 0.2218 - val_precision: 0.8607 - val_recall: 0.9881\n",
      "Epoch 75/100\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 216ms/step - accuracy: 0.9098 - f1_score: 0.9196 - loss: 0.2380 - precision: 0.8815 - recall: 0.9614 - val_accuracy: 0.9295 - val_f1_score: 0.9380 - val_loss: 0.1937 - val_precision: 0.9130 - val_recall: 0.9643\n",
      "Epoch 76/100\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 218ms/step - accuracy: 0.9327 - f1_score: 0.9388 - loss: 0.1788 - precision: 0.9176 - recall: 0.9612 - val_accuracy: 0.9301 - val_f1_score: 0.9401 - val_loss: 0.1829 - val_precision: 0.8929 - val_recall: 0.9926\n",
      "Epoch 77/100\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 247ms/step - accuracy: 0.9219 - f1_score: 0.9310 - loss: 0.1987 - precision: 0.8971 - recall: 0.9684 - val_accuracy: 0.9364 - val_f1_score: 0.9434 - val_loss: 0.1682 - val_precision: 0.9281 - val_recall: 0.9592\n",
      "Epoch 78/100\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 209ms/step - accuracy: 0.9227 - f1_score: 0.9316 - loss: 0.2051 - precision: 0.9060 - recall: 0.9588 - val_accuracy: 0.9126 - val_f1_score: 0.9236 - val_loss: 0.2362 - val_precision: 0.8931 - val_recall: 0.9563\n",
      "Epoch 79/100\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 206ms/step - accuracy: 0.9056 - f1_score: 0.9168 - loss: 0.2325 - precision: 0.8862 - recall: 0.9496 - val_accuracy: 0.9276 - val_f1_score: 0.9360 - val_loss: 0.1709 - val_precision: 0.9150 - val_recall: 0.9580\n",
      "Epoch 80/100\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 211ms/step - accuracy: 0.9056 - f1_score: 0.9168 - loss: 0.2357 - precision: 0.8835 - recall: 0.9528 - val_accuracy: 0.9201 - val_f1_score: 0.9296 - val_loss: 0.1902 - val_precision: 0.9063 - val_recall: 0.9541\n",
      "Epoch 81/100\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 189ms/step - accuracy: 0.9085 - f1_score: 0.9209 - loss: 0.2239 - precision: 0.8966 - recall: 0.9467 - val_accuracy: 0.9442 - val_f1_score: 0.9503 - val_loss: 0.1408 - val_precision: 0.9372 - val_recall: 0.9637\n",
      "Epoch 82/100\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 184ms/step - accuracy: 0.9413 - f1_score: 0.9489 - loss: 0.1507 - precision: 0.9253 - recall: 0.9739 - val_accuracy: 0.9348 - val_f1_score: 0.9407 - val_loss: 0.1671 - val_precision: 0.9456 - val_recall: 0.9359\n",
      "Epoch 83/100\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 185ms/step - accuracy: 0.9392 - f1_score: 0.9447 - loss: 0.1674 - precision: 0.9256 - recall: 0.9647 - val_accuracy: 0.9301 - val_f1_score: 0.9383 - val_loss: 0.1840 - val_precision: 0.9163 - val_recall: 0.9615\n",
      "Epoch 84/100\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 192ms/step - accuracy: 0.9427 - f1_score: 0.9503 - loss: 0.1492 - precision: 0.9283 - recall: 0.9734 - val_accuracy: 0.9373 - val_f1_score: 0.9424 - val_loss: 0.1722 - val_precision: 0.9573 - val_recall: 0.9280\n",
      "Epoch 85/100\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 212ms/step - accuracy: 0.9358 - f1_score: 0.9433 - loss: 0.1588 - precision: 0.9275 - recall: 0.9600 - val_accuracy: 0.8703 - val_f1_score: 0.8927 - val_loss: 0.3121 - val_precision: 0.8223 - val_recall: 0.9762\n",
      "Epoch 86/100\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 230ms/step - accuracy: 0.8727 - f1_score: 0.8960 - loss: 0.3409 - precision: 0.8467 - recall: 0.9519 - val_accuracy: 0.9389 - val_f1_score: 0.9458 - val_loss: 0.1576 - val_precision: 0.9275 - val_recall: 0.9649\n",
      "Epoch 87/100\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 225ms/step - accuracy: 0.9251 - f1_score: 0.9351 - loss: 0.2024 - precision: 0.9068 - recall: 0.9652 - val_accuracy: 0.9317 - val_f1_score: 0.9412 - val_loss: 0.1763 - val_precision: 0.8976 - val_recall: 0.9892\n",
      "Epoch 88/100\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 203ms/step - accuracy: 0.9392 - f1_score: 0.9471 - loss: 0.1609 - precision: 0.9220 - recall: 0.9739 - val_accuracy: 0.9355 - val_f1_score: 0.9443 - val_loss: 0.1646 - val_precision: 0.9028 - val_recall: 0.9898\n",
      "Epoch 89/100\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 256ms/step - accuracy: 0.9365 - f1_score: 0.9449 - loss: 0.1640 - precision: 0.9118 - recall: 0.9805 - val_accuracy: 0.9405 - val_f1_score: 0.9471 - val_loss: 0.1462 - val_precision: 0.9310 - val_recall: 0.9637\n",
      "Epoch 90/100\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 266ms/step - accuracy: 0.9428 - f1_score: 0.9485 - loss: 0.1539 - precision: 0.9229 - recall: 0.9757 - val_accuracy: 0.9305 - val_f1_score: 0.9398 - val_loss: 0.1749 - val_precision: 0.9003 - val_recall: 0.9830\n",
      "Epoch 91/100\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 231ms/step - accuracy: 0.9399 - f1_score: 0.9480 - loss: 0.1535 - precision: 0.9246 - recall: 0.9728 - val_accuracy: 0.9480 - val_f1_score: 0.9529 - val_loss: 0.1458 - val_precision: 0.9535 - val_recall: 0.9524\n",
      "Epoch 92/100\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 214ms/step - accuracy: 0.9112 - f1_score: 0.9215 - loss: 0.2286 - precision: 0.8920 - recall: 0.9533 - val_accuracy: 0.9489 - val_f1_score: 0.9550 - val_loss: 0.1348 - val_precision: 0.9301 - val_recall: 0.9813\n",
      "Epoch 93/100\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 209ms/step - accuracy: 0.9490 - f1_score: 0.9550 - loss: 0.1455 - precision: 0.9335 - recall: 0.9775 - val_accuracy: 0.8716 - val_f1_score: 0.8944 - val_loss: 0.3194 - val_precision: 0.8196 - val_recall: 0.9841\n",
      "Epoch 94/100\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 212ms/step - accuracy: 0.9140 - f1_score: 0.9264 - loss: 0.2161 - precision: 0.8892 - recall: 0.9672 - val_accuracy: 0.9273 - val_f1_score: 0.9372 - val_loss: 0.1791 - val_precision: 0.8969 - val_recall: 0.9813\n",
      "Epoch 95/100\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 211ms/step - accuracy: 0.9137 - f1_score: 0.9244 - loss: 0.2097 - precision: 0.8905 - recall: 0.9612 - val_accuracy: 0.9298 - val_f1_score: 0.9398 - val_loss: 0.1779 - val_precision: 0.8933 - val_recall: 0.9915\n",
      "Epoch 96/100\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 211ms/step - accuracy: 0.9372 - f1_score: 0.9469 - loss: 0.1650 - precision: 0.9143 - recall: 0.9820 - val_accuracy: 0.9424 - val_f1_score: 0.9495 - val_loss: 0.1384 - val_precision: 0.9207 - val_recall: 0.9802\n",
      "Epoch 97/100\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 211ms/step - accuracy: 0.9348 - f1_score: 0.9421 - loss: 0.1679 - precision: 0.9195 - recall: 0.9659 - val_accuracy: 0.9499 - val_f1_score: 0.9560 - val_loss: 0.1225 - val_precision: 0.9284 - val_recall: 0.9853\n",
      "Epoch 98/100\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 208ms/step - accuracy: 0.9490 - f1_score: 0.9558 - loss: 0.1409 - precision: 0.9274 - recall: 0.9860 - val_accuracy: 0.9568 - val_f1_score: 0.9621 - val_loss: 0.1124 - val_precision: 0.9324 - val_recall: 0.9938\n",
      "Epoch 99/100\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 218ms/step - accuracy: 0.9482 - f1_score: 0.9546 - loss: 0.1337 - precision: 0.9296 - recall: 0.9810 - val_accuracy: 0.9552 - val_f1_score: 0.9605 - val_loss: 0.1273 - val_precision: 0.9360 - val_recall: 0.9864\n",
      "Epoch 100/100\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 230ms/step - accuracy: 0.9480 - f1_score: 0.9545 - loss: 0.1325 - precision: 0.9306 - recall: 0.9798 - val_accuracy: 0.9433 - val_f1_score: 0.9502 - val_loss: 0.1499 - val_precision: 0.9239 - val_recall: 0.9779\n"
     ]
    }
   ],
   "source": [
    "# Train the model\n",
    "history = model.fit(\n",
    "    training_set,\n",
    "    validation_data=test_set,\n",
    "    epochs=100,  # Adjust as needed\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a20401a2-db02-4a0a-8baf-7c2836bd6119",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save Loss plot\n",
    "plt.figure()\n",
    "plt.plot(history.history['loss'], label='Train Loss')\n",
    "plt.plot(history.history['val_loss'], label='Validation Loss')\n",
    "plt.legend()\n",
    "plt.title(\"Loss\")\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.savefig('loss_plot_cnn_bgru_sa.png')  # Save the plot as a PNG file\n",
    "plt.close()\n",
    "\n",
    "# Save Accuracy plot\n",
    "plt.figure()\n",
    "plt.plot(history.history['accuracy'], label='Train Accuracy')\n",
    "plt.plot(history.history['val_accuracy'], label='Validation Accuracy')\n",
    "plt.legend()\n",
    "plt.title(\"Accuracy\")\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.savefig('accuracy_plot_cnn_bgru_sa.png')  # Save the plot as a PNG file\n",
    "plt.close()\n",
    "\n",
    "# Save Precision plot (custom metric)\n",
    "plt.figure()\n",
    "plt.plot(history.history['precision'], label='Train Precision')\n",
    "plt.plot(history.history['val_precision'], label='Validation Precision')\n",
    "plt.legend()\n",
    "plt.title(\"Precision\")\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Precision')\n",
    "plt.savefig('precision_plot_cnn_bgru_sa.png')  # Save the plot as a PNG file\n",
    "plt.close()\n",
    "\n",
    "# Save Recall plot (custom metric)\n",
    "plt.figure()\n",
    "plt.plot(history.history['recall'], label='Train Recall')\n",
    "plt.plot(history.history['val_recall'], label='Validation Recall')\n",
    "plt.legend()\n",
    "plt.title(\"Recall\")\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Recall')\n",
    "plt.savefig('recall_plot_cnn_bgru_sa.png')  # Save the plot as a PNG file\n",
    "plt.close()\n",
    "\n",
    "# Save F1-Score plot (custom metric)\n",
    "plt.figure()\n",
    "plt.plot(history.history['f1_score'], label='Train F1 Score')\n",
    "plt.plot(history.history['val_f1_score'], label='Validation F1 Score')\n",
    "plt.legend()\n",
    "plt.title(\"F1 Score\")\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('F1 Score')\n",
    "plt.savefig('f1_score_plot_cnn_bgru_sa.png')  # Save the plot as a PNG file\n",
    "plt.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "0e92b27f-e5fb-43b6-b361-3c93fefd6cd8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 56ms/step\n",
      "Classification Report:\n",
      "                      precision    recall  f1-score   support\n",
      "\n",
      "Monkeypox_augmented       0.42      0.39      0.40      1428\n",
      "   Others_augmented       0.53      0.56      0.55      1764\n",
      "\n",
      "           accuracy                           0.49      3192\n",
      "          macro avg       0.48      0.48      0.48      3192\n",
      "       weighted avg       0.48      0.49      0.48      3192\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import seaborn as sns\n",
    "from sklearn.metrics import confusion_matrix, classification_report, roc_curve, auc, RocCurveDisplay\n",
    "\n",
    "# ----------- Get predictions -----------\n",
    "# Get true labels and predicted probabilities\n",
    "test_set.reset()  # Important to reset the generator\n",
    "Y_true = test_set.classes  # True labels\n",
    "Y_pred_prob = model.predict(test_set)\n",
    "Y_pred = (Y_pred_prob >= 0.5).astype(int).flatten()  # Convert probabilities to binary predictions\n",
    "\n",
    "# ----------- Confusion Matrix -----------\n",
    "cm = confusion_matrix(Y_true, Y_pred)\n",
    "plt.figure(figsize=(6,5))\n",
    "sns.heatmap(cm, annot=True, fmt=\"d\", cmap=\"Blues\")\n",
    "plt.title(\"Confusion Matrix\")\n",
    "plt.xlabel(\"Predicted\")\n",
    "plt.ylabel(\"Actual\")\n",
    "plt.savefig('confusion_matrix_cnn_bgru_sa.png')\n",
    "plt.close()\n",
    "\n",
    "# ----------- Classification Report (Precision, Recall, F1) -----------\n",
    "report = classification_report(Y_true, Y_pred, target_names=list(test_set.class_indices.keys()))\n",
    "print(\"Classification Report:\\n\", report)\n",
    "\n",
    "# ----------- AUC - ROC Curve -----------\n",
    "fpr, tpr, thresholds = roc_curve(Y_true, Y_pred_prob)\n",
    "roc_auc = auc(fpr, tpr)\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(fpr, tpr, color='darkorange', lw=2, label=f'ROC curve (AUC = {roc_auc:.4f})')\n",
    "plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('Receiver Operating Characteristic (ROC)')\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.savefig('roc_auc_curve_cnn_bgru_sa.png')\n",
    "plt.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d2bb7a45-3615-4d9d-a58b-56d866082f44",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    }
   ],
   "source": [
    "# Save the trained model\n",
    "model.save(\"monkeypox_cnn_bgru_sa.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "92af508f-96db-47d6-96ac-e4852099b6b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing import image\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "cdd2b82f-824b-46bd-8fdf-1bd39cbddd48",
   "metadata": {},
   "outputs": [],
   "source": [
    "img_path = \"C:/Users/KIIT/Music/Monkeypox/Kaggle MP images/archive (2)/Augmented Images/Augmented Images/Monkeypox_augmented/M01_01_02.jpg\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "2431e733-a915-42ef-9018-e4086bee4446",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load and preprocess the image\n",
    "img = image.load_img(img_path, target_size=(64, 64))  # Resize to match model input size\n",
    "img_array = image.img_to_array(img) / 255.0  # Normalize pixel values\n",
    "img_array = np.expand_dims(img_array, axis=0)  # Add batch dimension"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "f2d28f92-6e5e-4146-8116-4078f5032d77",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step\n"
     ]
    }
   ],
   "source": [
    "# Make prediction\n",
    "prediction = model.predict(img_array)\n",
    "predicted_class = prediction[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "641491a9-c199-4665-bc70-3c4de372cd59",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.00091102475"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predicted_class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "3b35c7ca-6e43-4942-b27d-b48d0be1fce7",
   "metadata": {},
   "outputs": [],
   "source": [
    "img_path = \"C:/Users/KIIT/Music/Monkeypox/Kaggle MP images/archive (2)/Augmented Images/Augmented Images/Others_augmented/NM01_01_00.jpg\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "a5fea4e3-c44d-4f22-9991-1ffd1e1f2598",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The image C:/Users/KIIT/Music/Monkeypox/Kaggle MP images/archive (2)/Augmented Images/Augmented Images/Others_augmented/NM01_01_00.jpg is classified as Monkeypox Negative.\n"
     ]
    }
   ],
   "source": [
    "# Set a decision threshold\n",
    "threshold = 0.5  # Adjust if needed based on model performance\n",
    "\n",
    "# Output the result\n",
    "if predicted_class < threshold:\n",
    "    print(f\"The image {img_path} is classified as Monkeypox Positive.\")\n",
    "else:\n",
    "    print(f\"The image {img_path} is classified as Monkeypox Negative.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "56acafc7-2b10-4557-bb8d-5e16b510d761",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(\"monkeypox_cnn_bgru_sa.keras\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91f6313d-0b0c-45c7-839a-96532901d1ff",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "17d73391-a77d-400b-8ff6-bf4302cfad08",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.models import Sequential\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "886ab1ca-facb-4828-a2ab-463e25bf0d66",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Custom Self-Attention Layer\n",
    "class SelfAttention(layers.Layer):\n",
    "    def __init__(self, channels, **kwargs):\n",
    "        super(SelfAttention, self).__init__(**kwargs)\n",
    "        self.channels = channels\n",
    "        self.attention_dense = layers.Dense(channels, activation='sigmoid')\n",
    "\n",
    "    def call(self, inputs):\n",
    "        attention_weights = self.attention_dense(inputs)\n",
    "        return inputs * attention_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "aa9b341b-e431-4020-8db5-d5d7a1021a54",
   "metadata": {},
   "outputs": [],
   "source": [
    "class F1Score(tf.keras.metrics.Metric):\n",
    "    def __init__(self, name='f1_score', **kwargs):\n",
    "        super(F1Score, self).__init__(name=name, **kwargs)\n",
    "        self.precision = tf.keras.metrics.Precision()\n",
    "        self.recall = tf.keras.metrics.Recall()\n",
    "\n",
    "    def update_state(self, y_true, y_pred, sample_weight=None):\n",
    "        # Update the precision and recall for each batch\n",
    "        self.precision.update_state(y_true, y_pred, sample_weight)\n",
    "        self.recall.update_state(y_true, y_pred, sample_weight)\n",
    "\n",
    "    def result(self):\n",
    "        # Calculate F1 score as the harmonic mean of precision and recall\n",
    "        precision = self.precision.result()\n",
    "        recall = self.recall.result()\n",
    "        return 2 * (precision * recall) / (precision + recall + tf.keras.backend.epsilon())\n",
    "\n",
    "    def reset_states(self):\n",
    "        self.precision.reset_states()\n",
    "        self.recall.reset_states()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5ff30fe7-801c-4db2-be94-a7e90dcedb19",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 7532 images belonging to 6 classes.\n"
     ]
    }
   ],
   "source": [
    "# Data preparation (same as in your code)\n",
    "train_datagen = ImageDataGenerator(rescale=1./255)\n",
    "training_set1 = train_datagen.flow_from_directory(\n",
    "    \"Monkeypox/archive (60)/Augmented Images/Augmented Images/FOLDS_AUG/fold3_AUG/Train/\",\n",
    "    target_size=(64, 64),\n",
    "    batch_size=32,\n",
    "    class_mode='categorical',  # Use 'sparse' if your labels are integers (not one-hot encoded)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f13ecb83-5a4b-48d2-ba11-d33f2895824e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 7532 images belonging to 6 classes.\n"
     ]
    }
   ],
   "source": [
    "test_datagen = ImageDataGenerator(rescale=1./255)\n",
    "test_set1 = test_datagen.flow_from_directory(\n",
    "    \"Monkeypox/archive (60)/Augmented Images/Augmented Images/FOLDS_AUG/fold3_AUG/Train/\",\n",
    "    target_size=(64, 64),\n",
    "    batch_size=32,\n",
    "    class_mode='categorical',\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "85531386-56a5-41c3-93c2-44107901d1dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CNN model with Self-Attention and Bidirectional GRU\n",
    "cnn = Sequential()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "81794390-77b2-4043-bb33-3986f028d9bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\KIIT\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\layers\\convolutional\\base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\KIIT\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\backend\\tensorflow\\core.py:204: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "cnn.add(layers.Conv2D(filters=32, padding=\"same\", kernel_size=3, activation='relu', strides=2, input_shape=[64, 64, 3]))\n",
    "cnn.add(SelfAttention(channels=32))\n",
    "cnn.add(layers.MaxPool2D(pool_size=2, strides=2))\n",
    "\n",
    "cnn.add(layers.Conv2D(filters=32, padding='same', kernel_size=3, activation='relu'))\n",
    "cnn.add(layers.MaxPool2D(pool_size=2, strides=2))\n",
    "\n",
    "# Ensure the correct reshaping before GRU\n",
    "cnn.add(layers.Reshape((-1, 32)))  # Reshape for GRU (batch_size, time_steps, features)\n",
    "\n",
    "# Bidirectional GRU layer\n",
    "cnn.add(layers.Bidirectional(layers.GRU(64, return_sequences=True)))\n",
    "\n",
    "cnn.add(layers.Flatten())\n",
    "cnn.add(layers.Dense(units=128, activation='relu'))\n",
    "cnn.add(layers.Dense(6, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1ab02bd0-5f01-400d-9e6c-48dede5ce9e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile the model with Precision, Recall, and custom F1 score\n",
    "cnn.compile(\n",
    "    optimizer='adam', \n",
    "    loss='categorical_crossentropy', \n",
    "    metrics=['accuracy', 'Precision', 'Recall', F1Score()]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "96486a9c-74b1-4c83-9a92-b6ee5b7279a0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                         </span>┃<span style=\"font-weight: bold\"> Output Shape                </span>┃<span style=\"font-weight: bold\">         Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
       "│ conv2d (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)          │             <span style=\"color: #00af00; text-decoration-color: #00af00\">896</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ self_attention (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">SelfAttention</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)          │           <span style=\"color: #00af00; text-decoration-color: #00af00\">1,056</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ max_pooling2d (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)          │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ conv2d_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)          │           <span style=\"color: #00af00; text-decoration-color: #00af00\">9,248</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ max_pooling2d_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)            │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ reshape (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Reshape</span>)                    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)              │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ bidirectional (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Bidirectional</span>)        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)             │          <span style=\"color: #00af00; text-decoration-color: #00af00\">37,632</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ flatten (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)                    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8192</span>)                │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)                 │       <span style=\"color: #00af00; text-decoration-color: #00af00\">1,048,704</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">6</span>)                   │             <span style=\"color: #00af00; text-decoration-color: #00af00\">774</span> │\n",
       "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
       "│ conv2d (\u001b[38;5;33mConv2D\u001b[0m)                      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m)          │             \u001b[38;5;34m896\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ self_attention (\u001b[38;5;33mSelfAttention\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m)          │           \u001b[38;5;34m1,056\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ max_pooling2d (\u001b[38;5;33mMaxPooling2D\u001b[0m)         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m32\u001b[0m)          │               \u001b[38;5;34m0\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ conv2d_1 (\u001b[38;5;33mConv2D\u001b[0m)                    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m32\u001b[0m)          │           \u001b[38;5;34m9,248\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ max_pooling2d_1 (\u001b[38;5;33mMaxPooling2D\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m32\u001b[0m)            │               \u001b[38;5;34m0\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ reshape (\u001b[38;5;33mReshape\u001b[0m)                    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m32\u001b[0m)              │               \u001b[38;5;34m0\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ bidirectional (\u001b[38;5;33mBidirectional\u001b[0m)        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m128\u001b[0m)             │          \u001b[38;5;34m37,632\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ flatten (\u001b[38;5;33mFlatten\u001b[0m)                    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8192\u001b[0m)                │               \u001b[38;5;34m0\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)                      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)                 │       \u001b[38;5;34m1,048,704\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_2 (\u001b[38;5;33mDense\u001b[0m)                      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m6\u001b[0m)                   │             \u001b[38;5;34m774\u001b[0m │\n",
       "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,098,310</span> (4.19 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m1,098,310\u001b[0m (4.19 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,098,310</span> (4.19 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m1,098,310\u001b[0m (4.19 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Model summary\n",
    "cnn.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b8d2fd52-12c0-4b65-8539-d343a420c479",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\KIIT\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\trainers\\data_adapters\\py_dataset_adapter.py:121: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
      "  self._warn_if_super_not_called()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "\u001b[1m236/236\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m182s\u001b[0m 685ms/step - Precision: 0.4449 - Recall: 0.0675 - accuracy: 0.4026 - f1_score: 0.1151 - loss: 1.5809 - val_Precision: 0.7131 - val_Recall: 0.2023 - val_accuracy: 0.5081 - val_f1_score: 0.3152 - val_loss: 1.3119\n",
      "Epoch 2/100\n",
      "\u001b[1m236/236\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m145s\u001b[0m 617ms/step - Precision: 0.6868 - Recall: 0.3524 - accuracy: 0.5468 - f1_score: 0.4653 - loss: 1.2128 - val_Precision: 0.7666 - val_Recall: 0.4918 - val_accuracy: 0.6417 - val_f1_score: 0.5992 - val_loss: 0.9655\n",
      "Epoch 3/100\n",
      "\u001b[1m236/236\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m151s\u001b[0m 640ms/step - Precision: 0.7620 - Recall: 0.5041 - accuracy: 0.6363 - f1_score: 0.6065 - loss: 0.9536 - val_Precision: 0.7604 - val_Recall: 0.6476 - val_accuracy: 0.7013 - val_f1_score: 0.6995 - val_loss: 0.8187\n",
      "Epoch 4/100\n",
      "\u001b[1m236/236\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m138s\u001b[0m 588ms/step - Precision: 0.8124 - Recall: 0.6355 - accuracy: 0.7298 - f1_score: 0.7130 - loss: 0.7481 - val_Precision: 0.8392 - val_Recall: 0.7461 - val_accuracy: 0.7856 - val_f1_score: 0.7899 - val_loss: 0.5788\n",
      "Epoch 5/100\n",
      "\u001b[1m236/236\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m140s\u001b[0m 595ms/step - Precision: 0.8594 - Recall: 0.7350 - accuracy: 0.7959 - f1_score: 0.7923 - loss: 0.5752 - val_Precision: 0.9208 - val_Recall: 0.8285 - val_accuracy: 0.8773 - val_f1_score: 0.8722 - val_loss: 0.3732\n",
      "Epoch 6/100\n",
      "\u001b[1m236/236\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m148s\u001b[0m 623ms/step - Precision: 0.9003 - Recall: 0.8187 - accuracy: 0.8589 - f1_score: 0.8576 - loss: 0.3994 - val_Precision: 0.9209 - val_Recall: 0.8644 - val_accuracy: 0.8899 - val_f1_score: 0.8918 - val_loss: 0.3252\n",
      "Epoch 7/100\n",
      "\u001b[1m236/236\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m139s\u001b[0m 591ms/step - Precision: 0.9205 - Recall: 0.8595 - accuracy: 0.8885 - f1_score: 0.8889 - loss: 0.3217 - val_Precision: 0.9414 - val_Recall: 0.9028 - val_accuracy: 0.9234 - val_f1_score: 0.9217 - val_loss: 0.2358\n",
      "Epoch 8/100\n",
      "\u001b[1m236/236\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m144s\u001b[0m 611ms/step - Precision: 0.9421 - Recall: 0.9090 - accuracy: 0.9239 - f1_score: 0.9253 - loss: 0.2210 - val_Precision: 0.9706 - val_Recall: 0.9523 - val_accuracy: 0.9623 - val_f1_score: 0.9614 - val_loss: 0.1371\n",
      "Epoch 9/100\n",
      "\u001b[1m236/236\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m139s\u001b[0m 587ms/step - Precision: 0.9535 - Recall: 0.9324 - accuracy: 0.9420 - f1_score: 0.9429 - loss: 0.1706 - val_Precision: 0.9687 - val_Recall: 0.9485 - val_accuracy: 0.9586 - val_f1_score: 0.9585 - val_loss: 0.1337\n",
      "Epoch 10/100\n",
      "\u001b[1m236/236\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m69s\u001b[0m 290ms/step - Precision: 0.9619 - Recall: 0.9422 - accuracy: 0.9532 - f1_score: 0.9520 - loss: 0.1340 - val_Precision: 0.9605 - val_Recall: 0.9458 - val_accuracy: 0.9523 - val_f1_score: 0.9531 - val_loss: 0.1287\n",
      "Epoch 11/100\n",
      "\u001b[1m236/236\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m80s\u001b[0m 339ms/step - Precision: 0.9681 - Recall: 0.9572 - accuracy: 0.9616 - f1_score: 0.9626 - loss: 0.1200 - val_Precision: 0.9446 - val_Recall: 0.9312 - val_accuracy: 0.9380 - val_f1_score: 0.9379 - val_loss: 0.1807\n",
      "Epoch 12/100\n",
      "\u001b[1m236/236\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m65s\u001b[0m 276ms/step - Precision: 0.9635 - Recall: 0.9527 - accuracy: 0.9572 - f1_score: 0.9581 - loss: 0.1275 - val_Precision: 0.9847 - val_Recall: 0.9807 - val_accuracy: 0.9822 - val_f1_score: 0.9827 - val_loss: 0.0618\n",
      "Epoch 13/100\n",
      "\u001b[1m236/236\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m69s\u001b[0m 292ms/step - Precision: 0.9787 - Recall: 0.9718 - accuracy: 0.9754 - f1_score: 0.9752 - loss: 0.0822 - val_Precision: 0.9924 - val_Recall: 0.9881 - val_accuracy: 0.9904 - val_f1_score: 0.9902 - val_loss: 0.0408\n",
      "Epoch 14/100\n",
      "\u001b[1m236/236\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m79s\u001b[0m 333ms/step - Precision: 0.9849 - Recall: 0.9807 - accuracy: 0.9818 - f1_score: 0.9828 - loss: 0.0544 - val_Precision: 0.9849 - val_Recall: 0.9809 - val_accuracy: 0.9830 - val_f1_score: 0.9829 - val_loss: 0.0566\n",
      "Epoch 15/100\n",
      "\u001b[1m236/236\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m85s\u001b[0m 358ms/step - Precision: 0.9723 - Recall: 0.9661 - accuracy: 0.9694 - f1_score: 0.9692 - loss: 0.0928 - val_Precision: 0.9504 - val_Recall: 0.9448 - val_accuracy: 0.9473 - val_f1_score: 0.9476 - val_loss: 0.1573\n",
      "Epoch 16/100\n",
      "\u001b[1m236/236\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m79s\u001b[0m 336ms/step - Precision: 0.9794 - Recall: 0.9760 - accuracy: 0.9770 - f1_score: 0.9777 - loss: 0.0731 - val_Precision: 0.9905 - val_Recall: 0.9875 - val_accuracy: 0.9890 - val_f1_score: 0.9890 - val_loss: 0.0358\n",
      "Epoch 17/100\n",
      "\u001b[1m236/236\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m79s\u001b[0m 337ms/step - Precision: 0.9933 - Recall: 0.9914 - accuracy: 0.9923 - f1_score: 0.9924 - loss: 0.0276 - val_Precision: 0.9904 - val_Recall: 0.9882 - val_accuracy: 0.9891 - val_f1_score: 0.9893 - val_loss: 0.0313\n",
      "Epoch 18/100\n",
      "\u001b[1m236/236\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m81s\u001b[0m 345ms/step - Precision: 0.9919 - Recall: 0.9903 - accuracy: 0.9913 - f1_score: 0.9911 - loss: 0.0310 - val_Precision: 0.9932 - val_Recall: 0.9911 - val_accuracy: 0.9919 - val_f1_score: 0.9922 - val_loss: 0.0279\n",
      "Epoch 19/100\n",
      "\u001b[1m236/236\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 347ms/step - Precision: 0.9915 - Recall: 0.9894 - accuracy: 0.9910 - f1_score: 0.9904 - loss: 0.0301 - val_Precision: 0.9928 - val_Recall: 0.9920 - val_accuracy: 0.9924 - val_f1_score: 0.9924 - val_loss: 0.0276\n",
      "Epoch 20/100\n",
      "\u001b[1m236/236\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m74s\u001b[0m 314ms/step - Precision: 0.9880 - Recall: 0.9852 - accuracy: 0.9857 - f1_score: 0.9866 - loss: 0.0434 - val_Precision: 0.9859 - val_Recall: 0.9834 - val_accuracy: 0.9846 - val_f1_score: 0.9846 - val_loss: 0.0474\n",
      "Epoch 21/100\n",
      "\u001b[1m236/236\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m78s\u001b[0m 329ms/step - Precision: 0.9753 - Recall: 0.9701 - accuracy: 0.9726 - f1_score: 0.9727 - loss: 0.0803 - val_Precision: 0.9899 - val_Recall: 0.9887 - val_accuracy: 0.9891 - val_f1_score: 0.9893 - val_loss: 0.0332\n",
      "Epoch 22/100\n",
      "\u001b[1m236/236\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m85s\u001b[0m 358ms/step - Precision: 0.9889 - Recall: 0.9876 - accuracy: 0.9884 - f1_score: 0.9882 - loss: 0.0364 - val_Precision: 0.9858 - val_Recall: 0.9851 - val_accuracy: 0.9857 - val_f1_score: 0.9855 - val_loss: 0.0474\n",
      "Epoch 23/100\n",
      "\u001b[1m236/236\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m81s\u001b[0m 344ms/step - Precision: 0.9820 - Recall: 0.9812 - accuracy: 0.9815 - f1_score: 0.9816 - loss: 0.0524 - val_Precision: 0.9770 - val_Recall: 0.9741 - val_accuracy: 0.9758 - val_f1_score: 0.9755 - val_loss: 0.0776\n",
      "Epoch 24/100\n",
      "\u001b[1m236/236\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m74s\u001b[0m 312ms/step - Precision: 0.9840 - Recall: 0.9824 - accuracy: 0.9831 - f1_score: 0.9832 - loss: 0.0568 - val_Precision: 0.9750 - val_Recall: 0.9724 - val_accuracy: 0.9740 - val_f1_score: 0.9737 - val_loss: 0.0873\n",
      "Epoch 25/100\n",
      "\u001b[1m236/236\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m80s\u001b[0m 338ms/step - Precision: 0.9877 - Recall: 0.9873 - accuracy: 0.9877 - f1_score: 0.9875 - loss: 0.0368 - val_Precision: 0.9855 - val_Recall: 0.9831 - val_accuracy: 0.9845 - val_f1_score: 0.9843 - val_loss: 0.0471\n",
      "Epoch 26/100\n",
      "\u001b[1m236/236\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m84s\u001b[0m 356ms/step - Precision: 0.9816 - Recall: 0.9796 - accuracy: 0.9806 - f1_score: 0.9806 - loss: 0.0648 - val_Precision: 0.9931 - val_Recall: 0.9922 - val_accuracy: 0.9928 - val_f1_score: 0.9926 - val_loss: 0.0222\n",
      "Epoch 27/100\n",
      "\u001b[1m236/236\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m80s\u001b[0m 338ms/step - Precision: 0.9887 - Recall: 0.9878 - accuracy: 0.9882 - f1_score: 0.9882 - loss: 0.0406 - val_Precision: 0.9948 - val_Recall: 0.9944 - val_accuracy: 0.9944 - val_f1_score: 0.9946 - val_loss: 0.0192\n",
      "Epoch 28/100\n",
      "\u001b[1m236/236\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m79s\u001b[0m 334ms/step - Precision: 0.9903 - Recall: 0.9892 - accuracy: 0.9897 - f1_score: 0.9897 - loss: 0.0314 - val_Precision: 0.9751 - val_Recall: 0.9723 - val_accuracy: 0.9729 - val_f1_score: 0.9737 - val_loss: 0.0830\n",
      "Epoch 29/100\n",
      "\u001b[1m236/236\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m136s\u001b[0m 580ms/step - Precision: 0.9880 - Recall: 0.9866 - accuracy: 0.9879 - f1_score: 0.9873 - loss: 0.0436 - val_Precision: 0.9884 - val_Recall: 0.9869 - val_accuracy: 0.9877 - val_f1_score: 0.9876 - val_loss: 0.0413\n",
      "Epoch 30/100\n",
      "\u001b[1m236/236\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m164s\u001b[0m 693ms/step - Precision: 0.9889 - Recall: 0.9876 - accuracy: 0.9881 - f1_score: 0.9882 - loss: 0.0309 - val_Precision: 0.9969 - val_Recall: 0.9967 - val_accuracy: 0.9967 - val_f1_score: 0.9968 - val_loss: 0.0118\n",
      "Epoch 31/100\n",
      "\u001b[1m236/236\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m147s\u001b[0m 620ms/step - Precision: 0.9915 - Recall: 0.9910 - accuracy: 0.9913 - f1_score: 0.9912 - loss: 0.0363 - val_Precision: 0.9980 - val_Recall: 0.9969 - val_accuracy: 0.9976 - val_f1_score: 0.9975 - val_loss: 0.0098\n",
      "Epoch 32/100\n",
      "\u001b[1m236/236\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m145s\u001b[0m 615ms/step - Precision: 0.9960 - Recall: 0.9959 - accuracy: 0.9959 - f1_score: 0.9960 - loss: 0.0129 - val_Precision: 0.9989 - val_Recall: 0.9988 - val_accuracy: 0.9988 - val_f1_score: 0.9989 - val_loss: 0.0040\n",
      "Epoch 33/100\n",
      "\u001b[1m236/236\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m144s\u001b[0m 613ms/step - Precision: 0.9997 - Recall: 0.9997 - accuracy: 0.9997 - f1_score: 0.9997 - loss: 0.0024 - val_Precision: 1.0000 - val_Recall: 1.0000 - val_accuracy: 1.0000 - val_f1_score: 1.0000 - val_loss: 3.6869e-04\n",
      "Epoch 34/100\n",
      "\u001b[1m236/236\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m150s\u001b[0m 638ms/step - Precision: 1.0000 - Recall: 1.0000 - accuracy: 1.0000 - f1_score: 1.0000 - loss: 4.1942e-04 - val_Precision: 1.0000 - val_Recall: 1.0000 - val_accuracy: 1.0000 - val_f1_score: 1.0000 - val_loss: 1.9059e-04\n",
      "Epoch 35/100\n",
      "\u001b[1m236/236\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m143s\u001b[0m 605ms/step - Precision: 1.0000 - Recall: 1.0000 - accuracy: 1.0000 - f1_score: 1.0000 - loss: 2.2350e-04 - val_Precision: 1.0000 - val_Recall: 1.0000 - val_accuracy: 1.0000 - val_f1_score: 1.0000 - val_loss: 1.3555e-04\n",
      "Epoch 36/100\n",
      "\u001b[1m236/236\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m135s\u001b[0m 571ms/step - Precision: 1.0000 - Recall: 1.0000 - accuracy: 1.0000 - f1_score: 1.0000 - loss: 1.3551e-04 - val_Precision: 1.0000 - val_Recall: 1.0000 - val_accuracy: 1.0000 - val_f1_score: 1.0000 - val_loss: 1.1415e-04\n",
      "Epoch 37/100\n",
      "\u001b[1m236/236\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m122s\u001b[0m 515ms/step - Precision: 1.0000 - Recall: 1.0000 - accuracy: 1.0000 - f1_score: 1.0000 - loss: 1.0024e-04 - val_Precision: 1.0000 - val_Recall: 1.0000 - val_accuracy: 1.0000 - val_f1_score: 1.0000 - val_loss: 9.9489e-05\n",
      "Epoch 38/100\n",
      "\u001b[1m236/236\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m154s\u001b[0m 652ms/step - Precision: 1.0000 - Recall: 1.0000 - accuracy: 1.0000 - f1_score: 1.0000 - loss: 1.1035e-04 - val_Precision: 1.0000 - val_Recall: 1.0000 - val_accuracy: 1.0000 - val_f1_score: 1.0000 - val_loss: 8.5986e-05\n",
      "Epoch 39/100\n",
      "\u001b[1m236/236\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m136s\u001b[0m 573ms/step - Precision: 1.0000 - Recall: 1.0000 - accuracy: 1.0000 - f1_score: 1.0000 - loss: 8.0936e-05 - val_Precision: 1.0000 - val_Recall: 1.0000 - val_accuracy: 1.0000 - val_f1_score: 1.0000 - val_loss: 7.5865e-05\n",
      "Epoch 40/100\n",
      "\u001b[1m236/236\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m152s\u001b[0m 645ms/step - Precision: 1.0000 - Recall: 1.0000 - accuracy: 1.0000 - f1_score: 1.0000 - loss: 7.1279e-05 - val_Precision: 1.0000 - val_Recall: 1.0000 - val_accuracy: 1.0000 - val_f1_score: 1.0000 - val_loss: 6.7115e-05\n",
      "Epoch 41/100\n",
      "\u001b[1m236/236\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m139s\u001b[0m 589ms/step - Precision: 1.0000 - Recall: 1.0000 - accuracy: 1.0000 - f1_score: 1.0000 - loss: 6.7307e-05 - val_Precision: 1.0000 - val_Recall: 1.0000 - val_accuracy: 1.0000 - val_f1_score: 1.0000 - val_loss: 5.9458e-05\n",
      "Epoch 42/100\n",
      "\u001b[1m236/236\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m154s\u001b[0m 651ms/step - Precision: 1.0000 - Recall: 1.0000 - accuracy: 1.0000 - f1_score: 1.0000 - loss: 6.0627e-05 - val_Precision: 1.0000 - val_Recall: 1.0000 - val_accuracy: 1.0000 - val_f1_score: 1.0000 - val_loss: 5.2764e-05\n",
      "Epoch 43/100\n",
      "\u001b[1m236/236\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m178s\u001b[0m 754ms/step - Precision: 1.0000 - Recall: 1.0000 - accuracy: 1.0000 - f1_score: 1.0000 - loss: 5.1944e-05 - val_Precision: 1.0000 - val_Recall: 1.0000 - val_accuracy: 1.0000 - val_f1_score: 1.0000 - val_loss: 4.7464e-05\n",
      "Epoch 44/100\n",
      "\u001b[1m236/236\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m192s\u001b[0m 812ms/step - Precision: 1.0000 - Recall: 1.0000 - accuracy: 1.0000 - f1_score: 1.0000 - loss: 4.5159e-05 - val_Precision: 1.0000 - val_Recall: 1.0000 - val_accuracy: 1.0000 - val_f1_score: 1.0000 - val_loss: 4.1939e-05\n",
      "Epoch 45/100\n",
      "\u001b[1m236/236\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m191s\u001b[0m 810ms/step - Precision: 1.0000 - Recall: 1.0000 - accuracy: 1.0000 - f1_score: 1.0000 - loss: 4.1195e-05 - val_Precision: 1.0000 - val_Recall: 1.0000 - val_accuracy: 1.0000 - val_f1_score: 1.0000 - val_loss: 3.7872e-05\n",
      "Epoch 46/100\n",
      "\u001b[1m236/236\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m158s\u001b[0m 672ms/step - Precision: 1.0000 - Recall: 1.0000 - accuracy: 1.0000 - f1_score: 1.0000 - loss: 3.4104e-05 - val_Precision: 1.0000 - val_Recall: 1.0000 - val_accuracy: 1.0000 - val_f1_score: 1.0000 - val_loss: 3.0034e-05\n",
      "Epoch 48/100\n",
      "\u001b[1m236/236\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m176s\u001b[0m 748ms/step - Precision: 1.0000 - Recall: 1.0000 - accuracy: 1.0000 - f1_score: 1.0000 - loss: 3.2426e-05 - val_Precision: 1.0000 - val_Recall: 1.0000 - val_accuracy: 1.0000 - val_f1_score: 1.0000 - val_loss: 2.6780e-05\n",
      "Epoch 49/100\n",
      "\u001b[1m236/236\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m142s\u001b[0m 600ms/step - Precision: 1.0000 - Recall: 1.0000 - accuracy: 1.0000 - f1_score: 1.0000 - loss: 3.0099e-05 - val_Precision: 1.0000 - val_Recall: 1.0000 - val_accuracy: 1.0000 - val_f1_score: 1.0000 - val_loss: 2.3808e-05\n",
      "Epoch 50/100\n",
      "\u001b[1m236/236\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m164s\u001b[0m 694ms/step - Precision: 1.0000 - Recall: 1.0000 - accuracy: 1.0000 - f1_score: 1.0000 - loss: 2.1521e-05 - val_Precision: 1.0000 - val_Recall: 1.0000 - val_accuracy: 1.0000 - val_f1_score: 1.0000 - val_loss: 2.1309e-05\n",
      "Epoch 51/100\n",
      "\u001b[1m236/236\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m151s\u001b[0m 639ms/step - Precision: 1.0000 - Recall: 1.0000 - accuracy: 1.0000 - f1_score: 1.0000 - loss: 1.8525e-05 - val_Precision: 1.0000 - val_Recall: 1.0000 - val_accuracy: 1.0000 - val_f1_score: 1.0000 - val_loss: 2.1004e-05\n",
      "Epoch 52/100\n",
      "\u001b[1m236/236\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m134s\u001b[0m 570ms/step - Precision: 1.0000 - Recall: 1.0000 - accuracy: 1.0000 - f1_score: 1.0000 - loss: 1.8654e-05 - val_Precision: 1.0000 - val_Recall: 1.0000 - val_accuracy: 1.0000 - val_f1_score: 1.0000 - val_loss: 1.6823e-05\n",
      "Epoch 53/100\n",
      "\u001b[1m236/236\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m128s\u001b[0m 541ms/step - Precision: 1.0000 - Recall: 1.0000 - accuracy: 1.0000 - f1_score: 1.0000 - loss: 1.5662e-05 - val_Precision: 1.0000 - val_Recall: 1.0000 - val_accuracy: 1.0000 - val_f1_score: 1.0000 - val_loss: 1.4826e-05\n",
      "Epoch 54/100\n",
      "\u001b[1m236/236\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m141s\u001b[0m 597ms/step - Precision: 1.0000 - Recall: 1.0000 - accuracy: 1.0000 - f1_score: 1.0000 - loss: 1.5346e-05 - val_Precision: 1.0000 - val_Recall: 1.0000 - val_accuracy: 1.0000 - val_f1_score: 1.0000 - val_loss: 1.3159e-05\n",
      "Epoch 55/100\n",
      "\u001b[1m236/236\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m149s\u001b[0m 633ms/step - Precision: 1.0000 - Recall: 1.0000 - accuracy: 1.0000 - f1_score: 1.0000 - loss: 1.2218e-05 - val_Precision: 1.0000 - val_Recall: 1.0000 - val_accuracy: 1.0000 - val_f1_score: 1.0000 - val_loss: 1.3365e-05\n",
      "Epoch 56/100\n",
      "\u001b[1m236/236\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m129s\u001b[0m 546ms/step - Precision: 1.0000 - Recall: 1.0000 - accuracy: 1.0000 - f1_score: 1.0000 - loss: 1.3046e-05 - val_Precision: 1.0000 - val_Recall: 1.0000 - val_accuracy: 1.0000 - val_f1_score: 1.0000 - val_loss: 1.0780e-05\n",
      "Epoch 57/100\n",
      "\u001b[1m236/236\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m129s\u001b[0m 548ms/step - Precision: 1.0000 - Recall: 1.0000 - accuracy: 1.0000 - f1_score: 1.0000 - loss: 9.5951e-06 - val_Precision: 1.0000 - val_Recall: 1.0000 - val_accuracy: 1.0000 - val_f1_score: 1.0000 - val_loss: 9.2399e-06\n",
      "Epoch 58/100\n",
      "\u001b[1m236/236\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m146s\u001b[0m 615ms/step - Precision: 1.0000 - Recall: 1.0000 - accuracy: 1.0000 - f1_score: 1.0000 - loss: 8.3542e-06 - val_Precision: 1.0000 - val_Recall: 1.0000 - val_accuracy: 1.0000 - val_f1_score: 1.0000 - val_loss: 8.1005e-06\n",
      "Epoch 59/100\n",
      "\u001b[1m236/236\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m154s\u001b[0m 652ms/step - Precision: 1.0000 - Recall: 1.0000 - accuracy: 1.0000 - f1_score: 1.0000 - loss: 7.8507e-06 - val_Precision: 1.0000 - val_Recall: 1.0000 - val_accuracy: 1.0000 - val_f1_score: 1.0000 - val_loss: 7.2753e-06\n",
      "Epoch 60/100\n",
      "\u001b[1m236/236\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m133s\u001b[0m 566ms/step - Precision: 1.0000 - Recall: 1.0000 - accuracy: 1.0000 - f1_score: 1.0000 - loss: 7.3889e-06 - val_Precision: 1.0000 - val_Recall: 1.0000 - val_accuracy: 1.0000 - val_f1_score: 1.0000 - val_loss: 6.4972e-06\n",
      "Epoch 61/100\n",
      "\u001b[1m236/236\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m67s\u001b[0m 286ms/step - Precision: 1.0000 - Recall: 1.0000 - accuracy: 1.0000 - f1_score: 1.0000 - loss: 6.4733e-06 - val_Precision: 1.0000 - val_Recall: 1.0000 - val_accuracy: 1.0000 - val_f1_score: 1.0000 - val_loss: 5.8854e-06\n",
      "Epoch 62/100\n",
      "\u001b[1m236/236\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m75s\u001b[0m 317ms/step - Precision: 1.0000 - Recall: 1.0000 - accuracy: 1.0000 - f1_score: 1.0000 - loss: 6.5544e-06 - val_Precision: 1.0000 - val_Recall: 1.0000 - val_accuracy: 1.0000 - val_f1_score: 1.0000 - val_loss: 4.9660e-06\n",
      "Epoch 63/100\n",
      "\u001b[1m236/236\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m80s\u001b[0m 339ms/step - Precision: 1.0000 - Recall: 1.0000 - accuracy: 1.0000 - f1_score: 1.0000 - loss: 4.9260e-06 - val_Precision: 1.0000 - val_Recall: 1.0000 - val_accuracy: 1.0000 - val_f1_score: 1.0000 - val_loss: 4.4076e-06\n",
      "Epoch 64/100\n",
      "\u001b[1m236/236\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m92s\u001b[0m 391ms/step - Precision: 1.0000 - Recall: 1.0000 - accuracy: 1.0000 - f1_score: 1.0000 - loss: 5.0576e-06 - val_Precision: 1.0000 - val_Recall: 1.0000 - val_accuracy: 1.0000 - val_f1_score: 1.0000 - val_loss: 3.8841e-06\n",
      "Epoch 65/100\n",
      "\u001b[1m236/236\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m127s\u001b[0m 538ms/step - Precision: 1.0000 - Recall: 1.0000 - accuracy: 1.0000 - f1_score: 1.0000 - loss: 4.1046e-06 - val_Precision: 1.0000 - val_Recall: 1.0000 - val_accuracy: 1.0000 - val_f1_score: 1.0000 - val_loss: 4.1088e-06\n",
      "Epoch 66/100\n",
      "\u001b[1m236/236\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m153s\u001b[0m 649ms/step - Precision: 1.0000 - Recall: 1.0000 - accuracy: 1.0000 - f1_score: 1.0000 - loss: 3.7026e-06 - val_Precision: 1.0000 - val_Recall: 1.0000 - val_accuracy: 1.0000 - val_f1_score: 1.0000 - val_loss: 3.6524e-06\n",
      "Epoch 67/100\n",
      "\u001b[1m236/236\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m151s\u001b[0m 641ms/step - Precision: 0.9503 - Recall: 0.9418 - accuracy: 0.9452 - f1_score: 0.9461 - loss: 0.2455 - val_Precision: 0.9537 - val_Recall: 0.9470 - val_accuracy: 0.9507 - val_f1_score: 0.9504 - val_loss: 0.1470\n",
      "Epoch 68/100\n",
      "\u001b[1m236/236\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m159s\u001b[0m 675ms/step - Precision: 0.9690 - Recall: 0.9630 - accuracy: 0.9661 - f1_score: 0.9659 - loss: 0.1033 - val_Precision: 0.9829 - val_Recall: 0.9793 - val_accuracy: 0.9809 - val_f1_score: 0.9811 - val_loss: 0.0559\n",
      "Epoch 69/100\n",
      "\u001b[1m236/236\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m145s\u001b[0m 616ms/step - Precision: 0.9921 - Recall: 0.9902 - accuracy: 0.9911 - f1_score: 0.9912 - loss: 0.0242 - val_Precision: 1.0000 - val_Recall: 0.9999 - val_accuracy: 1.0000 - val_f1_score: 0.9999 - val_loss: 0.0034\n",
      "Epoch 70/100\n",
      "\u001b[1m236/236\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m142s\u001b[0m 600ms/step - Precision: 0.9995 - Recall: 0.9989 - accuracy: 0.9991 - f1_score: 0.9992 - loss: 0.0044 - val_Precision: 1.0000 - val_Recall: 1.0000 - val_accuracy: 1.0000 - val_f1_score: 1.0000 - val_loss: 0.0011\n",
      "Epoch 71/100\n",
      "\u001b[1m236/236\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m172s\u001b[0m 730ms/step - Precision: 1.0000 - Recall: 1.0000 - accuracy: 1.0000 - f1_score: 1.0000 - loss: 0.0014 - val_Precision: 1.0000 - val_Recall: 1.0000 - val_accuracy: 1.0000 - val_f1_score: 1.0000 - val_loss: 5.3453e-04\n",
      "Epoch 72/100\n",
      "\u001b[1m236/236\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m127s\u001b[0m 536ms/step - Precision: 1.0000 - Recall: 1.0000 - accuracy: 1.0000 - f1_score: 1.0000 - loss: 6.0187e-04 - val_Precision: 1.0000 - val_Recall: 1.0000 - val_accuracy: 1.0000 - val_f1_score: 1.0000 - val_loss: 3.3346e-04\n",
      "Epoch 73/100\n",
      "\u001b[1m236/236\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m145s\u001b[0m 616ms/step - Precision: 1.0000 - Recall: 1.0000 - accuracy: 1.0000 - f1_score: 1.0000 - loss: 3.1861e-04 - val_Precision: 1.0000 - val_Recall: 1.0000 - val_accuracy: 1.0000 - val_f1_score: 1.0000 - val_loss: 2.6794e-04\n",
      "Epoch 74/100\n",
      "\u001b[1m236/236\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m185s\u001b[0m 785ms/step - Precision: 1.0000 - Recall: 1.0000 - accuracy: 1.0000 - f1_score: 1.0000 - loss: 2.5834e-04 - val_Precision: 1.0000 - val_Recall: 1.0000 - val_accuracy: 1.0000 - val_f1_score: 1.0000 - val_loss: 2.1772e-04\n",
      "Epoch 75/100\n",
      "\u001b[1m236/236\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m84s\u001b[0m 356ms/step - Precision: 1.0000 - Recall: 1.0000 - accuracy: 1.0000 - f1_score: 1.0000 - loss: 2.2625e-04 - val_Precision: 1.0000 - val_Recall: 1.0000 - val_accuracy: 1.0000 - val_f1_score: 1.0000 - val_loss: 1.8184e-04\n",
      "Epoch 76/100\n",
      "\u001b[1m236/236\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m107s\u001b[0m 453ms/step - Precision: 1.0000 - Recall: 1.0000 - accuracy: 1.0000 - f1_score: 1.0000 - loss: 1.8731e-04 - val_Precision: 1.0000 - val_Recall: 1.0000 - val_accuracy: 1.0000 - val_f1_score: 1.0000 - val_loss: 1.5423e-04\n",
      "Epoch 77/100\n",
      "\u001b[1m236/236\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m116s\u001b[0m 493ms/step - Precision: 1.0000 - Recall: 1.0000 - accuracy: 1.0000 - f1_score: 1.0000 - loss: 1.5054e-04 - val_Precision: 1.0000 - val_Recall: 1.0000 - val_accuracy: 1.0000 - val_f1_score: 1.0000 - val_loss: 1.3383e-04\n",
      "Epoch 78/100\n",
      "\u001b[1m236/236\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m112s\u001b[0m 474ms/step - Precision: 1.0000 - Recall: 1.0000 - accuracy: 1.0000 - f1_score: 1.0000 - loss: 1.3176e-04 - val_Precision: 1.0000 - val_Recall: 1.0000 - val_accuracy: 1.0000 - val_f1_score: 1.0000 - val_loss: 1.1423e-04\n",
      "Epoch 79/100\n",
      "\u001b[1m236/236\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m122s\u001b[0m 519ms/step - Precision: 1.0000 - Recall: 1.0000 - accuracy: 1.0000 - f1_score: 1.0000 - loss: 1.1161e-04 - val_Precision: 1.0000 - val_Recall: 1.0000 - val_accuracy: 1.0000 - val_f1_score: 1.0000 - val_loss: 9.9228e-05\n",
      "Epoch 80/100\n",
      "\u001b[1m236/236\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m123s\u001b[0m 522ms/step - Precision: 1.0000 - Recall: 1.0000 - accuracy: 1.0000 - f1_score: 1.0000 - loss: 9.5249e-05 - val_Precision: 1.0000 - val_Recall: 1.0000 - val_accuracy: 1.0000 - val_f1_score: 1.0000 - val_loss: 8.5785e-05\n",
      "Epoch 81/100\n",
      "\u001b[1m236/236\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m123s\u001b[0m 520ms/step - Precision: 1.0000 - Recall: 1.0000 - accuracy: 1.0000 - f1_score: 1.0000 - loss: 8.0040e-05 - val_Precision: 1.0000 - val_Recall: 1.0000 - val_accuracy: 1.0000 - val_f1_score: 1.0000 - val_loss: 7.6762e-05\n",
      "Epoch 82/100\n",
      "\u001b[1m236/236\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m117s\u001b[0m 494ms/step - Precision: 1.0000 - Recall: 1.0000 - accuracy: 1.0000 - f1_score: 1.0000 - loss: 7.5276e-05 - val_Precision: 1.0000 - val_Recall: 1.0000 - val_accuracy: 1.0000 - val_f1_score: 1.0000 - val_loss: 6.5481e-05\n",
      "Epoch 83/100\n",
      "\u001b[1m236/236\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m110s\u001b[0m 467ms/step - Precision: 1.0000 - Recall: 1.0000 - accuracy: 1.0000 - f1_score: 1.0000 - loss: 6.5454e-05 - val_Precision: 1.0000 - val_Recall: 1.0000 - val_accuracy: 1.0000 - val_f1_score: 1.0000 - val_loss: 5.7614e-05\n",
      "Epoch 84/100\n",
      "\u001b[1m236/236\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m109s\u001b[0m 461ms/step - Precision: 1.0000 - Recall: 1.0000 - accuracy: 1.0000 - f1_score: 1.0000 - loss: 5.6421e-05 - val_Precision: 1.0000 - val_Recall: 1.0000 - val_accuracy: 1.0000 - val_f1_score: 1.0000 - val_loss: 5.1162e-05\n",
      "Epoch 85/100\n",
      "\u001b[1m236/236\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m106s\u001b[0m 450ms/step - Precision: 1.0000 - Recall: 1.0000 - accuracy: 1.0000 - f1_score: 1.0000 - loss: 5.4546e-05 - val_Precision: 1.0000 - val_Recall: 1.0000 - val_accuracy: 1.0000 - val_f1_score: 1.0000 - val_loss: 4.4651e-05\n",
      "Epoch 86/100\n",
      "\u001b[1m236/236\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m152s\u001b[0m 646ms/step - Precision: 1.0000 - Recall: 1.0000 - accuracy: 1.0000 - f1_score: 1.0000 - loss: 4.7218e-05 - val_Precision: 1.0000 - val_Recall: 1.0000 - val_accuracy: 1.0000 - val_f1_score: 1.0000 - val_loss: 3.8922e-05\n",
      "Epoch 87/100\n",
      "\u001b[1m236/236\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m130s\u001b[0m 548ms/step - Precision: 1.0000 - Recall: 1.0000 - accuracy: 1.0000 - f1_score: 1.0000 - loss: 4.0851e-05 - val_Precision: 1.0000 - val_Recall: 1.0000 - val_accuracy: 1.0000 - val_f1_score: 1.0000 - val_loss: 3.4311e-05\n",
      "Epoch 88/100\n",
      "\u001b[1m236/236\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m132s\u001b[0m 558ms/step - Precision: 1.0000 - Recall: 1.0000 - accuracy: 1.0000 - f1_score: 1.0000 - loss: 3.6179e-05 - val_Precision: 1.0000 - val_Recall: 1.0000 - val_accuracy: 1.0000 - val_f1_score: 1.0000 - val_loss: 3.0099e-05\n",
      "Epoch 89/100\n",
      "\u001b[1m236/236\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m115s\u001b[0m 487ms/step - Precision: 1.0000 - Recall: 1.0000 - accuracy: 1.0000 - f1_score: 1.0000 - loss: 3.4794e-05 - val_Precision: 1.0000 - val_Recall: 1.0000 - val_accuracy: 1.0000 - val_f1_score: 1.0000 - val_loss: 2.6410e-05\n",
      "Epoch 90/100\n",
      "\u001b[1m236/236\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m106s\u001b[0m 447ms/step - Precision: 1.0000 - Recall: 1.0000 - accuracy: 1.0000 - f1_score: 1.0000 - loss: 2.6902e-05 - val_Precision: 1.0000 - val_Recall: 1.0000 - val_accuracy: 1.0000 - val_f1_score: 1.0000 - val_loss: 2.3539e-05\n",
      "Epoch 91/100\n",
      "\u001b[1m236/236\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m97s\u001b[0m 411ms/step - Precision: 1.0000 - Recall: 1.0000 - accuracy: 1.0000 - f1_score: 1.0000 - loss: 2.3782e-05 - val_Precision: 1.0000 - val_Recall: 1.0000 - val_accuracy: 1.0000 - val_f1_score: 1.0000 - val_loss: 2.0482e-05\n",
      "Epoch 92/100\n",
      "\u001b[1m236/236\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m114s\u001b[0m 480ms/step - Precision: 1.0000 - Recall: 1.0000 - accuracy: 1.0000 - f1_score: 1.0000 - loss: 2.2371e-05 - val_Precision: 1.0000 - val_Recall: 1.0000 - val_accuracy: 1.0000 - val_f1_score: 1.0000 - val_loss: 1.8191e-05\n",
      "Epoch 93/100\n",
      "\u001b[1m236/236\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m113s\u001b[0m 480ms/step - Precision: 1.0000 - Recall: 1.0000 - accuracy: 1.0000 - f1_score: 1.0000 - loss: 1.8345e-05 - val_Precision: 1.0000 - val_Recall: 1.0000 - val_accuracy: 1.0000 - val_f1_score: 1.0000 - val_loss: 1.5985e-05\n",
      "Epoch 94/100\n",
      "\u001b[1m236/236\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m109s\u001b[0m 461ms/step - Precision: 1.0000 - Recall: 1.0000 - accuracy: 1.0000 - f1_score: 1.0000 - loss: 1.6018e-05 - val_Precision: 1.0000 - val_Recall: 1.0000 - val_accuracy: 1.0000 - val_f1_score: 1.0000 - val_loss: 1.4091e-05\n",
      "Epoch 95/100\n",
      "\u001b[1m236/236\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m110s\u001b[0m 468ms/step - Precision: 1.0000 - Recall: 1.0000 - accuracy: 1.0000 - f1_score: 1.0000 - loss: 1.2135e-05 - val_Precision: 1.0000 - val_Recall: 1.0000 - val_accuracy: 1.0000 - val_f1_score: 1.0000 - val_loss: 1.0882e-05\n",
      "Epoch 97/100\n",
      "\u001b[1m236/236\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m88s\u001b[0m 374ms/step - Precision: 1.0000 - Recall: 1.0000 - accuracy: 1.0000 - f1_score: 1.0000 - loss: 1.0973e-05 - val_Precision: 1.0000 - val_Recall: 1.0000 - val_accuracy: 1.0000 - val_f1_score: 1.0000 - val_loss: 9.5378e-06\n",
      "Epoch 98/100\n",
      "\u001b[1m236/236\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m73s\u001b[0m 308ms/step - Precision: 1.0000 - Recall: 1.0000 - accuracy: 1.0000 - f1_score: 1.0000 - loss: 9.1928e-06 - val_Precision: 1.0000 - val_Recall: 1.0000 - val_accuracy: 1.0000 - val_f1_score: 1.0000 - val_loss: 7.3643e-06\n",
      "Epoch 100/100\n",
      "\u001b[1m236/236\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 349ms/step - Precision: 1.0000 - Recall: 1.0000 - accuracy: 1.0000 - f1_score: 1.0000 - loss: 7.4232e-06 - val_Precision: 1.0000 - val_Recall: 1.0000 - val_accuracy: 1.0000 - val_f1_score: 1.0000 - val_loss: 6.4592e-06\n"
     ]
    }
   ],
   "source": [
    "# Train the model and capture the history\n",
    "history = cnn.fit(\n",
    "    training_set1,\n",
    "    validation_data=test_set1,\n",
    "    epochs=100\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e0f9d853-600c-4be8-a7bc-6491d38133bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save Loss plot\n",
    "plt.figure()\n",
    "plt.plot(history.history['loss'], label='Train Loss')\n",
    "plt.plot(history.history['val_loss'], label='Validation Loss')\n",
    "plt.legend()\n",
    "plt.title(\"Loss\")\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.savefig('loss_plot_bigru.png')  # Save the plot as a PNG file\n",
    "plt.close()\n",
    "\n",
    "# Save Accuracy plot\n",
    "plt.figure()\n",
    "plt.plot(history.history['accuracy'], label='Train Accuracy')\n",
    "plt.plot(history.history['val_accuracy'], label='Validation Accuracy')\n",
    "plt.legend()\n",
    "plt.title(\"Accuracy\")\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.savefig('accuracy_plot_bigru.png')  # Save the plot as a PNG file\n",
    "plt.close()\n",
    "\n",
    "# Save Precision plot (Correct key for precision)\n",
    "plt.figure()\n",
    "plt.plot(history.history['Precision'], label='Train Precision')  # Corrected for precision\n",
    "plt.plot(history.history['val_Precision'], label='Validation Precision')  # Corrected for validation precision\n",
    "plt.legend()\n",
    "plt.title(\"Precision\")\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Precision')\n",
    "plt.savefig('precision_plot_bigru.png')  # Save the plot as a PNG file\n",
    "plt.close()\n",
    "\n",
    "# Save Recall plot (Correct key for recall)\n",
    "plt.figure()\n",
    "plt.plot(history.history['Recall'], label='Train Recall')  # Corrected for recall\n",
    "plt.plot(history.history['val_Recall'], label='Validation Recall')  # Corrected for validation recall\n",
    "plt.legend()\n",
    "plt.title(\"Recall\")\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Recall')\n",
    "plt.savefig('recall_plot_bigru.png')  # Save the plot as a PNG file\n",
    "plt.close()\n",
    "\n",
    "# Save F1 Score plot (Correct key for F1 score)\n",
    "plt.figure()\n",
    "plt.plot(history.history['f1_score'], label='Train F1 Score')  # Corrected for F1 score\n",
    "plt.plot(history.history['val_f1_score'], label='Validation F1 Score')  # Corrected for validation F1 score\n",
    "plt.legend()\n",
    "plt.title(\"F1 Score\")\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('F1 Score')\n",
    "plt.savefig('f1_score_plot_bigru.png')  # Save the plot as a PNG file\n",
    "plt.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb117861-40c6-47c8-8ab9-4ccc00b02fe9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

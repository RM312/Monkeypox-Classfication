{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1cb9f400-45be-4ea7-8f76-3ec628662ab5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a238b102-25b3-49c6-9543-d0d231db87b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 7532 images belonging to 6 classes.\n"
     ]
    }
   ],
   "source": [
    "# Data Augmentation for Training\n",
    "train_datagen = ImageDataGenerator(rescale=1./255,\n",
    "                                   shear_range=0.2,\n",
    "                                   zoom_range=0.2,\n",
    "                                   horizontal_flip=True)\n",
    "training_set = train_datagen.flow_from_directory(\n",
    "    \"Monkeypox/archive (60)/Augmented Images/Augmented Images/FOLDS_AUG/fold3_AUG/Train/\",\n",
    "    target_size=(64, 64),\n",
    "    batch_size=32,\n",
    "    class_mode='categorical',  # Use 'categorical' for one-hot encoded labels\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8fb216c3-5b66-457b-a91c-041e2e2ed081",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 7532 images belonging to 6 classes.\n"
     ]
    }
   ],
   "source": [
    "test_datagen = ImageDataGenerator(rescale=1./255)\n",
    "validation_set = test_datagen.flow_from_directory(\n",
    "    \"Monkeypox/archive (60)/Augmented Images/Augmented Images/FOLDS_AUG/fold3_AUG/Train/\",\n",
    "    target_size=(64, 64),\n",
    "    batch_size=32,\n",
    "    class_mode='categorical',  # Use 'categorical' for one-hot encoded labels\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bddc2df4-7c75-46d0-98f5-980ed6b9e5b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Custom F1 Score Metric\n",
    "class F1Score(tf.keras.metrics.Metric):\n",
    "    def __init__(self, name='f1_score', **kwargs):\n",
    "        super(F1Score, self).__init__(name=name, **kwargs)\n",
    "        self.precision = tf.keras.metrics.Precision()\n",
    "        self.recall = tf.keras.metrics.Recall()\n",
    "\n",
    "    def update_state(self, y_true, y_pred, sample_weight=None):\n",
    "        # Update the precision and recall for each batch\n",
    "        self.precision.update_state(y_true, y_pred, sample_weight)\n",
    "        self.recall.update_state(y_true, y_pred, sample_weight)\n",
    "\n",
    "    def result(self):\n",
    "        # Calculate F1 score as the harmonic mean of precision and recall\n",
    "        precision = self.precision.result()\n",
    "        recall = self.recall.result()\n",
    "        return 2 * (precision * recall) / (precision + recall + tf.keras.backend.epsilon())\n",
    "\n",
    "    def reset_states(self):\n",
    "        self.precision.reset_states()\n",
    "        self.recall.reset_states()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1104605e-1f71-4beb-bf4b-10a575710ad9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build the Bi-LSTM Model\n",
    "bi_lstm_model = tf.keras.models.Sequential()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a51a370b-dcb7-45d8-b895-b01a722a27ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\KIIT\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\layers\\reshaping\\flatten.py:37: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    }
   ],
   "source": [
    "# Flatten and Reshape for Bi-LSTM\n",
    "bi_lstm_model.add(tf.keras.layers.Flatten(input_shape=(64, 64, 3)))\n",
    "bi_lstm_model.add(tf.keras.layers.Reshape((16, -1)))  # Reshape to (time_steps, features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "db1e7dc9-e2fb-429e-a587-3c30a1bd61c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bidirectional LSTM Layer\n",
    "bi_lstm_model.add(tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(units=64, activation='tanh', return_sequences=False)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9d743133-8ef0-4862-b6c5-369f5b61ef25",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fully Connected Layers\n",
    "bi_lstm_model.add(tf.keras.layers.Dense(units=128, activation='relu'))\n",
    "bi_lstm_model.add(tf.keras.layers.Dense(6, activation='softmax'))  # 6 classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "bb1bdca7-54a7-40a3-a13c-4f029643de49",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile the model with Precision, Recall, and F1 Score\n",
    "bi_lstm_model.compile(\n",
    "    optimizer='adam',\n",
    "    loss='categorical_crossentropy',  # Use categorical_crossentropy for one-hot encoded labels\n",
    "    metrics=[\n",
    "        'accuracy',\n",
    "        tf.keras.metrics.Precision(name='precision'),\n",
    "        tf.keras.metrics.Recall(name='recall'),\n",
    "        F1Score(name='f1_score')  # Add custom F1 score metric\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2d2e02fe-f0c8-4453-983c-c9b6d58b955b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\KIIT\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\trainers\\data_adapters\\py_dataset_adapter.py:121: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
      "  self._warn_if_super_not_called()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "\u001b[1m236/236\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 289ms/step - accuracy: 0.3851 - f1_score: 0.1006 - loss: 1.5949 - precision: 0.4890 - recall: 0.0567"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\KIIT\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\trainers\\data_adapters\\py_dataset_adapter.py:121: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
      "  self._warn_if_super_not_called()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m236/236\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m109s\u001b[0m 404ms/step - accuracy: 0.3852 - f1_score: 0.1007 - loss: 1.5948 - precision: 0.4892 - recall: 0.0568 - val_accuracy: 0.4133 - val_f1_score: 0.1287 - val_loss: 1.5196 - val_precision: 0.6301 - val_recall: 0.0717\n",
      "Epoch 2/100\n",
      "\u001b[1m236/236\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m93s\u001b[0m 396ms/step - accuracy: 0.4094 - f1_score: 0.1566 - loss: 1.5222 - precision: 0.5812 - recall: 0.0906 - val_accuracy: 0.4271 - val_f1_score: 0.1971 - val_loss: 1.4758 - val_precision: 0.6046 - val_recall: 0.1178\n",
      "Epoch 3/100\n",
      "\u001b[1m236/236\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m123s\u001b[0m 524ms/step - accuracy: 0.4233 - f1_score: 0.1862 - loss: 1.4884 - precision: 0.5947 - recall: 0.1106 - val_accuracy: 0.4401 - val_f1_score: 0.2712 - val_loss: 1.4524 - val_precision: 0.5728 - val_recall: 0.1776\n",
      "Epoch 4/100\n",
      "\u001b[1m236/236\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m126s\u001b[0m 533ms/step - accuracy: 0.4403 - f1_score: 0.2273 - loss: 1.4466 - precision: 0.5948 - recall: 0.1408 - val_accuracy: 0.4399 - val_f1_score: 0.2524 - val_loss: 1.4282 - val_precision: 0.6445 - val_recall: 0.1569\n",
      "Epoch 5/100\n",
      "\u001b[1m236/236\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m139s\u001b[0m 587ms/step - accuracy: 0.4622 - f1_score: 0.2577 - loss: 1.4070 - precision: 0.6216 - recall: 0.1628 - val_accuracy: 0.4672 - val_f1_score: 0.1825 - val_loss: 1.3969 - val_precision: 0.7336 - val_recall: 0.1042\n",
      "Epoch 6/100\n",
      "\u001b[1m236/236\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m146s\u001b[0m 620ms/step - accuracy: 0.4546 - f1_score: 0.2756 - loss: 1.3984 - precision: 0.6119 - recall: 0.1787 - val_accuracy: 0.4891 - val_f1_score: 0.2983 - val_loss: 1.3415 - val_precision: 0.6651 - val_recall: 0.1922\n",
      "Epoch 7/100\n",
      "\u001b[1m236/236\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m51s\u001b[0m 213ms/step - accuracy: 0.4696 - f1_score: 0.3140 - loss: 1.3682 - precision: 0.6375 - recall: 0.2084 - val_accuracy: 0.4934 - val_f1_score: 0.2739 - val_loss: 1.3325 - val_precision: 0.6963 - val_recall: 0.1705\n",
      "Epoch 8/100\n",
      "\u001b[1m236/236\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m89s\u001b[0m 375ms/step - accuracy: 0.4838 - f1_score: 0.3388 - loss: 1.3422 - precision: 0.6562 - recall: 0.2289 - val_accuracy: 0.5101 - val_f1_score: 0.3404 - val_loss: 1.2872 - val_precision: 0.6858 - val_recall: 0.2264\n",
      "Epoch 9/100\n",
      "\u001b[1m236/236\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m133s\u001b[0m 565ms/step - accuracy: 0.4860 - f1_score: 0.3367 - loss: 1.3424 - precision: 0.6269 - recall: 0.2302 - val_accuracy: 0.4935 - val_f1_score: 0.3566 - val_loss: 1.3049 - val_precision: 0.6781 - val_recall: 0.2419\n",
      "Epoch 10/100\n",
      "\u001b[1m236/236\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m152s\u001b[0m 643ms/step - accuracy: 0.4946 - f1_score: 0.3703 - loss: 1.3049 - precision: 0.6475 - recall: 0.2595 - val_accuracy: 0.5243 - val_f1_score: 0.4330 - val_loss: 1.2616 - val_precision: 0.6584 - val_recall: 0.3226\n",
      "Epoch 11/100\n",
      "\u001b[1m236/236\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m175s\u001b[0m 741ms/step - accuracy: 0.5124 - f1_score: 0.4073 - loss: 1.2731 - precision: 0.6511 - recall: 0.2966 - val_accuracy: 0.5216 - val_f1_score: 0.4594 - val_loss: 1.2419 - val_precision: 0.6318 - val_recall: 0.3609\n",
      "Epoch 12/100\n",
      "\u001b[1m236/236\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m149s\u001b[0m 628ms/step - accuracy: 0.5308 - f1_score: 0.4293 - loss: 1.2382 - precision: 0.6632 - recall: 0.3175 - val_accuracy: 0.5544 - val_f1_score: 0.4366 - val_loss: 1.1921 - val_precision: 0.6945 - val_recall: 0.3184\n",
      "Epoch 13/100\n",
      "\u001b[1m236/236\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m288s\u001b[0m 991ms/step - accuracy: 0.5332 - f1_score: 0.4442 - loss: 1.2171 - precision: 0.6700 - recall: 0.3323 - val_accuracy: 0.5420 - val_f1_score: 0.4181 - val_loss: 1.1901 - val_precision: 0.7252 - val_recall: 0.2937\n",
      "Epoch 14/100\n",
      "\u001b[1m236/236\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m229s\u001b[0m 971ms/step - accuracy: 0.5367 - f1_score: 0.4224 - loss: 1.2129 - precision: 0.6764 - recall: 0.3073 - val_accuracy: 0.5640 - val_f1_score: 0.4618 - val_loss: 1.1473 - val_precision: 0.7194 - val_recall: 0.3400\n",
      "Epoch 15/100\n",
      "\u001b[1m236/236\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m225s\u001b[0m 955ms/step - accuracy: 0.5447 - f1_score: 0.4626 - loss: 1.1927 - precision: 0.6796 - recall: 0.3508 - val_accuracy: 0.5616 - val_f1_score: 0.4707 - val_loss: 1.1486 - val_precision: 0.6918 - val_recall: 0.3567\n",
      "Epoch 16/100\n",
      "\u001b[1m236/236\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m233s\u001b[0m 987ms/step - accuracy: 0.5445 - f1_score: 0.4750 - loss: 1.1768 - precision: 0.6877 - recall: 0.3629 - val_accuracy: 0.5571 - val_f1_score: 0.4779 - val_loss: 1.1493 - val_precision: 0.6884 - val_recall: 0.3660\n",
      "Epoch 17/100\n",
      "\u001b[1m236/236\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m228s\u001b[0m 967ms/step - accuracy: 0.5482 - f1_score: 0.4678 - loss: 1.1628 - precision: 0.6816 - recall: 0.3562 - val_accuracy: 0.5851 - val_f1_score: 0.4828 - val_loss: 1.1247 - val_precision: 0.7501 - val_recall: 0.3559\n",
      "Epoch 18/100\n",
      "\u001b[1m236/236\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m235s\u001b[0m 994ms/step - accuracy: 0.5575 - f1_score: 0.4856 - loss: 1.1560 - precision: 0.7025 - recall: 0.3711 - val_accuracy: 0.5669 - val_f1_score: 0.4732 - val_loss: 1.1282 - val_precision: 0.7446 - val_recall: 0.3468\n",
      "Epoch 19/100\n",
      "\u001b[1m236/236\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m261s\u001b[0m 989ms/step - accuracy: 0.5804 - f1_score: 0.4966 - loss: 1.1245 - precision: 0.7002 - recall: 0.3849 - val_accuracy: 0.5899 - val_f1_score: 0.5192 - val_loss: 1.0766 - val_precision: 0.7463 - val_recall: 0.3980\n",
      "Epoch 20/100\n",
      "\u001b[1m236/236\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m236s\u001b[0m 998ms/step - accuracy: 0.5806 - f1_score: 0.5079 - loss: 1.1031 - precision: 0.7052 - recall: 0.3970 - val_accuracy: 0.6037 - val_f1_score: 0.5242 - val_loss: 1.0490 - val_precision: 0.7670 - val_recall: 0.3982\n",
      "Epoch 21/100\n",
      "\u001b[1m236/236\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m214s\u001b[0m 908ms/step - accuracy: 0.5801 - f1_score: 0.5206 - loss: 1.0855 - precision: 0.7131 - recall: 0.4101 - val_accuracy: 0.6184 - val_f1_score: 0.5487 - val_loss: 1.0184 - val_precision: 0.7613 - val_recall: 0.4290\n",
      "Epoch 22/100\n",
      "\u001b[1m236/236\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m256s\u001b[0m 1s/step - accuracy: 0.5914 - f1_score: 0.5325 - loss: 1.0574 - precision: 0.7251 - recall: 0.4209 - val_accuracy: 0.6289 - val_f1_score: 0.5451 - val_loss: 1.0135 - val_precision: 0.7875 - val_recall: 0.4168\n",
      "Epoch 23/100\n",
      "\u001b[1m236/236\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m220s\u001b[0m 934ms/step - accuracy: 0.6009 - f1_score: 0.5379 - loss: 1.0577 - precision: 0.7338 - recall: 0.4248 - val_accuracy: 0.6333 - val_f1_score: 0.6062 - val_loss: 0.9814 - val_precision: 0.7408 - val_recall: 0.5130\n",
      "Epoch 24/100\n",
      "\u001b[1m236/236\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m157s\u001b[0m 663ms/step - accuracy: 0.6144 - f1_score: 0.5551 - loss: 1.0299 - precision: 0.7273 - recall: 0.4492 - val_accuracy: 0.6190 - val_f1_score: 0.5406 - val_loss: 1.0037 - val_precision: 0.7587 - val_recall: 0.4199\n",
      "Epoch 25/100\n",
      "\u001b[1m236/236\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m117s\u001b[0m 496ms/step - accuracy: 0.6093 - f1_score: 0.5567 - loss: 1.0293 - precision: 0.7388 - recall: 0.4468 - val_accuracy: 0.6298 - val_f1_score: 0.5832 - val_loss: 0.9637 - val_precision: 0.7599 - val_recall: 0.4732\n",
      "Epoch 26/100\n",
      "\u001b[1m236/236\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m119s\u001b[0m 504ms/step - accuracy: 0.6179 - f1_score: 0.5647 - loss: 1.0098 - precision: 0.7360 - recall: 0.4580 - val_accuracy: 0.6296 - val_f1_score: 0.5774 - val_loss: 0.9986 - val_precision: 0.7708 - val_recall: 0.4616\n",
      "Epoch 27/100\n",
      "\u001b[1m236/236\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m137s\u001b[0m 580ms/step - accuracy: 0.6236 - f1_score: 0.5718 - loss: 0.9905 - precision: 0.7320 - recall: 0.4692 - val_accuracy: 0.6313 - val_f1_score: 0.5960 - val_loss: 0.9664 - val_precision: 0.7543 - val_recall: 0.4927\n",
      "Epoch 28/100\n",
      "\u001b[1m236/236\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m139s\u001b[0m 587ms/step - accuracy: 0.6251 - f1_score: 0.5848 - loss: 0.9843 - precision: 0.7450 - recall: 0.4814 - val_accuracy: 0.6572 - val_f1_score: 0.6096 - val_loss: 0.9199 - val_precision: 0.7997 - val_recall: 0.4926\n",
      "Epoch 29/100\n",
      "\u001b[1m236/236\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m141s\u001b[0m 595ms/step - accuracy: 0.6416 - f1_score: 0.5947 - loss: 0.9632 - precision: 0.7577 - recall: 0.4896 - val_accuracy: 0.6418 - val_f1_score: 0.6079 - val_loss: 0.9465 - val_precision: 0.7212 - val_recall: 0.5254\n",
      "Epoch 30/100\n",
      "\u001b[1m236/236\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m134s\u001b[0m 568ms/step - accuracy: 0.6319 - f1_score: 0.5907 - loss: 0.9613 - precision: 0.7509 - recall: 0.4869 - val_accuracy: 0.6654 - val_f1_score: 0.6367 - val_loss: 0.9012 - val_precision: 0.7635 - val_recall: 0.5461\n",
      "Epoch 31/100\n",
      "\u001b[1m236/236\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m137s\u001b[0m 582ms/step - accuracy: 0.6458 - f1_score: 0.6080 - loss: 0.9380 - precision: 0.7547 - recall: 0.5091 - val_accuracy: 0.6673 - val_f1_score: 0.6210 - val_loss: 0.8912 - val_precision: 0.8031 - val_recall: 0.5062\n",
      "Epoch 32/100\n",
      "\u001b[1m236/236\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m137s\u001b[0m 580ms/step - accuracy: 0.6506 - f1_score: 0.6109 - loss: 0.9324 - precision: 0.7629 - recall: 0.5095 - val_accuracy: 0.6737 - val_f1_score: 0.6388 - val_loss: 0.8729 - val_precision: 0.7731 - val_recall: 0.5442\n",
      "Epoch 33/100\n",
      "\u001b[1m236/236\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m135s\u001b[0m 572ms/step - accuracy: 0.6513 - f1_score: 0.6141 - loss: 0.9125 - precision: 0.7585 - recall: 0.5160 - val_accuracy: 0.6772 - val_f1_score: 0.6226 - val_loss: 0.8635 - val_precision: 0.8272 - val_recall: 0.4991\n",
      "Epoch 34/100\n",
      "\u001b[1m236/236\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m138s\u001b[0m 584ms/step - accuracy: 0.6584 - f1_score: 0.6174 - loss: 0.9024 - precision: 0.7716 - recall: 0.5149 - val_accuracy: 0.6730 - val_f1_score: 0.6568 - val_loss: 0.8520 - val_precision: 0.7670 - val_recall: 0.5743\n",
      "Epoch 35/100\n",
      "\u001b[1m236/236\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m144s\u001b[0m 608ms/step - accuracy: 0.6600 - f1_score: 0.6353 - loss: 0.8934 - precision: 0.7820 - recall: 0.5351 - val_accuracy: 0.6960 - val_f1_score: 0.6525 - val_loss: 0.8253 - val_precision: 0.8141 - val_recall: 0.5443\n",
      "Epoch 36/100\n",
      "\u001b[1m236/236\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m133s\u001b[0m 563ms/step - accuracy: 0.6654 - f1_score: 0.6377 - loss: 0.8747 - precision: 0.7702 - recall: 0.5442 - val_accuracy: 0.6880 - val_f1_score: 0.6587 - val_loss: 0.8332 - val_precision: 0.7887 - val_recall: 0.5655\n",
      "Epoch 37/100\n",
      "\u001b[1m236/236\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m130s\u001b[0m 550ms/step - accuracy: 0.6638 - f1_score: 0.6292 - loss: 0.8919 - precision: 0.7592 - recall: 0.5374 - val_accuracy: 0.7072 - val_f1_score: 0.6801 - val_loss: 0.7911 - val_precision: 0.8270 - val_recall: 0.5775\n",
      "Epoch 38/100\n",
      "\u001b[1m236/236\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m138s\u001b[0m 584ms/step - accuracy: 0.6718 - f1_score: 0.6471 - loss: 0.8659 - precision: 0.7802 - recall: 0.5529 - val_accuracy: 0.7114 - val_f1_score: 0.6834 - val_loss: 0.7748 - val_precision: 0.8049 - val_recall: 0.5937\n",
      "Epoch 39/100\n",
      "\u001b[1m236/236\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m136s\u001b[0m 578ms/step - accuracy: 0.6907 - f1_score: 0.6632 - loss: 0.8349 - precision: 0.7897 - recall: 0.5719 - val_accuracy: 0.6826 - val_f1_score: 0.6523 - val_loss: 0.8247 - val_precision: 0.7913 - val_recall: 0.5548\n",
      "Epoch 40/100\n",
      "\u001b[1m236/236\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m135s\u001b[0m 572ms/step - accuracy: 0.6774 - f1_score: 0.6471 - loss: 0.8526 - precision: 0.7769 - recall: 0.5546 - val_accuracy: 0.7157 - val_f1_score: 0.6949 - val_loss: 0.7678 - val_precision: 0.8290 - val_recall: 0.5981\n",
      "Epoch 41/100\n",
      "\u001b[1m236/236\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m138s\u001b[0m 585ms/step - accuracy: 0.6673 - f1_score: 0.6422 - loss: 0.8548 - precision: 0.7678 - recall: 0.5520 - val_accuracy: 0.7183 - val_f1_score: 0.6932 - val_loss: 0.7545 - val_precision: 0.8234 - val_recall: 0.5985\n",
      "Epoch 42/100\n",
      "\u001b[1m236/236\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m146s\u001b[0m 617ms/step - accuracy: 0.6858 - f1_score: 0.6482 - loss: 0.8327 - precision: 0.7764 - recall: 0.5565 - val_accuracy: 0.7030 - val_f1_score: 0.6762 - val_loss: 0.7838 - val_precision: 0.8082 - val_recall: 0.5813\n",
      "Epoch 43/100\n",
      "\u001b[1m236/236\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m181s\u001b[0m 768ms/step - accuracy: 0.6891 - f1_score: 0.6565 - loss: 0.8291 - precision: 0.7881 - recall: 0.5627 - val_accuracy: 0.7252 - val_f1_score: 0.7000 - val_loss: 0.7411 - val_precision: 0.8383 - val_recall: 0.6009\n",
      "Epoch 45/100\n",
      "\u001b[1m236/236\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m120s\u001b[0m 509ms/step - accuracy: 0.6918 - f1_score: 0.6746 - loss: 0.8059 - precision: 0.7914 - recall: 0.5879 - val_accuracy: 0.7297 - val_f1_score: 0.7027 - val_loss: 0.7294 - val_precision: 0.8387 - val_recall: 0.6046\n",
      "Epoch 46/100\n",
      "\u001b[1m236/236\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m167s\u001b[0m 711ms/step - accuracy: 0.7035 - f1_score: 0.6807 - loss: 0.8029 - precision: 0.8013 - recall: 0.5916 - val_accuracy: 0.7357 - val_f1_score: 0.7228 - val_loss: 0.7174 - val_precision: 0.8278 - val_recall: 0.6414\n",
      "Epoch 47/100\n",
      "\u001b[1m236/236\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m156s\u001b[0m 660ms/step - accuracy: 0.7003 - f1_score: 0.6817 - loss: 0.7974 - precision: 0.8029 - recall: 0.5924 - val_accuracy: 0.7038 - val_f1_score: 0.6832 - val_loss: 0.8001 - val_precision: 0.8083 - val_recall: 0.5916\n",
      "Epoch 48/100\n",
      "\u001b[1m236/236\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m191s\u001b[0m 809ms/step - accuracy: 0.6987 - f1_score: 0.6749 - loss: 0.8171 - precision: 0.7887 - recall: 0.5899 - val_accuracy: 0.7436 - val_f1_score: 0.7185 - val_loss: 0.7155 - val_precision: 0.8360 - val_recall: 0.6300\n",
      "Epoch 49/100\n",
      "\u001b[1m236/236\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m232s\u001b[0m 986ms/step - accuracy: 0.7089 - f1_score: 0.6889 - loss: 0.7781 - precision: 0.8017 - recall: 0.6039 - val_accuracy: 0.7455 - val_f1_score: 0.7284 - val_loss: 0.6875 - val_precision: 0.8361 - val_recall: 0.6452\n",
      "Epoch 50/100\n",
      "\u001b[1m236/236\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m246s\u001b[0m 1s/step - accuracy: 0.7222 - f1_score: 0.7023 - loss: 0.7575 - precision: 0.8130 - recall: 0.6182 - val_accuracy: 0.7219 - val_f1_score: 0.7047 - val_loss: 0.7380 - val_precision: 0.8203 - val_recall: 0.6176\n",
      "Epoch 51/100\n",
      "\u001b[1m236/236\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m134s\u001b[0m 567ms/step - accuracy: 0.7164 - f1_score: 0.7029 - loss: 0.7579 - precision: 0.8192 - recall: 0.6156 - val_accuracy: 0.7552 - val_f1_score: 0.7343 - val_loss: 0.6874 - val_precision: 0.8436 - val_recall: 0.6500\n",
      "Epoch 52/100\n",
      "\u001b[1m236/236\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m253s\u001b[0m 1s/step - accuracy: 0.7246 - f1_score: 0.7119 - loss: 0.7313 - precision: 0.8240 - recall: 0.6266 - val_accuracy: 0.7444 - val_f1_score: 0.7335 - val_loss: 0.6881 - val_precision: 0.8196 - val_recall: 0.6637\n",
      "Epoch 53/100\n",
      "\u001b[1m236/236\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m227s\u001b[0m 962ms/step - accuracy: 0.7200 - f1_score: 0.7021 - loss: 0.7556 - precision: 0.8089 - recall: 0.6205 - val_accuracy: 0.7529 - val_f1_score: 0.7354 - val_loss: 0.6772 - val_precision: 0.8366 - val_recall: 0.6560\n",
      "Epoch 54/100\n",
      "\u001b[1m236/236\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m241s\u001b[0m 1s/step - accuracy: 0.7267 - f1_score: 0.7069 - loss: 0.7373 - precision: 0.8127 - recall: 0.6256 - val_accuracy: 0.7623 - val_f1_score: 0.7419 - val_loss: 0.6507 - val_precision: 0.8484 - val_recall: 0.6592\n",
      "Epoch 55/100\n",
      "\u001b[1m236/236\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m235s\u001b[0m 995ms/step - accuracy: 0.7238 - f1_score: 0.7146 - loss: 0.7308 - precision: 0.8178 - recall: 0.6345 - val_accuracy: 0.7540 - val_f1_score: 0.7395 - val_loss: 0.6594 - val_precision: 0.8297 - val_recall: 0.6670\n",
      "Epoch 56/100\n",
      "\u001b[1m236/236\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m209s\u001b[0m 887ms/step - accuracy: 0.7339 - f1_score: 0.7207 - loss: 0.7020 - precision: 0.8180 - recall: 0.6440 - val_accuracy: 0.7377 - val_f1_score: 0.7138 - val_loss: 0.7194 - val_precision: 0.8502 - val_recall: 0.6151\n",
      "Epoch 57/100\n",
      "\u001b[1m236/236\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m239s\u001b[0m 1s/step - accuracy: 0.7193 - f1_score: 0.7023 - loss: 0.7439 - precision: 0.8128 - recall: 0.6186 - val_accuracy: 0.7467 - val_f1_score: 0.7290 - val_loss: 0.6799 - val_precision: 0.8345 - val_recall: 0.6472\n",
      "Epoch 58/100\n",
      "\u001b[1m236/236\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m238s\u001b[0m 1s/step - accuracy: 0.7411 - f1_score: 0.7329 - loss: 0.6991 - precision: 0.8325 - recall: 0.6546 - val_accuracy: 0.7781 - val_f1_score: 0.7676 - val_loss: 0.6100 - val_precision: 0.8540 - val_recall: 0.6972\n",
      "Epoch 59/100\n",
      "\u001b[1m236/236\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m207s\u001b[0m 878ms/step - accuracy: 0.7396 - f1_score: 0.7298 - loss: 0.6917 - precision: 0.8224 - recall: 0.6560 - val_accuracy: 0.7811 - val_f1_score: 0.7714 - val_loss: 0.5924 - val_precision: 0.8531 - val_recall: 0.7039\n",
      "Epoch 61/100\n",
      "\u001b[1m236/236\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m227s\u001b[0m 962ms/step - accuracy: 0.7514 - f1_score: 0.7391 - loss: 0.6858 - precision: 0.8332 - recall: 0.6642 - val_accuracy: 0.7853 - val_f1_score: 0.7706 - val_loss: 0.6035 - val_precision: 0.8762 - val_recall: 0.6877\n",
      "Epoch 62/100\n",
      "\u001b[1m236/236\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m231s\u001b[0m 978ms/step - accuracy: 0.7441 - f1_score: 0.7363 - loss: 0.6818 - precision: 0.8295 - recall: 0.6620 - val_accuracy: 0.7862 - val_f1_score: 0.7698 - val_loss: 0.6030 - val_precision: 0.8636 - val_recall: 0.6944\n",
      "Epoch 63/100\n",
      "\u001b[1m236/236\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m273s\u001b[0m 1s/step - accuracy: 0.7469 - f1_score: 0.7402 - loss: 0.6768 - precision: 0.8271 - recall: 0.6699 - val_accuracy: 0.7928 - val_f1_score: 0.7837 - val_loss: 0.5788 - val_precision: 0.8551 - val_recall: 0.7233\n",
      "Epoch 67/100\n",
      "\u001b[1m236/236\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m273s\u001b[0m 1s/step - accuracy: 0.7695 - f1_score: 0.7596 - loss: 0.6228 - precision: 0.8399 - recall: 0.6933 - val_accuracy: 0.7970 - val_f1_score: 0.7906 - val_loss: 0.5538 - val_precision: 0.8689 - val_recall: 0.7252\n",
      "Epoch 75/100\n",
      "\u001b[1m236/236\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m179s\u001b[0m 758ms/step - accuracy: 0.7731 - f1_score: 0.7647 - loss: 0.6183 - precision: 0.8415 - recall: 0.7009 - val_accuracy: 0.7978 - val_f1_score: 0.7842 - val_loss: 0.5662 - val_precision: 0.8683 - val_recall: 0.7149\n",
      "Epoch 77/100\n",
      "\u001b[1m236/236\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m247s\u001b[0m 1s/step - accuracy: 0.7769 - f1_score: 0.7729 - loss: 0.6123 - precision: 0.8472 - recall: 0.7106 - val_accuracy: 0.8044 - val_f1_score: 0.7913 - val_loss: 0.5419 - val_precision: 0.8718 - val_recall: 0.7244\n",
      "Epoch 78/100\n",
      "\u001b[1m236/236\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m258s\u001b[0m 1s/step - accuracy: 0.7795 - f1_score: 0.7706 - loss: 0.6045 - precision: 0.8444 - recall: 0.7087 - val_accuracy: 0.8103 - val_f1_score: 0.8075 - val_loss: 0.5162 - val_precision: 0.8824 - val_recall: 0.7443\n",
      "Epoch 79/100\n",
      "\u001b[1m236/236\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m259s\u001b[0m 1s/step - accuracy: 0.7732 - f1_score: 0.7652 - loss: 0.6149 - precision: 0.8435 - recall: 0.7002 - val_accuracy: 0.8344 - val_f1_score: 0.8250 - val_loss: 0.4820 - val_precision: 0.8906 - val_recall: 0.7685\n",
      "Epoch 80/100\n",
      "\u001b[1m236/236\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m255s\u001b[0m 1s/step - accuracy: 0.7916 - f1_score: 0.7859 - loss: 0.5779 - precision: 0.8541 - recall: 0.7278 - val_accuracy: 0.8099 - val_f1_score: 0.8038 - val_loss: 0.5197 - val_precision: 0.8776 - val_recall: 0.7415\n",
      "Epoch 81/100\n",
      "\u001b[1m236/236\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m250s\u001b[0m 1s/step - accuracy: 0.7932 - f1_score: 0.7838 - loss: 0.5807 - precision: 0.8544 - recall: 0.7240 - val_accuracy: 0.8099 - val_f1_score: 0.8043 - val_loss: 0.5316 - val_precision: 0.8685 - val_recall: 0.7489\n",
      "Epoch 82/100\n",
      "\u001b[1m236/236\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m268s\u001b[0m 1s/step - accuracy: 0.7856 - f1_score: 0.7824 - loss: 0.5952 - precision: 0.8518 - recall: 0.7236 - val_accuracy: 0.8169 - val_f1_score: 0.8165 - val_loss: 0.5002 - val_precision: 0.8835 - val_recall: 0.7589\n",
      "Epoch 83/100\n",
      "\u001b[1m236/236\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m253s\u001b[0m 1s/step - accuracy: 0.7951 - f1_score: 0.7860 - loss: 0.5712 - precision: 0.8560 - recall: 0.7267 - val_accuracy: 0.8302 - val_f1_score: 0.8243 - val_loss: 0.4741 - val_precision: 0.8863 - val_recall: 0.7703\n",
      "Epoch 84/100\n",
      "\u001b[1m236/236\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m253s\u001b[0m 1s/step - accuracy: 0.7991 - f1_score: 0.7914 - loss: 0.5645 - precision: 0.8567 - recall: 0.7354 - val_accuracy: 0.8196 - val_f1_score: 0.8126 - val_loss: 0.5173 - val_precision: 0.8810 - val_recall: 0.7541\n",
      "Epoch 85/100\n",
      "\u001b[1m236/236\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m258s\u001b[0m 1s/step - accuracy: 0.7958 - f1_score: 0.7856 - loss: 0.5678 - precision: 0.8506 - recall: 0.7299 - val_accuracy: 0.8123 - val_f1_score: 0.8109 - val_loss: 0.5255 - val_precision: 0.8760 - val_recall: 0.7548\n",
      "Epoch 86/100\n",
      "\u001b[1m236/236\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m230s\u001b[0m 976ms/step - accuracy: 0.7959 - f1_score: 0.7880 - loss: 0.5751 - precision: 0.8578 - recall: 0.7288 - val_accuracy: 0.8254 - val_f1_score: 0.8169 - val_loss: 0.4815 - val_precision: 0.8743 - val_recall: 0.7666\n",
      "Epoch 87/100\n",
      "\u001b[1m236/236\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m210s\u001b[0m 891ms/step - accuracy: 0.7917 - f1_score: 0.7811 - loss: 0.5834 - precision: 0.8454 - recall: 0.7260 - val_accuracy: 0.8384 - val_f1_score: 0.8334 - val_loss: 0.4681 - val_precision: 0.8997 - val_recall: 0.7762\n",
      "Epoch 88/100\n",
      "\u001b[1m236/236\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m230s\u001b[0m 976ms/step - accuracy: 0.7968 - f1_score: 0.7919 - loss: 0.5515 - precision: 0.8544 - recall: 0.7380 - val_accuracy: 0.8111 - val_f1_score: 0.8063 - val_loss: 0.5120 - val_precision: 0.8767 - val_recall: 0.7464\n",
      "Epoch 89/100\n",
      "\u001b[1m236/236\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m233s\u001b[0m 987ms/step - accuracy: 0.7921 - f1_score: 0.7885 - loss: 0.5654 - precision: 0.8530 - recall: 0.7330 - val_accuracy: 0.8314 - val_f1_score: 0.8238 - val_loss: 0.4763 - val_precision: 0.8922 - val_recall: 0.7651\n",
      "Epoch 90/100\n",
      "\u001b[1m236/236\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m233s\u001b[0m 989ms/step - accuracy: 0.7905 - f1_score: 0.7917 - loss: 0.5640 - precision: 0.8573 - recall: 0.7355 - val_accuracy: 0.8015 - val_f1_score: 0.8046 - val_loss: 0.5458 - val_precision: 0.8519 - val_recall: 0.7622\n",
      "Epoch 91/100\n",
      "\u001b[1m236/236\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m235s\u001b[0m 997ms/step - accuracy: 0.8000 - f1_score: 0.7948 - loss: 0.5512 - precision: 0.8563 - recall: 0.7416 - val_accuracy: 0.8214 - val_f1_score: 0.8169 - val_loss: 0.4827 - val_precision: 0.8801 - val_recall: 0.7622\n",
      "Epoch 92/100\n",
      "\u001b[1m236/236\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m222s\u001b[0m 943ms/step - accuracy: 0.8073 - f1_score: 0.8022 - loss: 0.5417 - precision: 0.8632 - recall: 0.7493 - val_accuracy: 0.8401 - val_f1_score: 0.8305 - val_loss: 0.4543 - val_precision: 0.9004 - val_recall: 0.7707\n",
      "Epoch 93/100\n",
      "\u001b[1m236/236\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m209s\u001b[0m 887ms/step - accuracy: 0.7936 - f1_score: 0.7857 - loss: 0.5551 - precision: 0.8461 - recall: 0.7334 - val_accuracy: 0.8468 - val_f1_score: 0.8421 - val_loss: 0.4515 - val_precision: 0.9017 - val_recall: 0.7900\n",
      "Epoch 94/100\n",
      "\u001b[1m236/236\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m287s\u001b[0m 991ms/step - accuracy: 0.8034 - f1_score: 0.7960 - loss: 0.5277 - precision: 0.8566 - recall: 0.7434 - val_accuracy: 0.8561 - val_f1_score: 0.8539 - val_loss: 0.4167 - val_precision: 0.9012 - val_recall: 0.8113\n",
      "Epoch 95/100\n",
      "\u001b[1m236/236\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m211s\u001b[0m 895ms/step - accuracy: 0.7990 - f1_score: 0.7966 - loss: 0.5308 - precision: 0.8594 - recall: 0.7425 - val_accuracy: 0.8461 - val_f1_score: 0.8426 - val_loss: 0.4354 - val_precision: 0.9019 - val_recall: 0.7906\n",
      "Epoch 96/100\n",
      "\u001b[1m236/236\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m194s\u001b[0m 823ms/step - accuracy: 0.8081 - f1_score: 0.8044 - loss: 0.5192 - precision: 0.8640 - recall: 0.7526 - val_accuracy: 0.8521 - val_f1_score: 0.8479 - val_loss: 0.4278 - val_precision: 0.9021 - val_recall: 0.7998\n",
      "Epoch 97/100\n",
      "\u001b[1m236/236\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m206s\u001b[0m 873ms/step - accuracy: 0.8137 - f1_score: 0.8070 - loss: 0.5135 - precision: 0.8649 - recall: 0.7564 - val_accuracy: 0.8188 - val_f1_score: 0.8173 - val_loss: 0.4724 - val_precision: 0.8694 - val_recall: 0.7710\n",
      "Epoch 98/100\n",
      "\u001b[1m236/236\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m205s\u001b[0m 869ms/step - accuracy: 0.8137 - f1_score: 0.8082 - loss: 0.5141 - precision: 0.8672 - recall: 0.7568 - val_accuracy: 0.8533 - val_f1_score: 0.8461 - val_loss: 0.4280 - val_precision: 0.9046 - val_recall: 0.7946\n",
      "Epoch 99/100\n",
      "\u001b[1m236/236\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m155s\u001b[0m 659ms/step - accuracy: 0.8097 - f1_score: 0.8060 - loss: 0.5099 - precision: 0.8615 - recall: 0.7573 - val_accuracy: 0.8555 - val_f1_score: 0.8511 - val_loss: 0.4224 - val_precision: 0.8980 - val_recall: 0.8088\n",
      "Epoch 100/100\n",
      "\u001b[1m236/236\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m187s\u001b[0m 792ms/step - accuracy: 0.8153 - f1_score: 0.8158 - loss: 0.5039 - precision: 0.8670 - recall: 0.7704 - val_accuracy: 0.8412 - val_f1_score: 0.8347 - val_loss: 0.4374 - val_precision: 0.8902 - val_recall: 0.7857\n"
     ]
    }
   ],
   "source": [
    "# Train the model\n",
    "history = bi_lstm_model.fit(\n",
    "    x=training_set,\n",
    "    validation_data=validation_set,\n",
    "    epochs=100\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "596daebb-2ae7-4cfd-a7ad-3c18f58c5f30",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save Loss plot\n",
    "plt.figure()\n",
    "plt.plot(history.history['loss'], label='Train Loss')\n",
    "plt.plot(history.history['val_loss'], label='Validation Loss')\n",
    "plt.legend()\n",
    "plt.title(\"Loss\")\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.savefig('loss_plot_bilstm.png')  # Save the plot as a PNG file\n",
    "plt.close()\n",
    "\n",
    "# Save Accuracy plot\n",
    "plt.figure()\n",
    "plt.plot(history.history['accuracy'], label='Train Accuracy')\n",
    "plt.plot(history.history['val_accuracy'], label='Validation Accuracy')\n",
    "plt.legend()\n",
    "plt.title(\"Accuracy\")\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.savefig('accuracy_plot_bilstm.png')  # Save the plot as a PNG file\n",
    "plt.close()\n",
    "\n",
    "# Save Precision plot\n",
    "plt.figure()\n",
    "plt.plot(history.history['precision'], label='Train Precision')\n",
    "plt.plot(history.history['val_precision'], label='Validation Precision')\n",
    "plt.legend()\n",
    "plt.title(\"Precision\")\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Precision')\n",
    "plt.savefig('precision_plot_bilstm.png')  # Save the plot as a PNG file\n",
    "plt.close()\n",
    "\n",
    "# Save Recall plot\n",
    "plt.figure()\n",
    "plt.plot(history.history['recall'], label='Train Recall')\n",
    "plt.plot(history.history['val_recall'], label='Validation Recall')\n",
    "plt.legend()\n",
    "plt.title(\"Recall\")\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Recall')\n",
    "plt.savefig('recall_plot_bilstm.png')  # Save the plot as a PNG file\n",
    "plt.close()\n",
    "\n",
    "# Save F1 Score plot\n",
    "plt.figure()\n",
    "plt.plot(history.history['f1_score'], label='Train F1 Score')\n",
    "plt.plot(history.history['val_f1_score'], label='Validation F1 Score')\n",
    "plt.legend()\n",
    "plt.title(\"F1 Score\")\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('F1 Score')\n",
    "plt.savefig('f1_score_plot_bilstm.png')  # Save the plot as a PNG file\n",
    "plt.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9c4fd971-515e-4ab2-91ac-f44228efcbed",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                         </span>┃<span style=\"font-weight: bold\"> Output Shape                </span>┃<span style=\"font-weight: bold\">         Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
       "│ flatten (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)                    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">12288</span>)               │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ reshape (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Reshape</span>)                    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">768</span>)             │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ bidirectional (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Bidirectional</span>)        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)                 │         <span style=\"color: #00af00; text-decoration-color: #00af00\">426,496</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)                 │          <span style=\"color: #00af00; text-decoration-color: #00af00\">16,512</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">6</span>)                   │             <span style=\"color: #00af00; text-decoration-color: #00af00\">774</span> │\n",
       "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
       "│ flatten (\u001b[38;5;33mFlatten\u001b[0m)                    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m12288\u001b[0m)               │               \u001b[38;5;34m0\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ reshape (\u001b[38;5;33mReshape\u001b[0m)                    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m768\u001b[0m)             │               \u001b[38;5;34m0\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ bidirectional (\u001b[38;5;33mBidirectional\u001b[0m)        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)                 │         \u001b[38;5;34m426,496\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense (\u001b[38;5;33mDense\u001b[0m)                        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)                 │          \u001b[38;5;34m16,512\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)                      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m6\u001b[0m)                   │             \u001b[38;5;34m774\u001b[0m │\n",
       "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,331,348</span> (5.08 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m1,331,348\u001b[0m (5.08 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">443,782</span> (1.69 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m443,782\u001b[0m (1.69 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Optimizer params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">887,566</span> (3.39 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Optimizer params: \u001b[0m\u001b[38;5;34m887,566\u001b[0m (3.39 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "bi_lstm_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "114a8aef-1d99-4b24-ab51-dfc3d5d314a5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

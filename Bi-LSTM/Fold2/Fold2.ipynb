{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a31ecc82-8bff-4619-a2fa-815d5a2ca3d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d074b74c-da78-4b1a-9191-d878a359b2cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 7126 images belonging to 6 classes.\n"
     ]
    }
   ],
   "source": [
    "# Data Augmentation for Training\n",
    "train_datagen = ImageDataGenerator(rescale=1./255,\n",
    "                                   shear_range=0.2,\n",
    "                                   zoom_range=0.2,\n",
    "                                   horizontal_flip=True)\n",
    "training_set = train_datagen.flow_from_directory(\n",
    "    \"Monkeypox/archive (60)/Augmented Images/Augmented Images/FOLDS_AUG/fold2_AUG/Train/\",\n",
    "    target_size=(64, 64),\n",
    "    batch_size=32,\n",
    "    class_mode='categorical',  # Use 'categorical' for one-hot encoded labels\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "31eb47e9-2332-425d-a9e8-2fbb934d42f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 7126 images belonging to 6 classes.\n"
     ]
    }
   ],
   "source": [
    "test_datagen = ImageDataGenerator(rescale=1./255)\n",
    "validation_set = test_datagen.flow_from_directory(\n",
    "    \"Monkeypox/archive (60)/Augmented Images/Augmented Images/FOLDS_AUG/fold2_AUG/Train/\",\n",
    "    target_size=(64, 64),\n",
    "    batch_size=32,\n",
    "    class_mode='categorical',  # Use 'categorical' for one-hot encoded labels\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0c516e8b-37e1-4097-8bdc-d44ec6d47f6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Custom F1 Score Metric\n",
    "class F1Score(tf.keras.metrics.Metric):\n",
    "    def __init__(self, name='f1_score', **kwargs):\n",
    "        super(F1Score, self).__init__(name=name, **kwargs)\n",
    "        self.precision = tf.keras.metrics.Precision()\n",
    "        self.recall = tf.keras.metrics.Recall()\n",
    "\n",
    "    def update_state(self, y_true, y_pred, sample_weight=None):\n",
    "        # Update the precision and recall for each batch\n",
    "        self.precision.update_state(y_true, y_pred, sample_weight)\n",
    "        self.recall.update_state(y_true, y_pred, sample_weight)\n",
    "\n",
    "    def result(self):\n",
    "        # Calculate F1 score as the harmonic mean of precision and recall\n",
    "        precision = self.precision.result()\n",
    "        recall = self.recall.result()\n",
    "        return 2 * (precision * recall) / (precision + recall + tf.keras.backend.epsilon())\n",
    "\n",
    "    def reset_states(self):\n",
    "        self.precision.reset_states()\n",
    "        self.recall.reset_states()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "16d0b09e-3b80-479f-ad64-eb1eecca24d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build the Bi-LSTM Model\n",
    "bi_lstm_model = tf.keras.models.Sequential()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "eae5b7fe-4a98-4b1f-8f27-a5b70cac1720",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\KIIT\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\layers\\reshaping\\flatten.py:37: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    }
   ],
   "source": [
    "# Flatten and Reshape for Bi-LSTM\n",
    "bi_lstm_model.add(tf.keras.layers.Flatten(input_shape=(64, 64, 3)))\n",
    "bi_lstm_model.add(tf.keras.layers.Reshape((16, -1)))  # Reshape to (time_steps, features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0d319d1d-980c-4694-bff5-bb011a76a99f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bidirectional LSTM Layer\n",
    "bi_lstm_model.add(tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(units=64, activation='tanh', return_sequences=False)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c67b5c95-7471-492d-b201-0e2531935d46",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fully Connected Layers\n",
    "bi_lstm_model.add(tf.keras.layers.Dense(units=128, activation='relu'))\n",
    "bi_lstm_model.add(tf.keras.layers.Dense(6, activation='softmax'))  # 6 classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "853587b4-d42c-42db-98dc-780f6ea541c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile the model with Precision, Recall, and F1 Score\n",
    "bi_lstm_model.compile(\n",
    "    optimizer='adam',\n",
    "    loss='categorical_crossentropy',  # Use categorical_crossentropy for one-hot encoded labels\n",
    "    metrics=[\n",
    "        'accuracy',\n",
    "        tf.keras.metrics.Precision(name='precision'),\n",
    "        tf.keras.metrics.Recall(name='recall'),\n",
    "        F1Score(name='f1_score')  # Add custom F1 score metric\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4eb3d21a-f6f6-4d9e-aee3-586784e7faad",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\KIIT\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\trainers\\data_adapters\\py_dataset_adapter.py:121: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
      "  self._warn_if_super_not_called()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "\u001b[1m223/223\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 155ms/step - accuracy: 0.3349 - f1_score: 0.0461 - loss: 1.6507 - precision: 0.4447 - recall: 0.0246"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\KIIT\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\trainers\\data_adapters\\py_dataset_adapter.py:121: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
      "  self._warn_if_super_not_called()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m223/223\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m60s\u001b[0m 224ms/step - accuracy: 0.3349 - f1_score: 0.0462 - loss: 1.6506 - precision: 0.4452 - recall: 0.0246 - val_accuracy: 0.3663 - val_f1_score: 0.0509 - val_loss: 1.6023 - val_precision: 0.7344 - val_recall: 0.0264\n",
      "Epoch 2/100\n",
      "\u001b[1m223/223\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m47s\u001b[0m 211ms/step - accuracy: 0.3612 - f1_score: 0.1148 - loss: 1.6005 - precision: 0.6161 - recall: 0.0634 - val_accuracy: 0.3705 - val_f1_score: 0.1288 - val_loss: 1.5589 - val_precision: 0.7190 - val_recall: 0.0707\n",
      "Epoch 3/100\n",
      "\u001b[1m223/223\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m67s\u001b[0m 300ms/step - accuracy: 0.3824 - f1_score: 0.1469 - loss: 1.5560 - precision: 0.5948 - recall: 0.0839 - val_accuracy: 0.3901 - val_f1_score: 0.1534 - val_loss: 1.5353 - val_precision: 0.6728 - val_recall: 0.0866\n",
      "Epoch 4/100\n",
      "\u001b[1m223/223\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m57s\u001b[0m 257ms/step - accuracy: 0.3887 - f1_score: 0.1651 - loss: 1.5175 - precision: 0.6577 - recall: 0.0945 - val_accuracy: 0.4143 - val_f1_score: 0.1930 - val_loss: 1.4737 - val_precision: 0.6918 - val_recall: 0.1121\n",
      "Epoch 5/100\n",
      "\u001b[1m223/223\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m81s\u001b[0m 362ms/step - accuracy: 0.4170 - f1_score: 0.1896 - loss: 1.4734 - precision: 0.6538 - recall: 0.1110 - val_accuracy: 0.4131 - val_f1_score: 0.2798 - val_loss: 1.4348 - val_precision: 0.6129 - val_recall: 0.1813\n",
      "Epoch 6/100\n",
      "\u001b[1m223/223\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m75s\u001b[0m 337ms/step - accuracy: 0.4300 - f1_score: 0.2342 - loss: 1.4432 - precision: 0.6483 - recall: 0.1432 - val_accuracy: 0.4422 - val_f1_score: 0.2722 - val_loss: 1.3992 - val_precision: 0.6216 - val_recall: 0.1743\n",
      "Epoch 7/100\n",
      "\u001b[1m223/223\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m91s\u001b[0m 408ms/step - accuracy: 0.4371 - f1_score: 0.2676 - loss: 1.4031 - precision: 0.6571 - recall: 0.1681 - val_accuracy: 0.4514 - val_f1_score: 0.3309 - val_loss: 1.3632 - val_precision: 0.6631 - val_recall: 0.2205\n",
      "Epoch 8/100\n",
      "\u001b[1m223/223\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m102s\u001b[0m 457ms/step - accuracy: 0.4428 - f1_score: 0.2787 - loss: 1.3890 - precision: 0.6519 - recall: 0.1774 - val_accuracy: 0.4825 - val_f1_score: 0.3312 - val_loss: 1.3357 - val_precision: 0.6639 - val_recall: 0.2206\n",
      "Epoch 9/100\n",
      "\u001b[1m223/223\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m112s\u001b[0m 503ms/step - accuracy: 0.4729 - f1_score: 0.3203 - loss: 1.3340 - precision: 0.6604 - recall: 0.2115 - val_accuracy: 0.5072 - val_f1_score: 0.3549 - val_loss: 1.2826 - val_precision: 0.7224 - val_recall: 0.2352\n",
      "Epoch 10/100\n",
      "\u001b[1m223/223\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m136s\u001b[0m 608ms/step - accuracy: 0.4799 - f1_score: 0.3356 - loss: 1.3159 - precision: 0.6665 - recall: 0.2245 - val_accuracy: 0.5156 - val_f1_score: 0.3849 - val_loss: 1.2572 - val_precision: 0.7284 - val_recall: 0.2616\n",
      "Epoch 11/100\n",
      "\u001b[1m223/223\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m130s\u001b[0m 581ms/step - accuracy: 0.4946 - f1_score: 0.3718 - loss: 1.2874 - precision: 0.6836 - recall: 0.2556 - val_accuracy: 0.5153 - val_f1_score: 0.3903 - val_loss: 1.2576 - val_precision: 0.7080 - val_recall: 0.2694\n",
      "Epoch 12/100\n",
      "\u001b[1m223/223\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m52s\u001b[0m 234ms/step - accuracy: 0.5094 - f1_score: 0.3685 - loss: 1.2644 - precision: 0.7114 - recall: 0.2491 - val_accuracy: 0.5394 - val_f1_score: 0.3878 - val_loss: 1.2095 - val_precision: 0.7811 - val_recall: 0.2579\n",
      "Epoch 13/100\n",
      "\u001b[1m223/223\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m45s\u001b[0m 200ms/step - accuracy: 0.5126 - f1_score: 0.4087 - loss: 1.2312 - precision: 0.7053 - recall: 0.2879 - val_accuracy: 0.5122 - val_f1_score: 0.4394 - val_loss: 1.2604 - val_precision: 0.6804 - val_recall: 0.3244\n",
      "Epoch 14/100\n",
      "\u001b[1m223/223\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m121s\u001b[0m 541ms/step - accuracy: 0.5286 - f1_score: 0.4235 - loss: 1.2291 - precision: 0.6993 - recall: 0.3038 - val_accuracy: 0.5629 - val_f1_score: 0.4644 - val_loss: 1.1396 - val_precision: 0.7627 - val_recall: 0.3338\n",
      "Epoch 15/100\n",
      "\u001b[1m223/223\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m121s\u001b[0m 542ms/step - accuracy: 0.5451 - f1_score: 0.4374 - loss: 1.1894 - precision: 0.7144 - recall: 0.3152 - val_accuracy: 0.5644 - val_f1_score: 0.4568 - val_loss: 1.1484 - val_precision: 0.7738 - val_recall: 0.3240\n",
      "Epoch 16/100\n",
      "\u001b[1m223/223\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m156s\u001b[0m 700ms/step - accuracy: 0.5401 - f1_score: 0.4500 - loss: 1.1950 - precision: 0.7166 - recall: 0.3280 - val_accuracy: 0.5796 - val_f1_score: 0.4843 - val_loss: 1.1095 - val_precision: 0.7421 - val_recall: 0.3594\n",
      "Epoch 17/100\n",
      "\u001b[1m223/223\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m120s\u001b[0m 539ms/step - accuracy: 0.5498 - f1_score: 0.4633 - loss: 1.1597 - precision: 0.7194 - recall: 0.3418 - val_accuracy: 0.5768 - val_f1_score: 0.4996 - val_loss: 1.0974 - val_precision: 0.7700 - val_recall: 0.3698\n",
      "Epoch 18/100\n",
      "\u001b[1m223/223\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m119s\u001b[0m 535ms/step - accuracy: 0.5516 - f1_score: 0.4703 - loss: 1.1431 - precision: 0.7192 - recall: 0.3495 - val_accuracy: 0.5740 - val_f1_score: 0.4775 - val_loss: 1.0976 - val_precision: 0.7893 - val_recall: 0.3423\n",
      "Epoch 19/100\n",
      "\u001b[1m223/223\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m212s\u001b[0m 949ms/step - accuracy: 0.5605 - f1_score: 0.4810 - loss: 1.1401 - precision: 0.7298 - recall: 0.3588 - val_accuracy: 0.6027 - val_f1_score: 0.5436 - val_loss: 1.0402 - val_precision: 0.7732 - val_recall: 0.4192\n",
      "Epoch 20/100\n",
      "\u001b[1m223/223\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m205s\u001b[0m 921ms/step - accuracy: 0.5846 - f1_score: 0.5114 - loss: 1.0886 - precision: 0.7437 - recall: 0.3898 - val_accuracy: 0.5612 - val_f1_score: 0.4930 - val_loss: 1.1027 - val_precision: 0.7361 - val_recall: 0.3706\n",
      "Epoch 21/100\n",
      "\u001b[1m223/223\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m196s\u001b[0m 878ms/step - accuracy: 0.5743 - f1_score: 0.5096 - loss: 1.0967 - precision: 0.7410 - recall: 0.3883 - val_accuracy: 0.6118 - val_f1_score: 0.5464 - val_loss: 1.0139 - val_precision: 0.7965 - val_recall: 0.4158\n",
      "Epoch 22/100\n",
      "\u001b[1m223/223\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m202s\u001b[0m 906ms/step - accuracy: 0.5921 - f1_score: 0.5238 - loss: 1.0663 - precision: 0.7511 - recall: 0.4022 - val_accuracy: 0.6116 - val_f1_score: 0.5448 - val_loss: 1.0149 - val_precision: 0.7843 - val_recall: 0.4173\n",
      "Epoch 23/100\n",
      "\u001b[1m223/223\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m206s\u001b[0m 925ms/step - accuracy: 0.5849 - f1_score: 0.5277 - loss: 1.0547 - precision: 0.7371 - recall: 0.4110 - val_accuracy: 0.6099 - val_f1_score: 0.5745 - val_loss: 1.0048 - val_precision: 0.7651 - val_recall: 0.4599\n",
      "Epoch 24/100\n",
      "\u001b[1m223/223\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m203s\u001b[0m 910ms/step - accuracy: 0.6040 - f1_score: 0.5531 - loss: 1.0212 - precision: 0.7569 - recall: 0.4358 - val_accuracy: 0.6402 - val_f1_score: 0.5818 - val_loss: 0.9594 - val_precision: 0.8061 - val_recall: 0.4551\n",
      "Epoch 25/100\n",
      "\u001b[1m223/223\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m209s\u001b[0m 935ms/step - accuracy: 0.6094 - f1_score: 0.5623 - loss: 1.0237 - precision: 0.7621 - recall: 0.4456 - val_accuracy: 0.6337 - val_f1_score: 0.5822 - val_loss: 0.9591 - val_precision: 0.7870 - val_recall: 0.4620\n",
      "Epoch 26/100\n",
      "\u001b[1m223/223\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m205s\u001b[0m 919ms/step - accuracy: 0.6092 - f1_score: 0.5648 - loss: 1.0134 - precision: 0.7654 - recall: 0.4476 - val_accuracy: 0.6155 - val_f1_score: 0.5778 - val_loss: 0.9794 - val_precision: 0.7807 - val_recall: 0.4586\n",
      "Epoch 27/100\n",
      "\u001b[1m223/223\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m207s\u001b[0m 928ms/step - accuracy: 0.6186 - f1_score: 0.5710 - loss: 0.9954 - precision: 0.7537 - recall: 0.4599 - val_accuracy: 0.6545 - val_f1_score: 0.6122 - val_loss: 0.9147 - val_precision: 0.7967 - val_recall: 0.4971\n",
      "Epoch 28/100\n",
      "\u001b[1m223/223\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m213s\u001b[0m 954ms/step - accuracy: 0.6149 - f1_score: 0.5765 - loss: 0.9795 - precision: 0.7667 - recall: 0.4620 - val_accuracy: 0.6458 - val_f1_score: 0.6017 - val_loss: 0.9232 - val_precision: 0.7787 - val_recall: 0.4903\n",
      "Epoch 29/100\n",
      "\u001b[1m223/223\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m212s\u001b[0m 951ms/step - accuracy: 0.6282 - f1_score: 0.5761 - loss: 0.9799 - precision: 0.7490 - recall: 0.4681 - val_accuracy: 0.6584 - val_f1_score: 0.6235 - val_loss: 0.8854 - val_precision: 0.7932 - val_recall: 0.5136\n",
      "Epoch 30/100\n",
      "\u001b[1m223/223\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m250s\u001b[0m 1s/step - accuracy: 0.6285 - f1_score: 0.5918 - loss: 0.9689 - precision: 0.7725 - recall: 0.4798 - val_accuracy: 0.6664 - val_f1_score: 0.6305 - val_loss: 0.8661 - val_precision: 0.8125 - val_recall: 0.5152\n",
      "Epoch 31/100\n",
      "\u001b[1m223/223\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m176s\u001b[0m 791ms/step - accuracy: 0.6487 - f1_score: 0.6114 - loss: 0.9234 - precision: 0.7735 - recall: 0.5055 - val_accuracy: 0.6371 - val_f1_score: 0.6026 - val_loss: 0.9262 - val_precision: 0.8047 - val_recall: 0.4816\n",
      "Epoch 32/100\n",
      "\u001b[1m223/223\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m108s\u001b[0m 482ms/step - accuracy: 0.6392 - f1_score: 0.5996 - loss: 0.9339 - precision: 0.7809 - recall: 0.4867 - val_accuracy: 0.6579 - val_f1_score: 0.6269 - val_loss: 0.8830 - val_precision: 0.7840 - val_recall: 0.5222\n",
      "Epoch 33/100\n",
      "\u001b[1m223/223\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m102s\u001b[0m 458ms/step - accuracy: 0.6419 - f1_score: 0.5999 - loss: 0.9317 - precision: 0.7710 - recall: 0.4910 - val_accuracy: 0.6713 - val_f1_score: 0.6124 - val_loss: 0.8793 - val_precision: 0.8359 - val_recall: 0.4832\n",
      "Epoch 34/100\n",
      "\u001b[1m223/223\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m107s\u001b[0m 478ms/step - accuracy: 0.6571 - f1_score: 0.6186 - loss: 0.9026 - precision: 0.7857 - recall: 0.5101 - val_accuracy: 0.6837 - val_f1_score: 0.6491 - val_loss: 0.8538 - val_precision: 0.7988 - val_recall: 0.5466\n",
      "Epoch 35/100\n",
      "\u001b[1m223/223\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m117s\u001b[0m 527ms/step - accuracy: 0.6536 - f1_score: 0.6211 - loss: 0.9045 - precision: 0.7800 - recall: 0.5160 - val_accuracy: 0.6800 - val_f1_score: 0.6483 - val_loss: 0.8367 - val_precision: 0.7995 - val_recall: 0.5452\n",
      "Epoch 36/100\n",
      "\u001b[1m223/223\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m118s\u001b[0m 528ms/step - accuracy: 0.6683 - f1_score: 0.6370 - loss: 0.8878 - precision: 0.7858 - recall: 0.5358 - val_accuracy: 0.6796 - val_f1_score: 0.6530 - val_loss: 0.8383 - val_precision: 0.7867 - val_recall: 0.5581\n",
      "Epoch 37/100\n",
      "\u001b[1m223/223\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m126s\u001b[0m 563ms/step - accuracy: 0.6616 - f1_score: 0.6314 - loss: 0.8775 - precision: 0.7790 - recall: 0.5310 - val_accuracy: 0.7061 - val_f1_score: 0.6676 - val_loss: 0.7948 - val_precision: 0.8188 - val_recall: 0.5636\n",
      "Epoch 38/100\n",
      "\u001b[1m223/223\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m121s\u001b[0m 545ms/step - accuracy: 0.6715 - f1_score: 0.6326 - loss: 0.8773 - precision: 0.7907 - recall: 0.5272 - val_accuracy: 0.6737 - val_f1_score: 0.6654 - val_loss: 0.8530 - val_precision: 0.7813 - val_recall: 0.5794\n",
      "Epoch 39/100\n",
      "\u001b[1m223/223\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m122s\u001b[0m 547ms/step - accuracy: 0.6749 - f1_score: 0.6504 - loss: 0.8621 - precision: 0.7978 - recall: 0.5490 - val_accuracy: 0.6997 - val_f1_score: 0.6738 - val_loss: 0.8091 - val_precision: 0.7963 - val_recall: 0.5841\n",
      "Epoch 40/100\n",
      "\u001b[1m223/223\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m123s\u001b[0m 551ms/step - accuracy: 0.6806 - f1_score: 0.6524 - loss: 0.8446 - precision: 0.8004 - recall: 0.5506 - val_accuracy: 0.7148 - val_f1_score: 0.6922 - val_loss: 0.7652 - val_precision: 0.8279 - val_recall: 0.5947\n",
      "Epoch 41/100\n",
      "\u001b[1m223/223\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m122s\u001b[0m 548ms/step - accuracy: 0.6785 - f1_score: 0.6442 - loss: 0.8403 - precision: 0.7930 - recall: 0.5425 - val_accuracy: 0.7233 - val_f1_score: 0.6863 - val_loss: 0.7560 - val_precision: 0.8482 - val_recall: 0.5763\n",
      "Epoch 42/100\n",
      "\u001b[1m223/223\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m120s\u001b[0m 537ms/step - accuracy: 0.6791 - f1_score: 0.6529 - loss: 0.8503 - precision: 0.8024 - recall: 0.5506 - val_accuracy: 0.7248 - val_f1_score: 0.6985 - val_loss: 0.7398 - val_precision: 0.8432 - val_recall: 0.5961\n",
      "Epoch 43/100\n",
      "\u001b[1m223/223\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m124s\u001b[0m 554ms/step - accuracy: 0.6915 - f1_score: 0.6650 - loss: 0.8350 - precision: 0.8023 - recall: 0.5678 - val_accuracy: 0.7233 - val_f1_score: 0.7029 - val_loss: 0.7319 - val_precision: 0.8298 - val_recall: 0.6096\n",
      "Epoch 44/100\n",
      "\u001b[1m223/223\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m128s\u001b[0m 571ms/step - accuracy: 0.6889 - f1_score: 0.6644 - loss: 0.8261 - precision: 0.8068 - recall: 0.5648 - val_accuracy: 0.7252 - val_f1_score: 0.7008 - val_loss: 0.7368 - val_precision: 0.8430 - val_recall: 0.5996\n",
      "Epoch 45/100\n",
      "\u001b[1m223/223\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m124s\u001b[0m 554ms/step - accuracy: 0.7056 - f1_score: 0.6844 - loss: 0.7787 - precision: 0.8088 - recall: 0.5933 - val_accuracy: 0.7165 - val_f1_score: 0.6940 - val_loss: 0.7493 - val_precision: 0.8466 - val_recall: 0.5880\n",
      "Epoch 46/100\n",
      "\u001b[1m223/223\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m141s\u001b[0m 551ms/step - accuracy: 0.6764 - f1_score: 0.6637 - loss: 0.8311 - precision: 0.7938 - recall: 0.5703 - val_accuracy: 0.7280 - val_f1_score: 0.7091 - val_loss: 0.7316 - val_precision: 0.8446 - val_recall: 0.6110\n",
      "Epoch 47/100\n",
      "\u001b[1m223/223\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m122s\u001b[0m 549ms/step - accuracy: 0.7015 - f1_score: 0.6792 - loss: 0.7824 - precision: 0.8101 - recall: 0.5850 - val_accuracy: 0.7210 - val_f1_score: 0.7052 - val_loss: 0.7271 - val_precision: 0.8270 - val_recall: 0.6147\n",
      "Epoch 48/100\n",
      "\u001b[1m223/223\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m109s\u001b[0m 486ms/step - accuracy: 0.6985 - f1_score: 0.6822 - loss: 0.7966 - precision: 0.8109 - recall: 0.5888 - val_accuracy: 0.7398 - val_f1_score: 0.7167 - val_loss: 0.6995 - val_precision: 0.8609 - val_recall: 0.6139\n",
      "Epoch 49/100\n",
      "\u001b[1m223/223\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m123s\u001b[0m 553ms/step - accuracy: 0.7102 - f1_score: 0.6937 - loss: 0.7685 - precision: 0.8124 - recall: 0.6053 - val_accuracy: 0.7575 - val_f1_score: 0.7431 - val_loss: 0.6704 - val_precision: 0.8550 - val_recall: 0.6570\n",
      "Epoch 50/100\n",
      "\u001b[1m223/223\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m142s\u001b[0m 551ms/step - accuracy: 0.7205 - f1_score: 0.7009 - loss: 0.7565 - precision: 0.8161 - recall: 0.6142 - val_accuracy: 0.7610 - val_f1_score: 0.7420 - val_loss: 0.6558 - val_precision: 0.8728 - val_recall: 0.6452\n",
      "Epoch 51/100\n",
      "\u001b[1m223/223\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m124s\u001b[0m 558ms/step - accuracy: 0.7279 - f1_score: 0.7087 - loss: 0.7288 - precision: 0.8243 - recall: 0.6216 - val_accuracy: 0.7393 - val_f1_score: 0.7245 - val_loss: 0.7006 - val_precision: 0.8471 - val_recall: 0.6329\n",
      "Epoch 52/100\n",
      "\u001b[1m223/223\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m125s\u001b[0m 560ms/step - accuracy: 0.7188 - f1_score: 0.7049 - loss: 0.7536 - precision: 0.8238 - recall: 0.6160 - val_accuracy: 0.7280 - val_f1_score: 0.7180 - val_loss: 0.7145 - val_precision: 0.8156 - val_recall: 0.6413\n",
      "Epoch 53/100\n",
      "\u001b[1m223/223\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m137s\u001b[0m 603ms/step - accuracy: 0.7356 - f1_score: 0.7228 - loss: 0.7058 - precision: 0.8240 - recall: 0.6439 - val_accuracy: 0.7644 - val_f1_score: 0.7556 - val_loss: 0.6350 - val_precision: 0.8643 - val_recall: 0.6712\n",
      "Epoch 56/100\n",
      "\u001b[1m223/223\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m134s\u001b[0m 602ms/step - accuracy: 0.7275 - f1_score: 0.7179 - loss: 0.7275 - precision: 0.8184 - recall: 0.6395 - val_accuracy: 0.7640 - val_f1_score: 0.7493 - val_loss: 0.6513 - val_precision: 0.8557 - val_recall: 0.6664\n",
      "Epoch 57/100\n",
      "\u001b[1m223/223\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m142s\u001b[0m 637ms/step - accuracy: 0.7381 - f1_score: 0.7238 - loss: 0.7168 - precision: 0.8317 - recall: 0.6408 - val_accuracy: 0.7509 - val_f1_score: 0.7489 - val_loss: 0.6455 - val_precision: 0.8301 - val_recall: 0.6821\n",
      "Epoch 58/100\n",
      "\u001b[1m223/223\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m144s\u001b[0m 646ms/step - accuracy: 0.7465 - f1_score: 0.7335 - loss: 0.6882 - precision: 0.8339 - recall: 0.6547 - val_accuracy: 0.7623 - val_f1_score: 0.7555 - val_loss: 0.6335 - val_precision: 0.8540 - val_recall: 0.6774\n",
      "Epoch 59/100\n",
      "\u001b[1m223/223\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m218s\u001b[0m 977ms/step - accuracy: 0.7435 - f1_score: 0.7344 - loss: 0.6868 - precision: 0.8318 - recall: 0.6575 - val_accuracy: 0.7513 - val_f1_score: 0.7473 - val_loss: 0.6521 - val_precision: 0.8247 - val_recall: 0.6831\n",
      "Epoch 60/100\n",
      "\u001b[1m223/223\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m212s\u001b[0m 950ms/step - accuracy: 0.7430 - f1_score: 0.7322 - loss: 0.6927 - precision: 0.8338 - recall: 0.6527 - val_accuracy: 0.7620 - val_f1_score: 0.7482 - val_loss: 0.6295 - val_precision: 0.8480 - val_recall: 0.6694\n",
      "Epoch 61/100\n",
      "\u001b[1m223/223\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m170s\u001b[0m 764ms/step - accuracy: 0.7369 - f1_score: 0.7246 - loss: 0.6900 - precision: 0.8158 - recall: 0.6518 - val_accuracy: 0.7619 - val_f1_score: 0.7583 - val_loss: 0.6277 - val_precision: 0.8533 - val_recall: 0.6823\n",
      "Epoch 62/100\n",
      "\u001b[1m223/223\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m155s\u001b[0m 694ms/step - accuracy: 0.7529 - f1_score: 0.7359 - loss: 0.6755 - precision: 0.8315 - recall: 0.6600 - val_accuracy: 0.7854 - val_f1_score: 0.7732 - val_loss: 0.6010 - val_precision: 0.8740 - val_recall: 0.6932\n",
      "Epoch 63/100\n",
      "\u001b[1m223/223\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m224s\u001b[0m 1s/step - accuracy: 0.7508 - f1_score: 0.7461 - loss: 0.6680 - precision: 0.8377 - recall: 0.6727 - val_accuracy: 0.7682 - val_f1_score: 0.7597 - val_loss: 0.6305 - val_precision: 0.8480 - val_recall: 0.6880\n",
      "Epoch 64/100\n",
      "\u001b[1m223/223\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m216s\u001b[0m 966ms/step - accuracy: 0.7529 - f1_score: 0.7439 - loss: 0.6720 - precision: 0.8388 - recall: 0.6683 - val_accuracy: 0.7683 - val_f1_score: 0.7610 - val_loss: 0.6265 - val_precision: 0.8452 - val_recall: 0.6920\n",
      "Epoch 65/100\n",
      "\u001b[1m223/223\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m222s\u001b[0m 997ms/step - accuracy: 0.7535 - f1_score: 0.7424 - loss: 0.6677 - precision: 0.8413 - recall: 0.6644 - val_accuracy: 0.7781 - val_f1_score: 0.7742 - val_loss: 0.5894 - val_precision: 0.8567 - val_recall: 0.7063\n",
      "Epoch 66/100\n",
      "\u001b[1m223/223\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m210s\u001b[0m 945ms/step - accuracy: 0.7380 - f1_score: 0.7362 - loss: 0.6907 - precision: 0.8326 - recall: 0.6599 - val_accuracy: 0.7853 - val_f1_score: 0.7812 - val_loss: 0.5722 - val_precision: 0.8536 - val_recall: 0.7200\n",
      "Epoch 67/100\n",
      "\u001b[1m223/223\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m218s\u001b[0m 977ms/step - accuracy: 0.7556 - f1_score: 0.7394 - loss: 0.6613 - precision: 0.8272 - recall: 0.6685 - val_accuracy: 0.7819 - val_f1_score: 0.7728 - val_loss: 0.5997 - val_precision: 0.8547 - val_recall: 0.7052\n",
      "Epoch 68/100\n",
      "\u001b[1m223/223\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m216s\u001b[0m 969ms/step - accuracy: 0.7646 - f1_score: 0.7576 - loss: 0.6266 - precision: 0.8390 - recall: 0.6906 - val_accuracy: 0.7951 - val_f1_score: 0.7811 - val_loss: 0.5753 - val_precision: 0.8776 - val_recall: 0.7036\n",
      "Epoch 69/100\n",
      "\u001b[1m223/223\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m213s\u001b[0m 952ms/step - accuracy: 0.7641 - f1_score: 0.7501 - loss: 0.6298 - precision: 0.8367 - recall: 0.6798 - val_accuracy: 0.8063 - val_f1_score: 0.7981 - val_loss: 0.5416 - val_precision: 0.8735 - val_recall: 0.7346\n",
      "Epoch 70/100\n",
      "\u001b[1m223/223\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m197s\u001b[0m 882ms/step - accuracy: 0.7645 - f1_score: 0.7538 - loss: 0.6387 - precision: 0.8358 - recall: 0.6864 - val_accuracy: 0.7965 - val_f1_score: 0.7893 - val_loss: 0.5631 - val_precision: 0.8688 - val_recall: 0.7231\n",
      "Epoch 71/100\n",
      "\u001b[1m223/223\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m175s\u001b[0m 785ms/step - accuracy: 0.7692 - f1_score: 0.7597 - loss: 0.6125 - precision: 0.8407 - recall: 0.6930 - val_accuracy: 0.8040 - val_f1_score: 0.8011 - val_loss: 0.5277 - val_precision: 0.8670 - val_recall: 0.7445\n",
      "Epoch 73/100\n",
      "\u001b[1m223/223\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m208s\u001b[0m 933ms/step - accuracy: 0.7716 - f1_score: 0.7634 - loss: 0.6160 - precision: 0.8443 - recall: 0.6966 - val_accuracy: 0.7965 - val_f1_score: 0.7861 - val_loss: 0.5606 - val_precision: 0.8637 - val_recall: 0.7213\n",
      "Epoch 74/100\n",
      "\u001b[1m223/223\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m207s\u001b[0m 930ms/step - accuracy: 0.7544 - f1_score: 0.7518 - loss: 0.6602 - precision: 0.8347 - recall: 0.6840 - val_accuracy: 0.7682 - val_f1_score: 0.7595 - val_loss: 0.6135 - val_precision: 0.8391 - val_recall: 0.6937\n",
      "Epoch 75/100\n",
      "\u001b[1m223/223\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m216s\u001b[0m 968ms/step - accuracy: 0.7658 - f1_score: 0.7622 - loss: 0.6291 - precision: 0.8398 - recall: 0.6977 - val_accuracy: 0.8004 - val_f1_score: 0.7910 - val_loss: 0.5503 - val_precision: 0.8742 - val_recall: 0.7223\n",
      "Epoch 76/100\n",
      "\u001b[1m223/223\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m222s\u001b[0m 998ms/step - accuracy: 0.7975 - f1_score: 0.7937 - loss: 0.5480 - precision: 0.8600 - recall: 0.7370 - val_accuracy: 0.8378 - val_f1_score: 0.8270 - val_loss: 0.4706 - val_precision: 0.8870 - val_recall: 0.7746\n",
      "Epoch 88/100\n",
      "\u001b[1m223/223\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m260s\u001b[0m 1s/step - accuracy: 0.7997 - f1_score: 0.7906 - loss: 0.5558 - precision: 0.8542 - recall: 0.7358 - val_accuracy: 0.8288 - val_f1_score: 0.8263 - val_loss: 0.4766 - val_precision: 0.8845 - val_recall: 0.7752\n",
      "Epoch 89/100\n",
      "\u001b[1m223/223\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m183s\u001b[0m 819ms/step - accuracy: 0.7992 - f1_score: 0.7921 - loss: 0.5527 - precision: 0.8542 - recall: 0.7385 - val_accuracy: 0.8458 - val_f1_score: 0.8407 - val_loss: 0.4477 - val_precision: 0.9001 - val_recall: 0.7887\n",
      "Epoch 91/100\n",
      "\u001b[1m223/223\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m255s\u001b[0m 1s/step - accuracy: 0.7992 - f1_score: 0.7929 - loss: 0.5538 - precision: 0.8550 - recall: 0.7392 - val_accuracy: 0.8302 - val_f1_score: 0.8302 - val_loss: 0.4775 - val_precision: 0.8950 - val_recall: 0.7741\n",
      "Epoch 92/100\n",
      "\u001b[1m223/223\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m231s\u001b[0m 1s/step - accuracy: 0.8014 - f1_score: 0.7956 - loss: 0.5631 - precision: 0.8565 - recall: 0.7429 - val_accuracy: 0.8456 - val_f1_score: 0.8451 - val_loss: 0.4357 - val_precision: 0.8997 - val_recall: 0.7968\n",
      "Epoch 93/100\n",
      "\u001b[1m223/223\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m234s\u001b[0m 1s/step - accuracy: 0.8057 - f1_score: 0.8047 - loss: 0.5238 - precision: 0.8614 - recall: 0.7551 - val_accuracy: 0.8406 - val_f1_score: 0.8367 - val_loss: 0.4489 - val_precision: 0.8943 - val_recall: 0.7860\n",
      "Epoch 94/100\n",
      "\u001b[1m223/223\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m234s\u001b[0m 1s/step - accuracy: 0.8055 - f1_score: 0.8015 - loss: 0.5365 - precision: 0.8582 - recall: 0.7519 - val_accuracy: 0.8440 - val_f1_score: 0.8402 - val_loss: 0.4357 - val_precision: 0.8873 - val_recall: 0.7978\n",
      "Epoch 95/100\n",
      "\u001b[1m223/223\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m232s\u001b[0m 1s/step - accuracy: 0.8032 - f1_score: 0.7959 - loss: 0.5400 - precision: 0.8626 - recall: 0.7388 - val_accuracy: 0.8532 - val_f1_score: 0.8516 - val_loss: 0.4103 - val_precision: 0.8983 - val_recall: 0.8096\n",
      "Epoch 96/100\n",
      "\u001b[1m223/223\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m228s\u001b[0m 1s/step - accuracy: 0.8134 - f1_score: 0.8151 - loss: 0.5201 - precision: 0.8737 - recall: 0.7639 - val_accuracy: 0.8515 - val_f1_score: 0.8444 - val_loss: 0.4322 - val_precision: 0.9030 - val_recall: 0.7930\n",
      "Epoch 97/100\n",
      "\u001b[1m223/223\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m234s\u001b[0m 1s/step - accuracy: 0.8091 - f1_score: 0.8036 - loss: 0.5244 - precision: 0.8645 - recall: 0.7507 - val_accuracy: 0.8298 - val_f1_score: 0.8268 - val_loss: 0.4667 - val_precision: 0.8798 - val_recall: 0.7798\n",
      "Epoch 98/100\n",
      "\u001b[1m223/223\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m222s\u001b[0m 998ms/step - accuracy: 0.7975 - f1_score: 0.7932 - loss: 0.5581 - precision: 0.8562 - recall: 0.7388 - val_accuracy: 0.8563 - val_f1_score: 0.8537 - val_loss: 0.4089 - val_precision: 0.9049 - val_recall: 0.8080\n",
      "Epoch 99/100\n",
      "\u001b[1m223/223\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m230s\u001b[0m 1s/step - accuracy: 0.8105 - f1_score: 0.8027 - loss: 0.5248 - precision: 0.8632 - recall: 0.7503 - val_accuracy: 0.8674 - val_f1_score: 0.8601 - val_loss: 0.4011 - val_precision: 0.9146 - val_recall: 0.8117\n",
      "Epoch 100/100\n",
      "\u001b[1m223/223\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m235s\u001b[0m 1s/step - accuracy: 0.8188 - f1_score: 0.8110 - loss: 0.4957 - precision: 0.8702 - recall: 0.7594 - val_accuracy: 0.8313 - val_f1_score: 0.8318 - val_loss: 0.4470 - val_precision: 0.8715 - val_recall: 0.7955\n"
     ]
    }
   ],
   "source": [
    "# Train the model\n",
    "history = bi_lstm_model.fit(\n",
    "    x=training_set,\n",
    "    validation_data=validation_set,\n",
    "    epochs=100\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f2de1472-7eca-4a71-a5a7-c985c5c40984",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save Loss plot\n",
    "plt.figure()\n",
    "plt.plot(history.history['loss'], label='Train Loss')\n",
    "plt.plot(history.history['val_loss'], label='Validation Loss')\n",
    "plt.legend()\n",
    "plt.title(\"Loss\")\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.savefig('loss_plot_bilstm.png')  # Save the plot as a PNG file\n",
    "plt.close()\n",
    "\n",
    "# Save Accuracy plot\n",
    "plt.figure()\n",
    "plt.plot(history.history['accuracy'], label='Train Accuracy')\n",
    "plt.plot(history.history['val_accuracy'], label='Validation Accuracy')\n",
    "plt.legend()\n",
    "plt.title(\"Accuracy\")\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.savefig('accuracy_plot_bilstm.png')  # Save the plot as a PNG file\n",
    "plt.close()\n",
    "\n",
    "# Save Precision plot\n",
    "plt.figure()\n",
    "plt.plot(history.history['precision'], label='Train Precision')\n",
    "plt.plot(history.history['val_precision'], label='Validation Precision')\n",
    "plt.legend()\n",
    "plt.title(\"Precision\")\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Precision')\n",
    "plt.savefig('precision_plot_bilstm.png')  # Save the plot as a PNG file\n",
    "plt.close()\n",
    "\n",
    "# Save Recall plot\n",
    "plt.figure()\n",
    "plt.plot(history.history['recall'], label='Train Recall')\n",
    "plt.plot(history.history['val_recall'], label='Validation Recall')\n",
    "plt.legend()\n",
    "plt.title(\"Recall\")\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Recall')\n",
    "plt.savefig('recall_plot_bilstm.png')  # Save the plot as a PNG file\n",
    "plt.close()\n",
    "\n",
    "# Save F1 Score plot\n",
    "plt.figure()\n",
    "plt.plot(history.history['f1_score'], label='Train F1 Score')\n",
    "plt.plot(history.history['val_f1_score'], label='Validation F1 Score')\n",
    "plt.legend()\n",
    "plt.title(\"F1 Score\")\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('F1 Score')\n",
    "plt.savefig('f1_score_plot_bilstm.png')  # Save the plot as a PNG file\n",
    "plt.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "43f30b59-bb29-45e1-aed4-56704032f553",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                         </span>┃<span style=\"font-weight: bold\"> Output Shape                </span>┃<span style=\"font-weight: bold\">         Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
       "│ flatten (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)                    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">12288</span>)               │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ reshape (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Reshape</span>)                    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">768</span>)             │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ bidirectional (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Bidirectional</span>)        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)                 │         <span style=\"color: #00af00; text-decoration-color: #00af00\">426,496</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)                 │          <span style=\"color: #00af00; text-decoration-color: #00af00\">16,512</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">6</span>)                   │             <span style=\"color: #00af00; text-decoration-color: #00af00\">774</span> │\n",
       "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
       "│ flatten (\u001b[38;5;33mFlatten\u001b[0m)                    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m12288\u001b[0m)               │               \u001b[38;5;34m0\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ reshape (\u001b[38;5;33mReshape\u001b[0m)                    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m768\u001b[0m)             │               \u001b[38;5;34m0\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ bidirectional (\u001b[38;5;33mBidirectional\u001b[0m)        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)                 │         \u001b[38;5;34m426,496\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense (\u001b[38;5;33mDense\u001b[0m)                        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)                 │          \u001b[38;5;34m16,512\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)                      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m6\u001b[0m)                   │             \u001b[38;5;34m774\u001b[0m │\n",
       "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,331,348</span> (5.08 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m1,331,348\u001b[0m (5.08 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">443,782</span> (1.69 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m443,782\u001b[0m (1.69 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Optimizer params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">887,566</span> (3.39 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Optimizer params: \u001b[0m\u001b[38;5;34m887,566\u001b[0m (3.39 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "bi_lstm_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "039bb700-3f24-416c-9d49-8e9f87f5c3c3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

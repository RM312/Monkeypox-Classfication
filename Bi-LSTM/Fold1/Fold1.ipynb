{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "895fc310-5391-4d5a-86a3-24d643760db2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ec2b784e-3220-4363-b330-777db2fa3f08",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 7518 images belonging to 6 classes.\n"
     ]
    }
   ],
   "source": [
    "# Data Augmentation for Training\n",
    "train_datagen = ImageDataGenerator(rescale=1./255,\n",
    "                                   shear_range=0.2,\n",
    "                                   zoom_range=0.2,\n",
    "                                   horizontal_flip=True)\n",
    "training_set = train_datagen.flow_from_directory(\n",
    "    \"Monkeypox/archive (60)/Augmented Images/Augmented Images/FOLDS_AUG/fold1_AUG/Train/\",\n",
    "    target_size=(64, 64),\n",
    "    batch_size=32,\n",
    "    class_mode='categorical',  # Use 'categorical' for one-hot encoded labels\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6699f7b0-a059-47d7-a4ed-5e60be17a5fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 7518 images belonging to 6 classes.\n"
     ]
    }
   ],
   "source": [
    "test_datagen = ImageDataGenerator(rescale=1./255)\n",
    "validation_set = test_datagen.flow_from_directory(\n",
    "    \"Monkeypox/archive (60)/Augmented Images/Augmented Images/FOLDS_AUG/fold1_AUG/Train/\",\n",
    "    target_size=(64, 64),\n",
    "    batch_size=32,\n",
    "    class_mode='categorical',  # Use 'categorical' for one-hot encoded labels\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "43cfb07d-5dd7-41d5-b939-882f12c74b74",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Custom F1 Score Metric\n",
    "class F1Score(tf.keras.metrics.Metric):\n",
    "    def __init__(self, name='f1_score', **kwargs):\n",
    "        super(F1Score, self).__init__(name=name, **kwargs)\n",
    "        self.precision = tf.keras.metrics.Precision()\n",
    "        self.recall = tf.keras.metrics.Recall()\n",
    "\n",
    "    def update_state(self, y_true, y_pred, sample_weight=None):\n",
    "        # Update the precision and recall for each batch\n",
    "        self.precision.update_state(y_true, y_pred, sample_weight)\n",
    "        self.recall.update_state(y_true, y_pred, sample_weight)\n",
    "\n",
    "    def result(self):\n",
    "        # Calculate F1 score as the harmonic mean of precision and recall\n",
    "        precision = self.precision.result()\n",
    "        recall = self.recall.result()\n",
    "        return 2 * (precision * recall) / (precision + recall + tf.keras.backend.epsilon())\n",
    "\n",
    "    def reset_states(self):\n",
    "        self.precision.reset_states()\n",
    "        self.recall.reset_states()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "90c5113c-6760-45d9-ab07-7ec25e96ab2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build the Bi-LSTM Model\n",
    "bi_lstm_model = tf.keras.models.Sequential()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fa5e5b50-d2cc-4287-b826-dd6c567efb53",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\KIIT\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\layers\\reshaping\\flatten.py:37: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    }
   ],
   "source": [
    "# Flatten and Reshape for Bi-LSTM\n",
    "bi_lstm_model.add(tf.keras.layers.Flatten(input_shape=(64, 64, 3)))\n",
    "bi_lstm_model.add(tf.keras.layers.Reshape((16, -1)))  # Reshape to (time_steps, features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "621cf1d8-dfe2-42e0-9dbf-60d51fa7268d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bidirectional LSTM Layer\n",
    "bi_lstm_model.add(tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(units=64, activation='tanh', return_sequences=False)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c91d1104-b172-4150-8318-f33abfcdfbc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fully Connected Layers\n",
    "bi_lstm_model.add(tf.keras.layers.Dense(units=128, activation='relu'))\n",
    "bi_lstm_model.add(tf.keras.layers.Dense(6, activation='softmax'))  # 6 classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1f932c0c-4aad-493b-a345-735800b8bd05",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile the model with Precision, Recall, and F1 Score\n",
    "bi_lstm_model.compile(\n",
    "    optimizer='adam',\n",
    "    loss='categorical_crossentropy',  # Use categorical_crossentropy for one-hot encoded labels\n",
    "    metrics=[\n",
    "        'accuracy',\n",
    "        tf.keras.metrics.Precision(name='precision'),\n",
    "        tf.keras.metrics.Recall(name='recall'),\n",
    "        F1Score(name='f1_score')  # Add custom F1 score metric\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8d651ca4-5736-4c42-a344-99752940be07",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\KIIT\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\trainers\\data_adapters\\py_dataset_adapter.py:121: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
      "  self._warn_if_super_not_called()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 188ms/step - accuracy: 0.3621 - f1_score: 0.0323 - loss: 1.6199 - precision: 0.4962 - recall: 0.0169"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\KIIT\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\trainers\\data_adapters\\py_dataset_adapter.py:121: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
      "  self._warn_if_super_not_called()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m71s\u001b[0m 277ms/step - accuracy: 0.3622 - f1_score: 0.0324 - loss: 1.6197 - precision: 0.4964 - recall: 0.0170 - val_accuracy: 0.4008 - val_f1_score: 0.0548 - val_loss: 1.5517 - val_precision: 0.7157 - val_recall: 0.0285\n",
      "Epoch 2/100\n",
      "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m49s\u001b[0m 208ms/step - accuracy: 0.3910 - f1_score: 0.1458 - loss: 1.5530 - precision: 0.5979 - recall: 0.0833 - val_accuracy: 0.4052 - val_f1_score: 0.2155 - val_loss: 1.5147 - val_precision: 0.6015 - val_recall: 0.1313\n",
      "Epoch 3/100\n",
      "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m59s\u001b[0m 252ms/step - accuracy: 0.4025 - f1_score: 0.1979 - loss: 1.5146 - precision: 0.6001 - recall: 0.1187 - val_accuracy: 0.4374 - val_f1_score: 0.1421 - val_loss: 1.4814 - val_precision: 0.7291 - val_recall: 0.0787\n",
      "Epoch 4/100\n",
      "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m55s\u001b[0m 236ms/step - accuracy: 0.4270 - f1_score: 0.2251 - loss: 1.4736 - precision: 0.6413 - recall: 0.1366 - val_accuracy: 0.4548 - val_f1_score: 0.2382 - val_loss: 1.4022 - val_precision: 0.7067 - val_recall: 0.1433\n",
      "Epoch 5/100\n",
      "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m74s\u001b[0m 316ms/step - accuracy: 0.4428 - f1_score: 0.2631 - loss: 1.4300 - precision: 0.6162 - recall: 0.1674 - val_accuracy: 0.4685 - val_f1_score: 0.3282 - val_loss: 1.3595 - val_precision: 0.6529 - val_recall: 0.2192\n",
      "Epoch 6/100\n",
      "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m70s\u001b[0m 298ms/step - accuracy: 0.4637 - f1_score: 0.2856 - loss: 1.3739 - precision: 0.6361 - recall: 0.1843 - val_accuracy: 0.4783 - val_f1_score: 0.3457 - val_loss: 1.3338 - val_precision: 0.6403 - val_recall: 0.2368\n",
      "Epoch 7/100\n",
      "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m107s\u001b[0m 454ms/step - accuracy: 0.4778 - f1_score: 0.3191 - loss: 1.3580 - precision: 0.6621 - recall: 0.2103 - val_accuracy: 0.4939 - val_f1_score: 0.3670 - val_loss: 1.2924 - val_precision: 0.7063 - val_recall: 0.2479\n",
      "Epoch 8/100\n",
      "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m98s\u001b[0m 416ms/step - accuracy: 0.4976 - f1_score: 0.3640 - loss: 1.3053 - precision: 0.6743 - recall: 0.2495 - val_accuracy: 0.5150 - val_f1_score: 0.4059 - val_loss: 1.2477 - val_precision: 0.7016 - val_recall: 0.2856\n",
      "Epoch 9/100\n",
      "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m129s\u001b[0m 551ms/step - accuracy: 0.5030 - f1_score: 0.3903 - loss: 1.2875 - precision: 0.6734 - recall: 0.2748 - val_accuracy: 0.5251 - val_f1_score: 0.4502 - val_loss: 1.2425 - val_precision: 0.6649 - val_recall: 0.3403\n",
      "Epoch 10/100\n",
      "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m132s\u001b[0m 564ms/step - accuracy: 0.5081 - f1_score: 0.4067 - loss: 1.2720 - precision: 0.6719 - recall: 0.2918 - val_accuracy: 0.5390 - val_f1_score: 0.4558 - val_loss: 1.2134 - val_precision: 0.6688 - val_recall: 0.3457\n",
      "Epoch 11/100\n",
      "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m147s\u001b[0m 624ms/step - accuracy: 0.5190 - f1_score: 0.4245 - loss: 1.2480 - precision: 0.6818 - recall: 0.3084 - val_accuracy: 0.5390 - val_f1_score: 0.4308 - val_loss: 1.2031 - val_precision: 0.7173 - val_recall: 0.3078\n",
      "Epoch 12/100\n",
      "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m134s\u001b[0m 570ms/step - accuracy: 0.5304 - f1_score: 0.4452 - loss: 1.2131 - precision: 0.6939 - recall: 0.3279 - val_accuracy: 0.5641 - val_f1_score: 0.4639 - val_loss: 1.1492 - val_precision: 0.7531 - val_recall: 0.3352\n",
      "Epoch 13/100\n",
      "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m47s\u001b[0m 199ms/step - accuracy: 0.5293 - f1_score: 0.4578 - loss: 1.2127 - precision: 0.7079 - recall: 0.3385 - val_accuracy: 0.5654 - val_f1_score: 0.4993 - val_loss: 1.1403 - val_precision: 0.7224 - val_recall: 0.3815\n",
      "Epoch 14/100\n",
      "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m112s\u001b[0m 478ms/step - accuracy: 0.5456 - f1_score: 0.4672 - loss: 1.1844 - precision: 0.7001 - recall: 0.3507 - val_accuracy: 0.5378 - val_f1_score: 0.4628 - val_loss: 1.2023 - val_precision: 0.6910 - val_recall: 0.3480\n",
      "Epoch 15/100\n",
      "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m129s\u001b[0m 550ms/step - accuracy: 0.5597 - f1_score: 0.4798 - loss: 1.1687 - precision: 0.7052 - recall: 0.3636 - val_accuracy: 0.5887 - val_f1_score: 0.5222 - val_loss: 1.0837 - val_precision: 0.7709 - val_recall: 0.3948\n",
      "Epoch 16/100\n",
      "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m179s\u001b[0m 761ms/step - accuracy: 0.5621 - f1_score: 0.5044 - loss: 1.1339 - precision: 0.7236 - recall: 0.3872 - val_accuracy: 0.5806 - val_f1_score: 0.4696 - val_loss: 1.1204 - val_precision: 0.7883 - val_recall: 0.3344\n",
      "Epoch 17/100\n",
      "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m140s\u001b[0m 596ms/step - accuracy: 0.5572 - f1_score: 0.4934 - loss: 1.1562 - precision: 0.7235 - recall: 0.3747 - val_accuracy: 0.6061 - val_f1_score: 0.5549 - val_loss: 1.0348 - val_precision: 0.7621 - val_recall: 0.4363\n",
      "Epoch 18/100\n",
      "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m184s\u001b[0m 782ms/step - accuracy: 0.5785 - f1_score: 0.5371 - loss: 1.0919 - precision: 0.7455 - recall: 0.4199 - val_accuracy: 0.6120 - val_f1_score: 0.5638 - val_loss: 1.0368 - val_precision: 0.7703 - val_recall: 0.4447\n",
      "Epoch 19/100\n",
      "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m236s\u001b[0m 1s/step - accuracy: 0.5717 - f1_score: 0.5248 - loss: 1.1059 - precision: 0.7366 - recall: 0.4076 - val_accuracy: 0.6073 - val_f1_score: 0.5646 - val_loss: 1.0245 - val_precision: 0.7575 - val_recall: 0.4500\n",
      "Epoch 20/100\n",
      "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m236s\u001b[0m 1s/step - accuracy: 0.5791 - f1_score: 0.5289 - loss: 1.0905 - precision: 0.7382 - recall: 0.4121 - val_accuracy: 0.5938 - val_f1_score: 0.5386 - val_loss: 1.0513 - val_precision: 0.7565 - val_recall: 0.4182\n",
      "Epoch 21/100\n",
      "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m234s\u001b[0m 994ms/step - accuracy: 0.6032 - f1_score: 0.5440 - loss: 1.0582 - precision: 0.7492 - recall: 0.4270 - val_accuracy: 0.6064 - val_f1_score: 0.5390 - val_loss: 1.0472 - val_precision: 0.7884 - val_recall: 0.4094\n",
      "Epoch 22/100\n",
      "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m240s\u001b[0m 1s/step - accuracy: 0.5867 - f1_score: 0.5333 - loss: 1.0844 - precision: 0.7264 - recall: 0.4216 - val_accuracy: 0.6035 - val_f1_score: 0.5568 - val_loss: 1.0261 - val_precision: 0.7666 - val_recall: 0.4372\n",
      "Epoch 23/100\n",
      "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m204s\u001b[0m 870ms/step - accuracy: 0.6057 - f1_score: 0.5562 - loss: 1.0449 - precision: 0.7552 - recall: 0.4403 - val_accuracy: 0.6470 - val_f1_score: 0.5852 - val_loss: 0.9584 - val_precision: 0.8127 - val_recall: 0.4572\n",
      "Epoch 24/100\n",
      "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m228s\u001b[0m 972ms/step - accuracy: 0.6110 - f1_score: 0.5572 - loss: 1.0316 - precision: 0.7604 - recall: 0.4399 - val_accuracy: 0.6338 - val_f1_score: 0.5841 - val_loss: 0.9833 - val_precision: 0.7762 - val_recall: 0.4682\n",
      "Epoch 25/100\n",
      "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m230s\u001b[0m 978ms/step - accuracy: 0.6143 - f1_score: 0.5603 - loss: 1.0304 - precision: 0.7476 - recall: 0.4481 - val_accuracy: 0.6375 - val_f1_score: 0.6074 - val_loss: 0.9622 - val_precision: 0.7629 - val_recall: 0.5045\n",
      "Epoch 26/100\n",
      "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m240s\u001b[0m 1s/step - accuracy: 0.6268 - f1_score: 0.5775 - loss: 1.0032 - precision: 0.7603 - recall: 0.4656 - val_accuracy: 0.6580 - val_f1_score: 0.6174 - val_loss: 0.9243 - val_precision: 0.8065 - val_recall: 0.5001\n",
      "Epoch 27/100\n",
      "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m246s\u001b[0m 1s/step - accuracy: 0.6237 - f1_score: 0.5841 - loss: 0.9818 - precision: 0.7654 - recall: 0.4723 - val_accuracy: 0.6600 - val_f1_score: 0.6303 - val_loss: 0.9077 - val_precision: 0.7845 - val_recall: 0.5267\n",
      "Epoch 28/100\n",
      "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m299s\u001b[0m 1s/step - accuracy: 0.6349 - f1_score: 0.6033 - loss: 0.9582 - precision: 0.7659 - recall: 0.4977 - val_accuracy: 0.6672 - val_f1_score: 0.6251 - val_loss: 0.8923 - val_precision: 0.7884 - val_recall: 0.5178\n",
      "Epoch 29/100\n",
      "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m224s\u001b[0m 953ms/step - accuracy: 0.6330 - f1_score: 0.5978 - loss: 0.9441 - precision: 0.7669 - recall: 0.4899 - val_accuracy: 0.6720 - val_f1_score: 0.6256 - val_loss: 0.8778 - val_precision: 0.8168 - val_recall: 0.5069\n",
      "Epoch 30/100\n",
      "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m133s\u001b[0m 563ms/step - accuracy: 0.6325 - f1_score: 0.5963 - loss: 0.9394 - precision: 0.7732 - recall: 0.4853 - val_accuracy: 0.6563 - val_f1_score: 0.6201 - val_loss: 0.9073 - val_precision: 0.8046 - val_recall: 0.5044\n",
      "Epoch 31/100\n",
      "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m121s\u001b[0m 512ms/step - accuracy: 0.6438 - f1_score: 0.6120 - loss: 0.9339 - precision: 0.7842 - recall: 0.5018 - val_accuracy: 0.6955 - val_f1_score: 0.6543 - val_loss: 0.8387 - val_precision: 0.8319 - val_recall: 0.5392\n",
      "Epoch 32/100\n",
      "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m127s\u001b[0m 540ms/step - accuracy: 0.6645 - f1_score: 0.6228 - loss: 0.9053 - precision: 0.7870 - recall: 0.5153 - val_accuracy: 0.6878 - val_f1_score: 0.6674 - val_loss: 0.8269 - val_precision: 0.8219 - val_recall: 0.5617\n",
      "Epoch 33/100\n",
      "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m157s\u001b[0m 605ms/step - accuracy: 0.6516 - f1_score: 0.6211 - loss: 0.9295 - precision: 0.7848 - recall: 0.5139 - val_accuracy: 0.6804 - val_f1_score: 0.6648 - val_loss: 0.8518 - val_precision: 0.8189 - val_recall: 0.5595\n",
      "Epoch 34/100\n",
      "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m144s\u001b[0m 611ms/step - accuracy: 0.6590 - f1_score: 0.6233 - loss: 0.8980 - precision: 0.7802 - recall: 0.5189 - val_accuracy: 0.7068 - val_f1_score: 0.6792 - val_loss: 0.7868 - val_precision: 0.8528 - val_recall: 0.5642\n",
      "Epoch 35/100\n",
      "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m140s\u001b[0m 598ms/step - accuracy: 0.6598 - f1_score: 0.6329 - loss: 0.8765 - precision: 0.7964 - recall: 0.5253 - val_accuracy: 0.6890 - val_f1_score: 0.6668 - val_loss: 0.8228 - val_precision: 0.8042 - val_recall: 0.5694\n",
      "Epoch 36/100\n",
      "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m137s\u001b[0m 581ms/step - accuracy: 0.6736 - f1_score: 0.6387 - loss: 0.8816 - precision: 0.7932 - recall: 0.5346 - val_accuracy: 0.6891 - val_f1_score: 0.6558 - val_loss: 0.8296 - val_precision: 0.8292 - val_recall: 0.5424\n",
      "Epoch 37/100\n",
      "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m140s\u001b[0m 594ms/step - accuracy: 0.6715 - f1_score: 0.6506 - loss: 0.8636 - precision: 0.7946 - recall: 0.5509 - val_accuracy: 0.7078 - val_f1_score: 0.6915 - val_loss: 0.7758 - val_precision: 0.7934 - val_recall: 0.6128\n",
      "Epoch 38/100\n",
      "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m139s\u001b[0m 590ms/step - accuracy: 0.6860 - f1_score: 0.6567 - loss: 0.8539 - precision: 0.8007 - recall: 0.5568 - val_accuracy: 0.6970 - val_f1_score: 0.6665 - val_loss: 0.8011 - val_precision: 0.8420 - val_recall: 0.5515\n",
      "Epoch 39/100\n",
      "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m136s\u001b[0m 578ms/step - accuracy: 0.6801 - f1_score: 0.6464 - loss: 0.8564 - precision: 0.8017 - recall: 0.5415 - val_accuracy: 0.7124 - val_f1_score: 0.6901 - val_loss: 0.7730 - val_precision: 0.8405 - val_recall: 0.5854\n",
      "Epoch 40/100\n",
      "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m144s\u001b[0m 611ms/step - accuracy: 0.6804 - f1_score: 0.6629 - loss: 0.8348 - precision: 0.8070 - recall: 0.5625 - val_accuracy: 0.7163 - val_f1_score: 0.7032 - val_loss: 0.7636 - val_precision: 0.8013 - val_recall: 0.6265\n",
      "Epoch 41/100\n",
      "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m140s\u001b[0m 595ms/step - accuracy: 0.7012 - f1_score: 0.6760 - loss: 0.7991 - precision: 0.8087 - recall: 0.5809 - val_accuracy: 0.7251 - val_f1_score: 0.7035 - val_loss: 0.7472 - val_precision: 0.8301 - val_recall: 0.6104\n",
      "Epoch 42/100\n",
      "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m168s\u001b[0m 716ms/step - accuracy: 0.6961 - f1_score: 0.6777 - loss: 0.8042 - precision: 0.8151 - recall: 0.5802 - val_accuracy: 0.7116 - val_f1_score: 0.6748 - val_loss: 0.7845 - val_precision: 0.8483 - val_recall: 0.5603\n",
      "Epoch 43/100\n",
      "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m141s\u001b[0m 598ms/step - accuracy: 0.6948 - f1_score: 0.6611 - loss: 0.8252 - precision: 0.8128 - recall: 0.5573 - val_accuracy: 0.7259 - val_f1_score: 0.7070 - val_loss: 0.7309 - val_precision: 0.8381 - val_recall: 0.6113\n",
      "Epoch 44/100\n",
      "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m140s\u001b[0m 595ms/step - accuracy: 0.7142 - f1_score: 0.6867 - loss: 0.7841 - precision: 0.8080 - recall: 0.5971 - val_accuracy: 0.7227 - val_f1_score: 0.6871 - val_loss: 0.7514 - val_precision: 0.8405 - val_recall: 0.5810\n",
      "Epoch 45/100\n",
      "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m137s\u001b[0m 584ms/step - accuracy: 0.7085 - f1_score: 0.6834 - loss: 0.7830 - precision: 0.8114 - recall: 0.5903 - val_accuracy: 0.7346 - val_f1_score: 0.7112 - val_loss: 0.7229 - val_precision: 0.8466 - val_recall: 0.6131\n",
      "Epoch 46/100\n",
      "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m141s\u001b[0m 599ms/step - accuracy: 0.7020 - f1_score: 0.6737 - loss: 0.8082 - precision: 0.8072 - recall: 0.5782 - val_accuracy: 0.7509 - val_f1_score: 0.7307 - val_loss: 0.6868 - val_precision: 0.8656 - val_recall: 0.6322\n",
      "Epoch 47/100\n",
      "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m141s\u001b[0m 599ms/step - accuracy: 0.7159 - f1_score: 0.6963 - loss: 0.7533 - precision: 0.8274 - recall: 0.6012 - val_accuracy: 0.7481 - val_f1_score: 0.7266 - val_loss: 0.6884 - val_precision: 0.8563 - val_recall: 0.6310\n",
      "Epoch 48/100\n",
      "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m205s\u001b[0m 872ms/step - accuracy: 0.7192 - f1_score: 0.7046 - loss: 0.7384 - precision: 0.8238 - recall: 0.6157 - val_accuracy: 0.7545 - val_f1_score: 0.7388 - val_loss: 0.6728 - val_precision: 0.8514 - val_recall: 0.6524\n",
      "Epoch 50/100\n",
      "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m119s\u001b[0m 507ms/step - accuracy: 0.7119 - f1_score: 0.6907 - loss: 0.7611 - precision: 0.8176 - recall: 0.5980 - val_accuracy: 0.7288 - val_f1_score: 0.7051 - val_loss: 0.7109 - val_precision: 0.8405 - val_recall: 0.6072\n",
      "Epoch 51/100\n",
      "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m153s\u001b[0m 651ms/step - accuracy: 0.7201 - f1_score: 0.6985 - loss: 0.7503 - precision: 0.8227 - recall: 0.6071 - val_accuracy: 0.7812 - val_f1_score: 0.7578 - val_loss: 0.6267 - val_precision: 0.8888 - val_recall: 0.6604\n",
      "Epoch 52/100\n",
      "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m151s\u001b[0m 643ms/step - accuracy: 0.7334 - f1_score: 0.7177 - loss: 0.7183 - precision: 0.8326 - recall: 0.6308 - val_accuracy: 0.7503 - val_f1_score: 0.7412 - val_loss: 0.6563 - val_precision: 0.8506 - val_recall: 0.6567\n",
      "Epoch 53/100\n",
      "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m186s\u001b[0m 792ms/step - accuracy: 0.7378 - f1_score: 0.7154 - loss: 0.7128 - precision: 0.8327 - recall: 0.6271 - val_accuracy: 0.7691 - val_f1_score: 0.7547 - val_loss: 0.6303 - val_precision: 0.8645 - val_recall: 0.6696\n",
      "Epoch 54/100\n",
      "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m236s\u001b[0m 1s/step - accuracy: 0.7332 - f1_score: 0.7167 - loss: 0.7204 - precision: 0.8308 - recall: 0.6302 - val_accuracy: 0.7811 - val_f1_score: 0.7654 - val_loss: 0.6068 - val_precision: 0.8893 - val_recall: 0.6719\n",
      "Epoch 55/100\n",
      "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m240s\u001b[0m 1s/step - accuracy: 0.7439 - f1_score: 0.7300 - loss: 0.6940 - precision: 0.8386 - recall: 0.6464 - val_accuracy: 0.7755 - val_f1_score: 0.7512 - val_loss: 0.6246 - val_precision: 0.8787 - val_recall: 0.6560\n",
      "Epoch 56/100\n",
      "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m151s\u001b[0m 641ms/step - accuracy: 0.7507 - f1_score: 0.7350 - loss: 0.6765 - precision: 0.8439 - recall: 0.6510 - val_accuracy: 0.7561 - val_f1_score: 0.7484 - val_loss: 0.6460 - val_precision: 0.8647 - val_recall: 0.6596\n",
      "Epoch 57/100\n",
      "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m245s\u001b[0m 1s/step - accuracy: 0.7436 - f1_score: 0.7252 - loss: 0.6805 - precision: 0.8324 - recall: 0.6425 - val_accuracy: 0.7691 - val_f1_score: 0.7645 - val_loss: 0.6166 - val_precision: 0.8549 - val_recall: 0.6914\n",
      "Epoch 58/100\n",
      "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m243s\u001b[0m 1s/step - accuracy: 0.7500 - f1_score: 0.7351 - loss: 0.6799 - precision: 0.8300 - recall: 0.6597 - val_accuracy: 0.7745 - val_f1_score: 0.7629 - val_loss: 0.6140 - val_precision: 0.8454 - val_recall: 0.6951\n",
      "Epoch 59/100\n",
      "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m243s\u001b[0m 1s/step - accuracy: 0.7369 - f1_score: 0.7265 - loss: 0.6949 - precision: 0.8227 - recall: 0.6504 - val_accuracy: 0.7753 - val_f1_score: 0.7674 - val_loss: 0.6112 - val_precision: 0.8637 - val_recall: 0.6903\n",
      "Epoch 60/100\n",
      "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m247s\u001b[0m 1s/step - accuracy: 0.7420 - f1_score: 0.7305 - loss: 0.6807 - precision: 0.8271 - recall: 0.6540 - val_accuracy: 0.7780 - val_f1_score: 0.7728 - val_loss: 0.5972 - val_precision: 0.8578 - val_recall: 0.7031\n",
      "Epoch 61/100\n",
      "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m237s\u001b[0m 1s/step - accuracy: 0.7583 - f1_score: 0.7423 - loss: 0.6564 - precision: 0.8429 - recall: 0.6632 - val_accuracy: 0.7990 - val_f1_score: 0.7717 - val_loss: 0.5776 - val_precision: 0.8808 - val_recall: 0.6868\n",
      "Epoch 62/100\n",
      "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m235s\u001b[0m 998ms/step - accuracy: 0.7766 - f1_score: 0.7633 - loss: 0.6343 - precision: 0.8585 - recall: 0.6871 - val_accuracy: 0.7819 - val_f1_score: 0.7723 - val_loss: 0.5896 - val_precision: 0.8631 - val_recall: 0.6987\n",
      "Epoch 63/100\n",
      "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m225s\u001b[0m 956ms/step - accuracy: 0.7596 - f1_score: 0.7516 - loss: 0.6523 - precision: 0.8428 - recall: 0.6782 - val_accuracy: 0.7817 - val_f1_score: 0.7710 - val_loss: 0.5941 - val_precision: 0.8627 - val_recall: 0.6969\n",
      "Epoch 64/100\n",
      "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m204s\u001b[0m 870ms/step - accuracy: 0.7746 - f1_score: 0.7629 - loss: 0.6244 - precision: 0.8543 - recall: 0.6892 - val_accuracy: 0.7965 - val_f1_score: 0.7888 - val_loss: 0.5582 - val_precision: 0.8657 - val_recall: 0.7244\n",
      "Epoch 66/100\n",
      "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m233s\u001b[0m 992ms/step - accuracy: 0.7613 - f1_score: 0.7556 - loss: 0.6299 - precision: 0.8471 - recall: 0.6819 - val_accuracy: 0.8022 - val_f1_score: 0.7899 - val_loss: 0.5491 - val_precision: 0.8908 - val_recall: 0.7095\n",
      "Epoch 67/100\n",
      "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m226s\u001b[0m 961ms/step - accuracy: 0.7679 - f1_score: 0.7548 - loss: 0.6427 - precision: 0.8483 - recall: 0.6799 - val_accuracy: 0.8062 - val_f1_score: 0.8049 - val_loss: 0.5240 - val_precision: 0.8685 - val_recall: 0.7501\n",
      "Epoch 68/100\n",
      "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m244s\u001b[0m 1s/step - accuracy: 0.7898 - f1_score: 0.7834 - loss: 0.5803 - precision: 0.8528 - recall: 0.7245 - val_accuracy: 0.7843 - val_f1_score: 0.7718 - val_loss: 0.5828 - val_precision: 0.8551 - val_recall: 0.7032\n",
      "Epoch 79/100\n",
      "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m302s\u001b[0m 1s/step - accuracy: 0.7976 - f1_score: 0.7862 - loss: 0.5525 - precision: 0.8556 - recall: 0.7272 - val_accuracy: 0.8226 - val_f1_score: 0.8173 - val_loss: 0.4952 - val_precision: 0.8875 - val_recall: 0.7574\n",
      "Epoch 80/100\n",
      "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m191s\u001b[0m 814ms/step - accuracy: 0.8093 - f1_score: 0.7985 - loss: 0.5366 - precision: 0.8648 - recall: 0.7418 - val_accuracy: 0.8377 - val_f1_score: 0.8358 - val_loss: 0.4553 - val_precision: 0.8996 - val_recall: 0.7805\n",
      "Epoch 82/100\n",
      "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m254s\u001b[0m 1s/step - accuracy: 0.8033 - f1_score: 0.7962 - loss: 0.5412 - precision: 0.8639 - recall: 0.7384 - val_accuracy: 0.8303 - val_f1_score: 0.8255 - val_loss: 0.4663 - val_precision: 0.8897 - val_recall: 0.7700\n",
      "Epoch 83/100\n",
      "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m252s\u001b[0m 1s/step - accuracy: 0.8097 - f1_score: 0.7982 - loss: 0.5466 - precision: 0.8649 - recall: 0.7410 - val_accuracy: 0.8414 - val_f1_score: 0.8380 - val_loss: 0.4456 - val_precision: 0.8945 - val_recall: 0.7882\n",
      "Epoch 84/100\n",
      "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m262s\u001b[0m 1s/step - accuracy: 0.8065 - f1_score: 0.8053 - loss: 0.5410 - precision: 0.8722 - recall: 0.7480 - val_accuracy: 0.8422 - val_f1_score: 0.8391 - val_loss: 0.4451 - val_precision: 0.8962 - val_recall: 0.7888\n",
      "Epoch 85/100\n",
      "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m257s\u001b[0m 1s/step - accuracy: 0.8023 - f1_score: 0.7991 - loss: 0.5446 - precision: 0.8639 - recall: 0.7434 - val_accuracy: 0.8320 - val_f1_score: 0.8206 - val_loss: 0.4825 - val_precision: 0.8950 - val_recall: 0.7576\n",
      "Epoch 86/100\n",
      "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m255s\u001b[0m 1s/step - accuracy: 0.8081 - f1_score: 0.8076 - loss: 0.5239 - precision: 0.8694 - recall: 0.7539 - val_accuracy: 0.8484 - val_f1_score: 0.8436 - val_loss: 0.4290 - val_precision: 0.9097 - val_recall: 0.7865\n",
      "Epoch 87/100\n",
      "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m267s\u001b[0m 1s/step - accuracy: 0.8105 - f1_score: 0.8046 - loss: 0.5190 - precision: 0.8678 - recall: 0.7500 - val_accuracy: 0.8291 - val_f1_score: 0.8302 - val_loss: 0.4570 - val_precision: 0.8809 - val_recall: 0.7850\n",
      "Epoch 88/100\n",
      "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m249s\u001b[0m 1s/step - accuracy: 0.8173 - f1_score: 0.8077 - loss: 0.5163 - precision: 0.8673 - recall: 0.7559 - val_accuracy: 0.8312 - val_f1_score: 0.8263 - val_loss: 0.4600 - val_precision: 0.8949 - val_recall: 0.7675\n",
      "Epoch 89/100\n",
      "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m251s\u001b[0m 1s/step - accuracy: 0.8101 - f1_score: 0.8050 - loss: 0.5216 - precision: 0.8652 - recall: 0.7527 - val_accuracy: 0.8353 - val_f1_score: 0.8248 - val_loss: 0.4663 - val_precision: 0.8962 - val_recall: 0.7639\n",
      "Epoch 90/100\n",
      "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m261s\u001b[0m 1s/step - accuracy: 0.8095 - f1_score: 0.8006 - loss: 0.5360 - precision: 0.8665 - recall: 0.7440 - val_accuracy: 0.8532 - val_f1_score: 0.8442 - val_loss: 0.4253 - val_precision: 0.9093 - val_recall: 0.7878\n",
      "Epoch 91/100\n",
      "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m229s\u001b[0m 976ms/step - accuracy: 0.8020 - f1_score: 0.7947 - loss: 0.5456 - precision: 0.8580 - recall: 0.7402 - val_accuracy: 0.8297 - val_f1_score: 0.8241 - val_loss: 0.4737 - val_precision: 0.8890 - val_recall: 0.7680\n",
      "Epoch 92/100\n",
      "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m229s\u001b[0m 977ms/step - accuracy: 0.8174 - f1_score: 0.8107 - loss: 0.5063 - precision: 0.8742 - recall: 0.7560 - val_accuracy: 0.8469 - val_f1_score: 0.8467 - val_loss: 0.4238 - val_precision: 0.8938 - val_recall: 0.8042\n",
      "Epoch 93/100\n",
      "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m227s\u001b[0m 967ms/step - accuracy: 0.8087 - f1_score: 0.8050 - loss: 0.5118 - precision: 0.8650 - recall: 0.7528 - val_accuracy: 0.8404 - val_f1_score: 0.8427 - val_loss: 0.4307 - val_precision: 0.8966 - val_recall: 0.7949\n",
      "Epoch 94/100\n",
      "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m230s\u001b[0m 980ms/step - accuracy: 0.8060 - f1_score: 0.8014 - loss: 0.5233 - precision: 0.8648 - recall: 0.7466 - val_accuracy: 0.8578 - val_f1_score: 0.8558 - val_loss: 0.4018 - val_precision: 0.9129 - val_recall: 0.8054\n",
      "Epoch 95/100\n",
      "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m174s\u001b[0m 740ms/step - accuracy: 0.8209 - f1_score: 0.8215 - loss: 0.5041 - precision: 0.8776 - recall: 0.7721 - val_accuracy: 0.8542 - val_f1_score: 0.8509 - val_loss: 0.4165 - val_precision: 0.8995 - val_recall: 0.8073\n",
      "Epoch 96/100\n",
      "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m237s\u001b[0m 1s/step - accuracy: 0.8131 - f1_score: 0.8110 - loss: 0.5151 - precision: 0.8690 - recall: 0.7602 - val_accuracy: 0.8599 - val_f1_score: 0.8581 - val_loss: 0.3995 - val_precision: 0.9035 - val_recall: 0.8170\n",
      "Epoch 97/100\n",
      "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m254s\u001b[0m 1s/step - accuracy: 0.8204 - f1_score: 0.8132 - loss: 0.5107 - precision: 0.8741 - recall: 0.7604 - val_accuracy: 0.8570 - val_f1_score: 0.8497 - val_loss: 0.4105 - val_precision: 0.9046 - val_recall: 0.8011\n",
      "Epoch 98/100\n",
      "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m228s\u001b[0m 971ms/step - accuracy: 0.8377 - f1_score: 0.8327 - loss: 0.4545 - precision: 0.8897 - recall: 0.7826 - val_accuracy: 0.8687 - val_f1_score: 0.8619 - val_loss: 0.3871 - val_precision: 0.9080 - val_recall: 0.8203\n",
      "Epoch 99/100\n",
      "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m243s\u001b[0m 1s/step - accuracy: 0.8210 - f1_score: 0.8234 - loss: 0.4803 - precision: 0.8767 - recall: 0.7763 - val_accuracy: 0.8603 - val_f1_score: 0.8582 - val_loss: 0.3980 - val_precision: 0.9057 - val_recall: 0.8154\n",
      "Epoch 100/100\n",
      "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m227s\u001b[0m 967ms/step - accuracy: 0.8248 - f1_score: 0.8239 - loss: 0.4794 - precision: 0.8726 - recall: 0.7804 - val_accuracy: 0.8766 - val_f1_score: 0.8698 - val_loss: 0.3734 - val_precision: 0.9210 - val_recall: 0.8239\n"
     ]
    }
   ],
   "source": [
    "# Train the model\n",
    "history = bi_lstm_model.fit(\n",
    "    x=training_set,\n",
    "    validation_data=validation_set,\n",
    "    epochs=100\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "28c4d22e-c271-4be8-984a-5fc6e74bef30",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save Loss plot\n",
    "plt.figure()\n",
    "plt.plot(history.history['loss'], label='Train Loss')\n",
    "plt.plot(history.history['val_loss'], label='Validation Loss')\n",
    "plt.legend()\n",
    "plt.title(\"Loss\")\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.savefig('loss_plot_bilstm.png')  # Save the plot as a PNG file\n",
    "plt.close()\n",
    "\n",
    "# Save Accuracy plot\n",
    "plt.figure()\n",
    "plt.plot(history.history['accuracy'], label='Train Accuracy')\n",
    "plt.plot(history.history['val_accuracy'], label='Validation Accuracy')\n",
    "plt.legend()\n",
    "plt.title(\"Accuracy\")\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.savefig('accuracy_plot_bilstm.png')  # Save the plot as a PNG file\n",
    "plt.close()\n",
    "\n",
    "# Save Precision plot\n",
    "plt.figure()\n",
    "plt.plot(history.history['precision'], label='Train Precision')\n",
    "plt.plot(history.history['val_precision'], label='Validation Precision')\n",
    "plt.legend()\n",
    "plt.title(\"Precision\")\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Precision')\n",
    "plt.savefig('precision_plot_bilstm.png')  # Save the plot as a PNG file\n",
    "plt.close()\n",
    "\n",
    "# Save Recall plot\n",
    "plt.figure()\n",
    "plt.plot(history.history['recall'], label='Train Recall')\n",
    "plt.plot(history.history['val_recall'], label='Validation Recall')\n",
    "plt.legend()\n",
    "plt.title(\"Recall\")\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Recall')\n",
    "plt.savefig('recall_plot_bilstm.png')  # Save the plot as a PNG file\n",
    "plt.close()\n",
    "\n",
    "# Save F1 Score plot\n",
    "plt.figure()\n",
    "plt.plot(history.history['f1_score'], label='Train F1 Score')\n",
    "plt.plot(history.history['val_f1_score'], label='Validation F1 Score')\n",
    "plt.legend()\n",
    "plt.title(\"F1 Score\")\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('F1 Score')\n",
    "plt.savefig('f1_score_plot_bilstm.png')  # Save the plot as a PNG file\n",
    "plt.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "cc047439-6fd4-46e5-a510-dca0dedb436e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                         </span>┃<span style=\"font-weight: bold\"> Output Shape                </span>┃<span style=\"font-weight: bold\">         Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
       "│ flatten (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)                    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">12288</span>)               │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ reshape (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Reshape</span>)                    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">768</span>)             │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ bidirectional (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Bidirectional</span>)        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)                 │         <span style=\"color: #00af00; text-decoration-color: #00af00\">426,496</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)                 │          <span style=\"color: #00af00; text-decoration-color: #00af00\">16,512</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">6</span>)                   │             <span style=\"color: #00af00; text-decoration-color: #00af00\">774</span> │\n",
       "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
       "│ flatten (\u001b[38;5;33mFlatten\u001b[0m)                    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m12288\u001b[0m)               │               \u001b[38;5;34m0\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ reshape (\u001b[38;5;33mReshape\u001b[0m)                    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m768\u001b[0m)             │               \u001b[38;5;34m0\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ bidirectional (\u001b[38;5;33mBidirectional\u001b[0m)        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)                 │         \u001b[38;5;34m426,496\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense (\u001b[38;5;33mDense\u001b[0m)                        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)                 │          \u001b[38;5;34m16,512\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)                      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m6\u001b[0m)                   │             \u001b[38;5;34m774\u001b[0m │\n",
       "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,331,348</span> (5.08 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m1,331,348\u001b[0m (5.08 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">443,782</span> (1.69 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m443,782\u001b[0m (1.69 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Optimizer params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">887,566</span> (3.39 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Optimizer params: \u001b[0m\u001b[38;5;34m887,566\u001b[0m (3.39 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "bi_lstm_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd40071b-2722-4386-8be3-6e9976436146",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

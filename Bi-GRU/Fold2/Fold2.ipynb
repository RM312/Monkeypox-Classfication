{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ac947f9e-ffe1-4fcb-ac1c-45adabc6205c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "abc1ba32-e582-4554-9e3e-8dbc506acdd8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 7126 images belonging to 6 classes.\n"
     ]
    }
   ],
   "source": [
    "# Data Augmentation for Training\n",
    "train_datagen = ImageDataGenerator(rescale=1./255,\n",
    "                                   shear_range=0.2,\n",
    "                                   zoom_range=0.2,\n",
    "                                   horizontal_flip=True)\n",
    "training_set = train_datagen.flow_from_directory(\n",
    "    \"Monkeypox/archive (60)/Augmented Images/Augmented Images/FOLDS_AUG/fold2_AUG/Train/\",\n",
    "    target_size=(64, 64),\n",
    "    batch_size=32,\n",
    "    class_mode='categorical',  # Use 'categorical' for one-hot encoded labels\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3ea27a6d-abde-4e9c-8622-d34d1a3123f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 7126 images belonging to 6 classes.\n"
     ]
    }
   ],
   "source": [
    "test_datagen = ImageDataGenerator(rescale=1./255)\n",
    "validation_set = test_datagen.flow_from_directory(\n",
    "    \"Monkeypox/archive (60)/Augmented Images/Augmented Images/FOLDS_AUG/fold2_AUG/Train/\",\n",
    "    target_size=(64, 64),\n",
    "    batch_size=32,\n",
    "    class_mode='categorical',  # Use 'categorical' for one-hot encoded labels\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b5a19100-9d95-4239-9eef-571bd80e1e96",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Custom F1 Score Metric\n",
    "class F1Score(tf.keras.metrics.Metric):\n",
    "    def __init__(self, name='f1_score', **kwargs):\n",
    "        super(F1Score, self).__init__(name=name, **kwargs)\n",
    "        self.precision = tf.keras.metrics.Precision()\n",
    "        self.recall = tf.keras.metrics.Recall()\n",
    "\n",
    "    def update_state(self, y_true, y_pred, sample_weight=None):\n",
    "        # Update the precision and recall for each batch\n",
    "        self.precision.update_state(y_true, y_pred, sample_weight)\n",
    "        self.recall.update_state(y_true, y_pred, sample_weight)\n",
    "\n",
    "    def result(self):\n",
    "        # Calculate F1 score as the harmonic mean of precision and recall\n",
    "        precision = self.precision.result()\n",
    "        recall = self.recall.result()\n",
    "        return 2 * (precision * recall) / (precision + recall + tf.keras.backend.epsilon())\n",
    "\n",
    "    def reset_states(self):\n",
    "        self.precision.reset_states()\n",
    "        self.recall.reset_states()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fcc2215b-1cef-481f-ac28-d5d728d2930d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build the Bi-GRU Model\n",
    "bi_gru_model = tf.keras.models.Sequential()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3aab2597-8b90-4c00-b194-7f666999ecfd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\KIIT\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\layers\\reshaping\\flatten.py:37: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    }
   ],
   "source": [
    "# Flatten and Reshape for Bi-GRU\n",
    "bi_gru_model.add(tf.keras.layers.Flatten(input_shape=(64, 64, 3)))\n",
    "bi_gru_model.add(tf.keras.layers.Reshape((16, -1)))  # Reshape to (time_steps, features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6df6b847-8461-418a-8f9a-ea931a650eea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bidirectional GRU Layer\n",
    "bi_gru_model.add(tf.keras.layers.Bidirectional(tf.keras.layers.GRU(units=64, activation='tanh', return_sequences=False)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "da8ec490-acc5-447b-85ee-2fa28cd89c97",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fully Connected Layers\n",
    "bi_gru_model.add(tf.keras.layers.Dense(units=128, activation='relu'))\n",
    "bi_gru_model.add(tf.keras.layers.Dense(6, activation='softmax'))  # 6 classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "304896a8-493b-4f3c-a175-81535fca119a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile the model with Precision, Recall, and F1 Score\n",
    "bi_gru_model.compile(\n",
    "    optimizer='adam',\n",
    "    loss='categorical_crossentropy',  # Use categorical_crossentropy for one-hot encoded labels\n",
    "    metrics=[\n",
    "        'accuracy',\n",
    "        tf.keras.metrics.Precision(name='precision'),\n",
    "        tf.keras.metrics.Recall(name='recall'),\n",
    "        F1Score(name='f1_score')  # Add custom F1 score metric\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "091f5b11-7ccb-4eca-9d0c-04d6d09b6696",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\KIIT\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\trainers\\data_adapters\\py_dataset_adapter.py:121: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
      "  self._warn_if_super_not_called()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "\u001b[1m223/223\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 656ms/step - accuracy: 0.3337 - f1_score: 0.0901 - loss: 1.6706 - precision: 0.4109 - recall: 0.0508"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\KIIT\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\trainers\\data_adapters\\py_dataset_adapter.py:121: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
      "  self._warn_if_super_not_called()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m223/223\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m242s\u001b[0m 979ms/step - accuracy: 0.3337 - f1_score: 0.0902 - loss: 1.6705 - precision: 0.4112 - recall: 0.0509 - val_accuracy: 0.3649 - val_f1_score: 0.1953 - val_loss: 1.5946 - val_precision: 0.5560 - val_recall: 0.1184\n",
      "Epoch 2/100\n",
      "\u001b[1m223/223\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m202s\u001b[0m 906ms/step - accuracy: 0.3569 - f1_score: 0.1128 - loss: 1.5928 - precision: 0.6242 - recall: 0.0622 - val_accuracy: 0.3741 - val_f1_score: 0.0995 - val_loss: 1.5556 - val_precision: 0.7379 - val_recall: 0.0533\n",
      "Epoch 3/100\n",
      "\u001b[1m223/223\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m203s\u001b[0m 910ms/step - accuracy: 0.3805 - f1_score: 0.1550 - loss: 1.5327 - precision: 0.6400 - recall: 0.0882 - val_accuracy: 0.4178 - val_f1_score: 0.1929 - val_loss: 1.4726 - val_precision: 0.6373 - val_recall: 0.1137\n",
      "Epoch 4/100\n",
      "\u001b[1m223/223\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m219s\u001b[0m 984ms/step - accuracy: 0.4078 - f1_score: 0.1827 - loss: 1.4948 - precision: 0.6178 - recall: 0.1074 - val_accuracy: 0.4171 - val_f1_score: 0.2279 - val_loss: 1.4407 - val_precision: 0.6649 - val_recall: 0.1375\n",
      "Epoch 5/100\n",
      "\u001b[1m223/223\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m210s\u001b[0m 943ms/step - accuracy: 0.4258 - f1_score: 0.2204 - loss: 1.4409 - precision: 0.6617 - recall: 0.1323 - val_accuracy: 0.4512 - val_f1_score: 0.2946 - val_loss: 1.3857 - val_precision: 0.6557 - val_recall: 0.1900\n",
      "Epoch 6/100\n",
      "\u001b[1m223/223\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m201s\u001b[0m 903ms/step - accuracy: 0.4453 - f1_score: 0.2585 - loss: 1.3927 - precision: 0.6541 - recall: 0.1612 - val_accuracy: 0.4701 - val_f1_score: 0.3337 - val_loss: 1.3445 - val_precision: 0.6447 - val_recall: 0.2251\n",
      "Epoch 7/100\n",
      "\u001b[1m223/223\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m198s\u001b[0m 888ms/step - accuracy: 0.4590 - f1_score: 0.2941 - loss: 1.3713 - precision: 0.6426 - recall: 0.1908 - val_accuracy: 0.4916 - val_f1_score: 0.3187 - val_loss: 1.3139 - val_precision: 0.7034 - val_recall: 0.2060\n",
      "Epoch 8/100\n",
      "\u001b[1m223/223\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m203s\u001b[0m 911ms/step - accuracy: 0.4717 - f1_score: 0.3329 - loss: 1.3414 - precision: 0.6443 - recall: 0.2245 - val_accuracy: 0.5094 - val_f1_score: 0.3755 - val_loss: 1.2561 - val_precision: 0.7163 - val_recall: 0.2544\n",
      "Epoch 9/100\n",
      "\u001b[1m223/223\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m197s\u001b[0m 879ms/step - accuracy: 0.4883 - f1_score: 0.3583 - loss: 1.2987 - precision: 0.6701 - recall: 0.2447 - val_accuracy: 0.5038 - val_f1_score: 0.3912 - val_loss: 1.2594 - val_precision: 0.6812 - val_recall: 0.2743\n",
      "Epoch 10/100\n",
      "\u001b[1m223/223\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m214s\u001b[0m 959ms/step - accuracy: 0.4889 - f1_score: 0.3649 - loss: 1.3001 - precision: 0.6658 - recall: 0.2515 - val_accuracy: 0.5361 - val_f1_score: 0.4427 - val_loss: 1.2204 - val_precision: 0.6858 - val_recall: 0.3268\n",
      "Epoch 11/100\n",
      "\u001b[1m223/223\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m200s\u001b[0m 898ms/step - accuracy: 0.5104 - f1_score: 0.4075 - loss: 1.2496 - precision: 0.6691 - recall: 0.2933 - val_accuracy: 0.5081 - val_f1_score: 0.4286 - val_loss: 1.2672 - val_precision: 0.6900 - val_recall: 0.3108\n",
      "Epoch 12/100\n",
      "\u001b[1m223/223\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m219s\u001b[0m 980ms/step - accuracy: 0.5142 - f1_score: 0.4121 - loss: 1.2472 - precision: 0.6728 - recall: 0.2971 - val_accuracy: 0.5316 - val_f1_score: 0.4443 - val_loss: 1.1907 - val_precision: 0.6948 - val_recall: 0.3266\n",
      "Epoch 13/100\n",
      "\u001b[1m223/223\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m199s\u001b[0m 890ms/step - accuracy: 0.5221 - f1_score: 0.4319 - loss: 1.2217 - precision: 0.6898 - recall: 0.3144 - val_accuracy: 0.5657 - val_f1_score: 0.4977 - val_loss: 1.1302 - val_precision: 0.7165 - val_recall: 0.3813\n",
      "Epoch 14/100\n",
      "\u001b[1m223/223\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m101s\u001b[0m 452ms/step - accuracy: 0.5461 - f1_score: 0.4668 - loss: 1.1707 - precision: 0.6994 - recall: 0.3504 - val_accuracy: 0.5688 - val_f1_score: 0.4958 - val_loss: 1.1323 - val_precision: 0.7230 - val_recall: 0.3772\n",
      "Epoch 15/100\n",
      "\u001b[1m223/223\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m103s\u001b[0m 463ms/step - accuracy: 0.5582 - f1_score: 0.4928 - loss: 1.1469 - precision: 0.7151 - recall: 0.3761 - val_accuracy: 0.5587 - val_f1_score: 0.5025 - val_loss: 1.1122 - val_precision: 0.7072 - val_recall: 0.3897\n",
      "Epoch 16/100\n",
      "\u001b[1m223/223\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m107s\u001b[0m 482ms/step - accuracy: 0.5647 - f1_score: 0.4930 - loss: 1.1297 - precision: 0.7171 - recall: 0.3756 - val_accuracy: 0.6002 - val_f1_score: 0.5331 - val_loss: 1.0378 - val_precision: 0.7676 - val_recall: 0.4084\n",
      "Epoch 17/100\n",
      "\u001b[1m223/223\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m121s\u001b[0m 542ms/step - accuracy: 0.5767 - f1_score: 0.5133 - loss: 1.0885 - precision: 0.7270 - recall: 0.3967 - val_accuracy: 0.5942 - val_f1_score: 0.5269 - val_loss: 1.0446 - val_precision: 0.7569 - val_recall: 0.4042\n",
      "Epoch 18/100\n",
      "\u001b[1m223/223\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m122s\u001b[0m 547ms/step - accuracy: 0.5807 - f1_score: 0.5254 - loss: 1.1026 - precision: 0.7372 - recall: 0.4082 - val_accuracy: 0.6134 - val_f1_score: 0.5635 - val_loss: 1.0011 - val_precision: 0.7813 - val_recall: 0.4406\n",
      "Epoch 19/100\n",
      "\u001b[1m223/223\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m122s\u001b[0m 548ms/step - accuracy: 0.5891 - f1_score: 0.5262 - loss: 1.0712 - precision: 0.7262 - recall: 0.4127 - val_accuracy: 0.6267 - val_f1_score: 0.5846 - val_loss: 0.9737 - val_precision: 0.7685 - val_recall: 0.4718\n",
      "Epoch 20/100\n",
      "\u001b[1m223/223\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m118s\u001b[0m 528ms/step - accuracy: 0.6001 - f1_score: 0.5444 - loss: 1.0408 - precision: 0.7451 - recall: 0.4290 - val_accuracy: 0.6298 - val_f1_score: 0.5964 - val_loss: 0.9671 - val_precision: 0.7433 - val_recall: 0.4979\n",
      "Epoch 21/100\n",
      "\u001b[1m223/223\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m119s\u001b[0m 531ms/step - accuracy: 0.6024 - f1_score: 0.5567 - loss: 1.0214 - precision: 0.7467 - recall: 0.4439 - val_accuracy: 0.6228 - val_f1_score: 0.5526 - val_loss: 0.9854 - val_precision: 0.8074 - val_recall: 0.4200\n",
      "Epoch 22/100\n",
      "\u001b[1m223/223\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m123s\u001b[0m 554ms/step - accuracy: 0.6086 - f1_score: 0.5655 - loss: 1.0220 - precision: 0.7509 - recall: 0.4535 - val_accuracy: 0.6365 - val_f1_score: 0.6073 - val_loss: 0.9529 - val_precision: 0.7385 - val_recall: 0.5157\n",
      "Epoch 23/100\n",
      "\u001b[1m223/223\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m122s\u001b[0m 546ms/step - accuracy: 0.6161 - f1_score: 0.5759 - loss: 1.0109 - precision: 0.7446 - recall: 0.4697 - val_accuracy: 0.6660 - val_f1_score: 0.6189 - val_loss: 0.9042 - val_precision: 0.7907 - val_recall: 0.5084\n",
      "Epoch 24/100\n",
      "\u001b[1m223/223\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m118s\u001b[0m 527ms/step - accuracy: 0.6302 - f1_score: 0.5904 - loss: 0.9610 - precision: 0.7620 - recall: 0.4819 - val_accuracy: 0.6530 - val_f1_score: 0.6252 - val_loss: 0.9025 - val_precision: 0.7730 - val_recall: 0.5248\n",
      "Epoch 25/100\n",
      "\u001b[1m223/223\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m126s\u001b[0m 564ms/step - accuracy: 0.6311 - f1_score: 0.6049 - loss: 0.9541 - precision: 0.7644 - recall: 0.5006 - val_accuracy: 0.6695 - val_f1_score: 0.6455 - val_loss: 0.8686 - val_precision: 0.8098 - val_recall: 0.5366\n",
      "Epoch 26/100\n",
      "\u001b[1m223/223\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m96s\u001b[0m 430ms/step - accuracy: 0.6412 - f1_score: 0.5953 - loss: 0.9594 - precision: 0.7544 - recall: 0.4917 - val_accuracy: 0.6671 - val_f1_score: 0.6351 - val_loss: 0.8682 - val_precision: 0.7978 - val_recall: 0.5275\n",
      "Epoch 27/100\n",
      "\u001b[1m223/223\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m125s\u001b[0m 562ms/step - accuracy: 0.6383 - f1_score: 0.5968 - loss: 0.9422 - precision: 0.7574 - recall: 0.4926 - val_accuracy: 0.6729 - val_f1_score: 0.6491 - val_loss: 0.8725 - val_precision: 0.7828 - val_recall: 0.5544\n",
      "Epoch 28/100\n",
      "\u001b[1m223/223\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m119s\u001b[0m 536ms/step - accuracy: 0.6398 - f1_score: 0.6032 - loss: 0.9384 - precision: 0.7595 - recall: 0.5003 - val_accuracy: 0.6861 - val_f1_score: 0.6676 - val_loss: 0.8269 - val_precision: 0.7895 - val_recall: 0.5783\n",
      "Epoch 29/100\n",
      "\u001b[1m223/223\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m119s\u001b[0m 534ms/step - accuracy: 0.6447 - f1_score: 0.6167 - loss: 0.9184 - precision: 0.7737 - recall: 0.5128 - val_accuracy: 0.6636 - val_f1_score: 0.6139 - val_loss: 0.8791 - val_precision: 0.7994 - val_recall: 0.4983\n",
      "Epoch 30/100\n",
      "\u001b[1m223/223\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m123s\u001b[0m 553ms/step - accuracy: 0.6638 - f1_score: 0.6318 - loss: 0.8933 - precision: 0.7790 - recall: 0.5315 - val_accuracy: 0.6986 - val_f1_score: 0.6633 - val_loss: 0.8215 - val_precision: 0.8300 - val_recall: 0.5523\n",
      "Epoch 31/100\n",
      "\u001b[1m223/223\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m122s\u001b[0m 549ms/step - accuracy: 0.6670 - f1_score: 0.6363 - loss: 0.8921 - precision: 0.7854 - recall: 0.5349 - val_accuracy: 0.6944 - val_f1_score: 0.6615 - val_loss: 0.8090 - val_precision: 0.8338 - val_recall: 0.5483\n",
      "Epoch 32/100\n",
      "\u001b[1m223/223\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m121s\u001b[0m 541ms/step - accuracy: 0.6647 - f1_score: 0.6297 - loss: 0.9005 - precision: 0.7774 - recall: 0.5292 - val_accuracy: 0.6838 - val_f1_score: 0.6590 - val_loss: 0.8221 - val_precision: 0.7829 - val_recall: 0.5689\n",
      "Epoch 33/100\n",
      "\u001b[1m223/223\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m127s\u001b[0m 568ms/step - accuracy: 0.6750 - f1_score: 0.6445 - loss: 0.8651 - precision: 0.7880 - recall: 0.5453 - val_accuracy: 0.7308 - val_f1_score: 0.7049 - val_loss: 0.7386 - val_precision: 0.8539 - val_recall: 0.6002\n",
      "Epoch 34/100\n",
      "\u001b[1m223/223\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m123s\u001b[0m 552ms/step - accuracy: 0.6755 - f1_score: 0.6436 - loss: 0.8527 - precision: 0.7822 - recall: 0.5468 - val_accuracy: 0.7238 - val_f1_score: 0.7028 - val_loss: 0.7571 - val_precision: 0.8169 - val_recall: 0.6166\n",
      "Epoch 35/100\n",
      "\u001b[1m223/223\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m130s\u001b[0m 584ms/step - accuracy: 0.6930 - f1_score: 0.6675 - loss: 0.8259 - precision: 0.7880 - recall: 0.5790 - val_accuracy: 0.7073 - val_f1_score: 0.6800 - val_loss: 0.7683 - val_precision: 0.8286 - val_recall: 0.5766\n",
      "Epoch 36/100\n",
      "\u001b[1m223/223\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m147s\u001b[0m 658ms/step - accuracy: 0.6905 - f1_score: 0.6588 - loss: 0.8328 - precision: 0.7926 - recall: 0.5637 - val_accuracy: 0.7136 - val_f1_score: 0.6959 - val_loss: 0.7433 - val_precision: 0.8230 - val_recall: 0.6029\n",
      "Epoch 37/100\n",
      "\u001b[1m223/223\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m205s\u001b[0m 923ms/step - accuracy: 0.6925 - f1_score: 0.6682 - loss: 0.8019 - precision: 0.7909 - recall: 0.5785 - val_accuracy: 0.7083 - val_f1_score: 0.6879 - val_loss: 0.7594 - val_precision: 0.8318 - val_recall: 0.5864\n",
      "Epoch 38/100\n",
      "\u001b[1m223/223\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m132s\u001b[0m 592ms/step - accuracy: 0.6919 - f1_score: 0.6723 - loss: 0.8069 - precision: 0.7995 - recall: 0.5800 - val_accuracy: 0.7255 - val_f1_score: 0.7066 - val_loss: 0.7384 - val_precision: 0.8188 - val_recall: 0.6214\n",
      "Epoch 39/100\n",
      "\u001b[1m223/223\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m146s\u001b[0m 653ms/step - accuracy: 0.6992 - f1_score: 0.6792 - loss: 0.8042 - precision: 0.8030 - recall: 0.5887 - val_accuracy: 0.7546 - val_f1_score: 0.7225 - val_loss: 0.6942 - val_precision: 0.8554 - val_recall: 0.6253\n",
      "Epoch 40/100\n",
      "\u001b[1m223/223\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m228s\u001b[0m 769ms/step - accuracy: 0.7000 - f1_score: 0.6804 - loss: 0.7908 - precision: 0.8043 - recall: 0.5896 - val_accuracy: 0.7456 - val_f1_score: 0.7287 - val_loss: 0.6846 - val_precision: 0.8465 - val_recall: 0.6398\n",
      "Epoch 41/100\n",
      "\u001b[1m223/223\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m215s\u001b[0m 964ms/step - accuracy: 0.7181 - f1_score: 0.6943 - loss: 0.7809 - precision: 0.8145 - recall: 0.6051 - val_accuracy: 0.7509 - val_f1_score: 0.7410 - val_loss: 0.6821 - val_precision: 0.8432 - val_recall: 0.6610\n",
      "Epoch 42/100\n",
      "\u001b[1m223/223\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m218s\u001b[0m 980ms/step - accuracy: 0.7125 - f1_score: 0.7028 - loss: 0.7569 - precision: 0.8135 - recall: 0.6187 - val_accuracy: 0.7617 - val_f1_score: 0.7543 - val_loss: 0.6462 - val_precision: 0.8510 - val_recall: 0.6774\n",
      "Epoch 43/100\n",
      "\u001b[1m223/223\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m145s\u001b[0m 648ms/step - accuracy: 0.7405 - f1_score: 0.7207 - loss: 0.7105 - precision: 0.8265 - recall: 0.6389 - val_accuracy: 0.7609 - val_f1_score: 0.7447 - val_loss: 0.6634 - val_precision: 0.8556 - val_recall: 0.6593\n",
      "Epoch 44/100\n",
      "\u001b[1m223/223\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m211s\u001b[0m 949ms/step - accuracy: 0.7144 - f1_score: 0.6973 - loss: 0.7544 - precision: 0.8080 - recall: 0.6134 - val_accuracy: 0.7644 - val_f1_score: 0.7547 - val_loss: 0.6549 - val_precision: 0.8658 - val_recall: 0.6688\n",
      "Epoch 45/100\n",
      "\u001b[1m223/223\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m222s\u001b[0m 997ms/step - accuracy: 0.7214 - f1_score: 0.7089 - loss: 0.7577 - precision: 0.8112 - recall: 0.6296 - val_accuracy: 0.7722 - val_f1_score: 0.7591 - val_loss: 0.6230 - val_precision: 0.8693 - val_recall: 0.6737\n",
      "Epoch 46/100\n",
      "\u001b[1m223/223\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m218s\u001b[0m 977ms/step - accuracy: 0.7323 - f1_score: 0.7158 - loss: 0.7206 - precision: 0.8289 - recall: 0.6299 - val_accuracy: 0.7482 - val_f1_score: 0.7362 - val_loss: 0.6819 - val_precision: 0.8391 - val_recall: 0.6558\n",
      "Epoch 47/100\n",
      "\u001b[1m223/223\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m210s\u001b[0m 942ms/step - accuracy: 0.7214 - f1_score: 0.7170 - loss: 0.7503 - precision: 0.8162 - recall: 0.6393 - val_accuracy: 0.7686 - val_f1_score: 0.7516 - val_loss: 0.6311 - val_precision: 0.8612 - val_recall: 0.6667\n",
      "Epoch 48/100\n",
      "\u001b[1m223/223\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m210s\u001b[0m 942ms/step - accuracy: 0.7332 - f1_score: 0.7186 - loss: 0.7279 - precision: 0.8213 - recall: 0.6388 - val_accuracy: 0.7756 - val_f1_score: 0.7710 - val_loss: 0.6120 - val_precision: 0.8686 - val_recall: 0.6931\n",
      "Epoch 49/100\n",
      "\u001b[1m223/223\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m210s\u001b[0m 944ms/step - accuracy: 0.7277 - f1_score: 0.7198 - loss: 0.7129 - precision: 0.8238 - recall: 0.6392 - val_accuracy: 0.7857 - val_f1_score: 0.7720 - val_loss: 0.5989 - val_precision: 0.8676 - val_recall: 0.6953\n",
      "Epoch 50/100\n",
      "\u001b[1m223/223\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m218s\u001b[0m 980ms/step - accuracy: 0.7413 - f1_score: 0.7347 - loss: 0.6959 - precision: 0.8295 - recall: 0.6595 - val_accuracy: 0.7920 - val_f1_score: 0.7809 - val_loss: 0.5894 - val_precision: 0.8739 - val_recall: 0.7059\n",
      "Epoch 51/100\n",
      "\u001b[1m223/223\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m230s\u001b[0m 1s/step - accuracy: 0.7327 - f1_score: 0.7204 - loss: 0.7012 - precision: 0.8133 - recall: 0.6466 - val_accuracy: 0.7738 - val_f1_score: 0.7688 - val_loss: 0.6086 - val_precision: 0.8536 - val_recall: 0.6994\n",
      "Epoch 52/100\n",
      "\u001b[1m223/223\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m185s\u001b[0m 831ms/step - accuracy: 0.7528 - f1_score: 0.7476 - loss: 0.6483 - precision: 0.8307 - recall: 0.6796 - val_accuracy: 0.7724 - val_f1_score: 0.7619 - val_loss: 0.6136 - val_precision: 0.8583 - val_recall: 0.6850\n",
      "Epoch 54/100\n",
      "\u001b[1m223/223\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m203s\u001b[0m 910ms/step - accuracy: 0.7424 - f1_score: 0.7330 - loss: 0.6712 - precision: 0.8214 - recall: 0.6617 - val_accuracy: 0.8024 - val_f1_score: 0.7999 - val_loss: 0.5450 - val_precision: 0.8782 - val_recall: 0.7345\n",
      "Epoch 55/100\n",
      "\u001b[1m223/223\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m209s\u001b[0m 935ms/step - accuracy: 0.7636 - f1_score: 0.7496 - loss: 0.6496 - precision: 0.8327 - recall: 0.6816 - val_accuracy: 0.8009 - val_f1_score: 0.7874 - val_loss: 0.5487 - val_precision: 0.8694 - val_recall: 0.7195\n",
      "Epoch 56/100\n",
      "\u001b[1m223/223\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m215s\u001b[0m 962ms/step - accuracy: 0.7682 - f1_score: 0.7547 - loss: 0.6359 - precision: 0.8397 - recall: 0.6854 - val_accuracy: 0.8183 - val_f1_score: 0.8129 - val_loss: 0.5142 - val_precision: 0.8927 - val_recall: 0.7461\n",
      "Epoch 57/100\n",
      "\u001b[1m223/223\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m210s\u001b[0m 940ms/step - accuracy: 0.7747 - f1_score: 0.7633 - loss: 0.6227 - precision: 0.8431 - recall: 0.6973 - val_accuracy: 0.7836 - val_f1_score: 0.7852 - val_loss: 0.5688 - val_precision: 0.8613 - val_recall: 0.7214\n",
      "Epoch 58/100\n",
      "\u001b[1m223/223\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m221s\u001b[0m 992ms/step - accuracy: 0.7671 - f1_score: 0.7605 - loss: 0.6336 - precision: 0.8405 - recall: 0.6945 - val_accuracy: 0.8044 - val_f1_score: 0.7954 - val_loss: 0.5355 - val_precision: 0.8670 - val_recall: 0.7346\n",
      "Epoch 59/100\n",
      "\u001b[1m223/223\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m263s\u001b[0m 994ms/step - accuracy: 0.7797 - f1_score: 0.7694 - loss: 0.6113 - precision: 0.8471 - recall: 0.7047 - val_accuracy: 0.8258 - val_f1_score: 0.8211 - val_loss: 0.4941 - val_precision: 0.8950 - val_recall: 0.7585\n",
      "Epoch 60/100\n",
      "\u001b[1m223/223\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m261s\u001b[0m 1s/step - accuracy: 0.7805 - f1_score: 0.7733 - loss: 0.6077 - precision: 0.8469 - recall: 0.7115 - val_accuracy: 0.8139 - val_f1_score: 0.8047 - val_loss: 0.5226 - val_precision: 0.8787 - val_recall: 0.7422\n",
      "Epoch 61/100\n",
      "\u001b[1m223/223\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m156s\u001b[0m 698ms/step - accuracy: 0.7785 - f1_score: 0.7723 - loss: 0.5965 - precision: 0.8439 - recall: 0.7120 - val_accuracy: 0.8261 - val_f1_score: 0.8209 - val_loss: 0.4946 - val_precision: 0.8897 - val_recall: 0.7620\n",
      "Epoch 63/100\n",
      "\u001b[1m223/223\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m263s\u001b[0m 1s/step - accuracy: 0.7862 - f1_score: 0.7877 - loss: 0.5765 - precision: 0.8555 - recall: 0.7299 - val_accuracy: 0.8190 - val_f1_score: 0.8183 - val_loss: 0.4837 - val_precision: 0.8823 - val_recall: 0.7630\n",
      "Epoch 70/100\n",
      "\u001b[1m223/223\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m226s\u001b[0m 1s/step - accuracy: 0.7865 - f1_score: 0.7820 - loss: 0.5830 - precision: 0.8532 - recall: 0.7218 - val_accuracy: 0.8333 - val_f1_score: 0.8315 - val_loss: 0.4716 - val_precision: 0.8937 - val_recall: 0.7774\n",
      "Epoch 71/100\n",
      "\u001b[1m223/223\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m171s\u001b[0m 767ms/step - accuracy: 0.7825 - f1_score: 0.7740 - loss: 0.5854 - precision: 0.8433 - recall: 0.7152 - val_accuracy: 0.8257 - val_f1_score: 0.8191 - val_loss: 0.4815 - val_precision: 0.8967 - val_recall: 0.7539\n",
      "Epoch 72/100\n",
      "\u001b[1m223/223\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m239s\u001b[0m 1s/step - accuracy: 0.7878 - f1_score: 0.7834 - loss: 0.5805 - precision: 0.8453 - recall: 0.7299 - val_accuracy: 0.8191 - val_f1_score: 0.8178 - val_loss: 0.4837 - val_precision: 0.8701 - val_recall: 0.7714\n",
      "Epoch 73/100\n",
      "\u001b[1m223/223\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m230s\u001b[0m 1s/step - accuracy: 0.7987 - f1_score: 0.7972 - loss: 0.5546 - precision: 0.8580 - recall: 0.7444 - val_accuracy: 0.8409 - val_f1_score: 0.8392 - val_loss: 0.4425 - val_precision: 0.8953 - val_recall: 0.7898\n",
      "Epoch 74/100\n",
      "\u001b[1m223/223\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m229s\u001b[0m 1s/step - accuracy: 0.8035 - f1_score: 0.8008 - loss: 0.5371 - precision: 0.8613 - recall: 0.7482 - val_accuracy: 0.8462 - val_f1_score: 0.8453 - val_loss: 0.4397 - val_precision: 0.8988 - val_recall: 0.7978\n",
      "Epoch 75/100\n",
      "\u001b[1m223/223\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m205s\u001b[0m 922ms/step - accuracy: 0.7969 - f1_score: 0.7937 - loss: 0.5531 - precision: 0.8564 - recall: 0.7395 - val_accuracy: 0.8469 - val_f1_score: 0.8444 - val_loss: 0.4411 - val_precision: 0.9043 - val_recall: 0.7919\n",
      "Epoch 76/100\n",
      "\u001b[1m223/223\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m226s\u001b[0m 1s/step - accuracy: 0.8118 - f1_score: 0.8107 - loss: 0.5311 - precision: 0.8754 - recall: 0.7549 - val_accuracy: 0.8663 - val_f1_score: 0.8603 - val_loss: 0.4056 - val_precision: 0.9118 - val_recall: 0.8143\n",
      "Epoch 77/100\n",
      "\u001b[1m223/223\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m229s\u001b[0m 1s/step - accuracy: 0.8159 - f1_score: 0.8119 - loss: 0.5183 - precision: 0.8658 - recall: 0.7644 - val_accuracy: 0.8470 - val_f1_score: 0.8433 - val_loss: 0.4361 - val_precision: 0.9028 - val_recall: 0.7912\n",
      "Epoch 78/100\n",
      "\u001b[1m223/223\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m244s\u001b[0m 1s/step - accuracy: 0.8151 - f1_score: 0.8097 - loss: 0.5191 - precision: 0.8638 - recall: 0.7620 - val_accuracy: 0.8354 - val_f1_score: 0.8310 - val_loss: 0.4663 - val_precision: 0.9040 - val_recall: 0.7689\n",
      "Epoch 79/100\n",
      "\u001b[1m223/223\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m232s\u001b[0m 1s/step - accuracy: 0.7930 - f1_score: 0.7881 - loss: 0.5543 - precision: 0.8488 - recall: 0.7356 - val_accuracy: 0.8525 - val_f1_score: 0.8494 - val_loss: 0.4165 - val_precision: 0.8921 - val_recall: 0.8107\n",
      "Epoch 80/100\n",
      "\u001b[1m223/223\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m244s\u001b[0m 1s/step - accuracy: 0.8012 - f1_score: 0.8001 - loss: 0.5342 - precision: 0.8545 - recall: 0.7522 - val_accuracy: 0.8587 - val_f1_score: 0.8556 - val_loss: 0.4008 - val_precision: 0.9047 - val_recall: 0.8115\n",
      "Epoch 81/100\n",
      "\u001b[1m223/223\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m222s\u001b[0m 996ms/step - accuracy: 0.8106 - f1_score: 0.8095 - loss: 0.5155 - precision: 0.8642 - recall: 0.7613 - val_accuracy: 0.8553 - val_f1_score: 0.8542 - val_loss: 0.4032 - val_precision: 0.9015 - val_recall: 0.8117\n",
      "Epoch 82/100\n",
      "\u001b[1m223/223\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m213s\u001b[0m 954ms/step - accuracy: 0.8090 - f1_score: 0.8106 - loss: 0.5186 - precision: 0.8647 - recall: 0.7629 - val_accuracy: 0.8459 - val_f1_score: 0.8416 - val_loss: 0.4311 - val_precision: 0.8919 - val_recall: 0.7967\n",
      "Epoch 83/100\n",
      "\u001b[1m223/223\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m203s\u001b[0m 912ms/step - accuracy: 0.8152 - f1_score: 0.8167 - loss: 0.4968 - precision: 0.8677 - recall: 0.7715 - val_accuracy: 0.8525 - val_f1_score: 0.8524 - val_loss: 0.4180 - val_precision: 0.8953 - val_recall: 0.8135\n",
      "Epoch 84/100\n",
      "\u001b[1m223/223\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m187s\u001b[0m 837ms/step - accuracy: 0.8067 - f1_score: 0.8033 - loss: 0.5443 - precision: 0.8588 - recall: 0.7545 - val_accuracy: 0.8517 - val_f1_score: 0.8494 - val_loss: 0.4131 - val_precision: 0.8914 - val_recall: 0.8111\n",
      "Epoch 85/100\n",
      "\u001b[1m223/223\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m199s\u001b[0m 891ms/step - accuracy: 0.8120 - f1_score: 0.8092 - loss: 0.5252 - precision: 0.8636 - recall: 0.7614 - val_accuracy: 0.8674 - val_f1_score: 0.8664 - val_loss: 0.3907 - val_precision: 0.9140 - val_recall: 0.8235\n",
      "Epoch 86/100\n",
      "\u001b[1m223/223\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m181s\u001b[0m 809ms/step - accuracy: 0.8220 - f1_score: 0.8202 - loss: 0.5051 - precision: 0.8704 - recall: 0.7756 - val_accuracy: 0.8515 - val_f1_score: 0.8469 - val_loss: 0.4247 - val_precision: 0.8955 - val_recall: 0.8033\n",
      "Epoch 87/100\n",
      "\u001b[1m223/223\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m220s\u001b[0m 986ms/step - accuracy: 0.8136 - f1_score: 0.8108 - loss: 0.5087 - precision: 0.8666 - recall: 0.7619 - val_accuracy: 0.8689 - val_f1_score: 0.8702 - val_loss: 0.3790 - val_precision: 0.9140 - val_recall: 0.8305\n",
      "Epoch 88/100\n",
      "\u001b[1m223/223\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m210s\u001b[0m 941ms/step - accuracy: 0.8371 - f1_score: 0.8353 - loss: 0.4573 - precision: 0.8890 - recall: 0.7878 - val_accuracy: 0.8702 - val_f1_score: 0.8675 - val_loss: 0.3867 - val_precision: 0.9135 - val_recall: 0.8258\n",
      "Epoch 89/100\n",
      "\u001b[1m223/223\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m228s\u001b[0m 1s/step - accuracy: 0.8258 - f1_score: 0.8222 - loss: 0.4850 - precision: 0.8721 - recall: 0.7778 - val_accuracy: 0.8639 - val_f1_score: 0.8586 - val_loss: 0.3893 - val_precision: 0.9064 - val_recall: 0.8156\n",
      "Epoch 90/100\n",
      "\u001b[1m223/223\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m193s\u001b[0m 866ms/step - accuracy: 0.8275 - f1_score: 0.8248 - loss: 0.4784 - precision: 0.8699 - recall: 0.7842 - val_accuracy: 0.8664 - val_f1_score: 0.8660 - val_loss: 0.3833 - val_precision: 0.9058 - val_recall: 0.8295\n",
      "Epoch 91/100\n",
      "\u001b[1m223/223\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m215s\u001b[0m 964ms/step - accuracy: 0.8358 - f1_score: 0.8335 - loss: 0.4669 - precision: 0.8797 - recall: 0.7920 - val_accuracy: 0.8525 - val_f1_score: 0.8506 - val_loss: 0.4136 - val_precision: 0.8970 - val_recall: 0.8087\n",
      "Epoch 92/100\n",
      "\u001b[1m223/223\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m268s\u001b[0m 1s/step - accuracy: 0.8316 - f1_score: 0.8252 - loss: 0.4760 - precision: 0.8742 - recall: 0.7813 - val_accuracy: 0.8588 - val_f1_score: 0.8579 - val_loss: 0.4063 - val_precision: 0.8956 - val_recall: 0.8233\n",
      "Epoch 93/100\n",
      "\u001b[1m223/223\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m191s\u001b[0m 857ms/step - accuracy: 0.8261 - f1_score: 0.8231 - loss: 0.4842 - precision: 0.8699 - recall: 0.7812 - val_accuracy: 0.8668 - val_f1_score: 0.8638 - val_loss: 0.3847 - val_precision: 0.9041 - val_recall: 0.8270\n",
      "Epoch 94/100\n",
      "\u001b[1m223/223\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m189s\u001b[0m 846ms/step - accuracy: 0.8294 - f1_score: 0.8261 - loss: 0.4758 - precision: 0.8763 - recall: 0.7814 - val_accuracy: 0.8637 - val_f1_score: 0.8617 - val_loss: 0.3889 - val_precision: 0.9034 - val_recall: 0.8237\n",
      "Epoch 95/100\n",
      "\u001b[1m223/223\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m192s\u001b[0m 863ms/step - accuracy: 0.8363 - f1_score: 0.8336 - loss: 0.4574 - precision: 0.8783 - recall: 0.7933 - val_accuracy: 0.8757 - val_f1_score: 0.8741 - val_loss: 0.3706 - val_precision: 0.9200 - val_recall: 0.8326\n",
      "Epoch 96/100\n",
      "\u001b[1m223/223\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m201s\u001b[0m 901ms/step - accuracy: 0.8317 - f1_score: 0.8265 - loss: 0.4608 - precision: 0.8743 - recall: 0.7837 - val_accuracy: 0.8716 - val_f1_score: 0.8708 - val_loss: 0.3682 - val_precision: 0.9130 - val_recall: 0.8323\n",
      "Epoch 97/100\n",
      "\u001b[1m223/223\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m153s\u001b[0m 686ms/step - accuracy: 0.8175 - f1_score: 0.8167 - loss: 0.4948 - precision: 0.8645 - recall: 0.7738 - val_accuracy: 0.8752 - val_f1_score: 0.8710 - val_loss: 0.3639 - val_precision: 0.9068 - val_recall: 0.8379\n",
      "Epoch 98/100\n",
      "\u001b[1m223/223\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m165s\u001b[0m 741ms/step - accuracy: 0.8402 - f1_score: 0.8390 - loss: 0.4579 - precision: 0.8806 - recall: 0.8011 - val_accuracy: 0.8654 - val_f1_score: 0.8650 - val_loss: 0.3762 - val_precision: 0.9023 - val_recall: 0.8306\n",
      "Epoch 99/100\n",
      "\u001b[1m223/223\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m136s\u001b[0m 608ms/step - accuracy: 0.8362 - f1_score: 0.8297 - loss: 0.4730 - precision: 0.8709 - recall: 0.7923 - val_accuracy: 0.8762 - val_f1_score: 0.8733 - val_loss: 0.3530 - val_precision: 0.9101 - val_recall: 0.8395\n",
      "Epoch 100/100\n",
      "\u001b[1m223/223\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m131s\u001b[0m 589ms/step - accuracy: 0.8350 - f1_score: 0.8338 - loss: 0.4537 - precision: 0.8775 - recall: 0.7943 - val_accuracy: 0.8870 - val_f1_score: 0.8856 - val_loss: 0.3218 - val_precision: 0.9235 - val_recall: 0.8507\n"
     ]
    }
   ],
   "source": [
    "# Train the model\n",
    "history = bi_gru_model.fit(\n",
    "    x=training_set,\n",
    "    validation_data=validation_set,\n",
    "    epochs=100\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "bdaf7159-7d3d-4fb2-9e76-4d72890a3676",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save Loss plot\n",
    "plt.figure()\n",
    "plt.plot(history.history['loss'], label='Train Loss')\n",
    "plt.plot(history.history['val_loss'], label='Validation Loss')\n",
    "plt.legend()\n",
    "plt.title(\"Loss\")\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.savefig('loss_plot_bigru.png')  # Save the plot as a PNG file\n",
    "plt.close()\n",
    "\n",
    "# Save Accuracy plot\n",
    "plt.figure()\n",
    "plt.plot(history.history['accuracy'], label='Train Accuracy')\n",
    "plt.plot(history.history['val_accuracy'], label='Validation Accuracy')\n",
    "plt.legend()\n",
    "plt.title(\"Accuracy\")\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.savefig('accuracy_plot_bigru.png')  # Save the plot as a PNG file\n",
    "plt.close()\n",
    "\n",
    "# Save Precision plot\n",
    "plt.figure()\n",
    "plt.plot(history.history['precision'], label='Train Precision')\n",
    "plt.plot(history.history['val_precision'], label='Validation Precision')\n",
    "plt.legend()\n",
    "plt.title(\"Precision\")\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Precision')\n",
    "plt.savefig('precision_plot_bigru.png')  # Save the plot as a PNG file\n",
    "plt.close()\n",
    "\n",
    "# Save Recall plot\n",
    "plt.figure()\n",
    "plt.plot(history.history['recall'], label='Train Recall')\n",
    "plt.plot(history.history['val_recall'], label='Validation Recall')\n",
    "plt.legend()\n",
    "plt.title(\"Recall\")\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Recall')\n",
    "plt.savefig('recall_plot_bigru.png')  # Save the plot as a PNG file\n",
    "plt.close()\n",
    "\n",
    "# Save F1 Score plot\n",
    "plt.figure()\n",
    "plt.plot(history.history['f1_score'], label='Train F1 Score')\n",
    "plt.plot(history.history['val_f1_score'], label='Validation F1 Score')\n",
    "plt.legend()\n",
    "plt.title(\"F1 Score\")\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('F1 Score')\n",
    "plt.savefig('f1_score_plot_bigru.png')  # Save the plot as a PNG file\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2fcb970d-e6c8-442d-83ab-bb90cbd9c8ae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                         </span>┃<span style=\"font-weight: bold\"> Output Shape                </span>┃<span style=\"font-weight: bold\">         Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
       "│ flatten (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)                    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">12288</span>)               │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ reshape (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Reshape</span>)                    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">768</span>)             │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ bidirectional (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Bidirectional</span>)        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)                 │         <span style=\"color: #00af00; text-decoration-color: #00af00\">320,256</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)                 │          <span style=\"color: #00af00; text-decoration-color: #00af00\">16,512</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">6</span>)                   │             <span style=\"color: #00af00; text-decoration-color: #00af00\">774</span> │\n",
       "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
       "│ flatten (\u001b[38;5;33mFlatten\u001b[0m)                    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m12288\u001b[0m)               │               \u001b[38;5;34m0\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ reshape (\u001b[38;5;33mReshape\u001b[0m)                    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m768\u001b[0m)             │               \u001b[38;5;34m0\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ bidirectional (\u001b[38;5;33mBidirectional\u001b[0m)        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)                 │         \u001b[38;5;34m320,256\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense (\u001b[38;5;33mDense\u001b[0m)                        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)                 │          \u001b[38;5;34m16,512\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)                      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m6\u001b[0m)                   │             \u001b[38;5;34m774\u001b[0m │\n",
       "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,012,628</span> (3.86 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m1,012,628\u001b[0m (3.86 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">337,542</span> (1.29 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m337,542\u001b[0m (1.29 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Optimizer params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">675,086</span> (2.58 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Optimizer params: \u001b[0m\u001b[38;5;34m675,086\u001b[0m (2.58 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "bi_gru_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9fac0b2-c967-4fb3-85e4-b39bd7559f80",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

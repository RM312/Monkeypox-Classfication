{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "466144bc-8b03-4972-8270-b8678a61d355",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.compat.v1 import ConfigProto\n",
    "from tensorflow.compat.v1 import InteractiveSession\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "65ef942e-84e6-46cb-99b6-3a9fc4da0693",
   "metadata": {},
   "outputs": [],
   "source": [
    "# GPU Configuration\n",
    "config = ConfigProto()\n",
    "config.gpu_options.per_process_gpu_memory_fraction = 0.5\n",
    "config.gpu_options.allow_growth = True\n",
    "session = InteractiveSession(config=config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9c4705bb-9a9b-4a7b-9be9-ebd702a526e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data Augmentation for Training\n",
    "train_datagen = ImageDataGenerator(rescale=1./255,\n",
    "                                   shear_range=0.2,\n",
    "                                   zoom_range=0.2,\n",
    "                                   horizontal_flip=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "235d7a07-79f1-4291-b4ce-77ef308c79a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 7532 images belonging to 6 classes.\n"
     ]
    }
   ],
   "source": [
    "training_set = train_datagen.flow_from_directory(\n",
    "    \"Monkeypox/archive (60)/Augmented Images/Augmented Images/FOLDS_AUG/fold5_AUG/Train/\",\n",
    "    target_size=(64, 64),\n",
    "    batch_size=32,\n",
    "    class_mode='categorical',  # Use 'categorical' for one-hot encoded labels\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ba43f161-007e-4dfa-a698-436351456c87",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 7532 images belonging to 6 classes.\n"
     ]
    }
   ],
   "source": [
    "test_datagen = ImageDataGenerator(rescale=1./255)\n",
    "validation_set = test_datagen.flow_from_directory(\n",
    "    \"Monkeypox/archive (60)/Augmented Images/Augmented Images/FOLDS_AUG/fold5_AUG/Train/\",\n",
    "    target_size=(64, 64),\n",
    "    batch_size=32,\n",
    "    class_mode='categorical',  # Use 'categorical' for one-hot encoded labels\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7e1adf2c-81c6-40ae-8953-ae68a35227e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Custom F1 Score Metric\n",
    "class F1Score(tf.keras.metrics.Metric):\n",
    "    def __init__(self, name='f1_score', **kwargs):\n",
    "        super(F1Score, self).__init__(name=name, **kwargs)\n",
    "        self.precision = tf.keras.metrics.Precision()\n",
    "        self.recall = tf.keras.metrics.Recall()\n",
    "\n",
    "    def update_state(self, y_true, y_pred, sample_weight=None):\n",
    "        # Update the precision and recall for each batch\n",
    "        self.precision.update_state(y_true, y_pred, sample_weight)\n",
    "        self.recall.update_state(y_true, y_pred, sample_weight)\n",
    "\n",
    "    def result(self):\n",
    "        # Calculate F1 score as the harmonic mean of precision and recall\n",
    "        precision = self.precision.result()\n",
    "        recall = self.recall.result()\n",
    "        return 2 * (precision * recall) / (precision + recall + tf.keras.backend.epsilon())\n",
    "\n",
    "    def reset_states(self):\n",
    "        self.precision.reset_states()\n",
    "        self.recall.reset_states()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "618fb192-74bd-4bc4-b99f-43581b26ff5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build the CNN-LSTM Model\n",
    "cnn_lstm = tf.keras.models.Sequential()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "379adc87-3046-43a9-beb3-0b71e3cb3698",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Flatten and Reshape for LSTM\n",
    "cnn_lstm.add(tf.keras.layers.Flatten())\n",
    "cnn_lstm.add(tf.keras.layers.Reshape((16, -1)))  # Reshape to (time_steps, features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8d81f589-1f4d-4898-817d-d6dcd2d21d82",
   "metadata": {},
   "outputs": [],
   "source": [
    "# LSTM Layer\n",
    "cnn_lstm.add(tf.keras.layers.LSTM(units=64, activation='tanh', return_sequences=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "caba13e3-ddbc-40c9-9b0d-6bb1174e7652",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fully Connected Layers\n",
    "cnn_lstm.add(tf.keras.layers.Dense(units=128, activation='relu'))\n",
    "cnn_lstm.add(tf.keras.layers.Dense(6, activation='softmax'))  # 6 classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5aaa8ace-30e1-42a0-869d-ef751687f014",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile the model with Precision, Recall, and F1 Score\n",
    "cnn_lstm.compile(\n",
    "    optimizer='adam',\n",
    "    loss='categorical_crossentropy',  # Use categorical_crossentropy for one-hot encoded labels\n",
    "    metrics=[\n",
    "        'accuracy',\n",
    "        tf.keras.metrics.Precision(name='precision'),\n",
    "        tf.keras.metrics.Recall(name='recall'),\n",
    "        F1Score(name='f1_score')  # Add custom F1 score metric\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2ca603b4-0cb5-4264-8776-ec92e1136ae7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\KIIT\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\trainers\\data_adapters\\py_dataset_adapter.py:121: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
      "  self._warn_if_super_not_called()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "\u001b[1m236/236\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 197ms/step - accuracy: 0.3783 - f1_score: 0.0673 - loss: 1.6183 - precision: 0.4289 - recall: 0.0371"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\KIIT\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\trainers\\data_adapters\\py_dataset_adapter.py:121: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
      "  self._warn_if_super_not_called()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m236/236\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m72s\u001b[0m 279ms/step - accuracy: 0.3784 - f1_score: 0.0674 - loss: 1.6182 - precision: 0.4294 - recall: 0.0371 - val_accuracy: 0.3537 - val_f1_score: 0.1179 - val_loss: 1.5746 - val_precision: 0.6653 - val_recall: 0.0647\n",
      "Epoch 2/100\n",
      "\u001b[1m236/236\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m55s\u001b[0m 232ms/step - accuracy: 0.3961 - f1_score: 0.1695 - loss: 1.5538 - precision: 0.5770 - recall: 0.0995 - val_accuracy: 0.4052 - val_f1_score: 0.2249 - val_loss: 1.5288 - val_precision: 0.5820 - val_recall: 0.1394\n",
      "Epoch 3/100\n",
      "\u001b[1m236/236\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m55s\u001b[0m 233ms/step - accuracy: 0.4008 - f1_score: 0.2038 - loss: 1.5348 - precision: 0.6012 - recall: 0.1228 - val_accuracy: 0.4153 - val_f1_score: 0.2719 - val_loss: 1.5050 - val_precision: 0.5867 - val_recall: 0.1770\n",
      "Epoch 4/100\n",
      "\u001b[1m236/236\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m55s\u001b[0m 232ms/step - accuracy: 0.4214 - f1_score: 0.2304 - loss: 1.5025 - precision: 0.5919 - recall: 0.1433 - val_accuracy: 0.4361 - val_f1_score: 0.2539 - val_loss: 1.4568 - val_precision: 0.6627 - val_recall: 0.1571\n",
      "Epoch 5/100\n",
      "\u001b[1m236/236\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m54s\u001b[0m 231ms/step - accuracy: 0.4264 - f1_score: 0.2724 - loss: 1.4609 - precision: 0.6333 - recall: 0.1736 - val_accuracy: 0.4436 - val_f1_score: 0.3001 - val_loss: 1.4415 - val_precision: 0.6317 - val_recall: 0.1968\n",
      "Epoch 6/100\n",
      "\u001b[1m236/236\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m56s\u001b[0m 238ms/step - accuracy: 0.4317 - f1_score: 0.2665 - loss: 1.4535 - precision: 0.6209 - recall: 0.1700 - val_accuracy: 0.4413 - val_f1_score: 0.2100 - val_loss: 1.4277 - val_precision: 0.7337 - val_recall: 0.1225\n",
      "Epoch 7/100\n",
      "\u001b[1m236/236\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 238ms/step - accuracy: 0.4520 - f1_score: 0.2895 - loss: 1.4169 - precision: 0.6369 - recall: 0.1876 - val_accuracy: 0.4863 - val_f1_score: 0.2800 - val_loss: 1.3681 - val_precision: 0.6878 - val_recall: 0.1758\n",
      "Epoch 8/100\n",
      "\u001b[1m236/236\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m50s\u001b[0m 213ms/step - accuracy: 0.4697 - f1_score: 0.3154 - loss: 1.3824 - precision: 0.6556 - recall: 0.2080 - val_accuracy: 0.4688 - val_f1_score: 0.2505 - val_loss: 1.3760 - val_precision: 0.6993 - val_recall: 0.1525\n",
      "Epoch 9/100\n",
      "\u001b[1m236/236\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m55s\u001b[0m 233ms/step - accuracy: 0.4830 - f1_score: 0.3316 - loss: 1.3565 - precision: 0.6602 - recall: 0.2219 - val_accuracy: 0.5097 - val_f1_score: 0.4002 - val_loss: 1.2953 - val_precision: 0.6498 - val_recall: 0.2892\n",
      "Epoch 10/100\n",
      "\u001b[1m236/236\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m56s\u001b[0m 237ms/step - accuracy: 0.4931 - f1_score: 0.3621 - loss: 1.3282 - precision: 0.6440 - recall: 0.2519 - val_accuracy: 0.5204 - val_f1_score: 0.3964 - val_loss: 1.2614 - val_precision: 0.6786 - val_recall: 0.2800\n",
      "Epoch 11/100\n",
      "\u001b[1m236/236\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m54s\u001b[0m 230ms/step - accuracy: 0.4893 - f1_score: 0.3709 - loss: 1.3146 - precision: 0.6557 - recall: 0.2588 - val_accuracy: 0.5219 - val_f1_score: 0.4023 - val_loss: 1.2576 - val_precision: 0.7292 - val_recall: 0.2777\n",
      "Epoch 12/100\n",
      "\u001b[1m236/236\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m55s\u001b[0m 235ms/step - accuracy: 0.5171 - f1_score: 0.4114 - loss: 1.2759 - precision: 0.6862 - recall: 0.2941 - val_accuracy: 0.4462 - val_f1_score: 0.3070 - val_loss: 1.3737 - val_precision: 0.6033 - val_recall: 0.2059\n",
      "Epoch 13/100\n",
      "\u001b[1m236/236\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m55s\u001b[0m 231ms/step - accuracy: 0.5137 - f1_score: 0.4112 - loss: 1.2770 - precision: 0.6823 - recall: 0.2953 - val_accuracy: 0.5462 - val_f1_score: 0.4314 - val_loss: 1.2194 - val_precision: 0.7204 - val_recall: 0.3079\n",
      "Epoch 14/100\n",
      "\u001b[1m236/236\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m54s\u001b[0m 229ms/step - accuracy: 0.5295 - f1_score: 0.4269 - loss: 1.2423 - precision: 0.6803 - recall: 0.3111 - val_accuracy: 0.5451 - val_f1_score: 0.4386 - val_loss: 1.1948 - val_precision: 0.7349 - val_recall: 0.3125\n",
      "Epoch 15/100\n",
      "\u001b[1m236/236\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m54s\u001b[0m 230ms/step - accuracy: 0.5292 - f1_score: 0.4378 - loss: 1.2362 - precision: 0.6835 - recall: 0.3222 - val_accuracy: 0.5482 - val_f1_score: 0.4854 - val_loss: 1.1866 - val_precision: 0.6726 - val_recall: 0.3797\n",
      "Epoch 16/100\n",
      "\u001b[1m236/236\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m54s\u001b[0m 231ms/step - accuracy: 0.5351 - f1_score: 0.4475 - loss: 1.2201 - precision: 0.6872 - recall: 0.3319 - val_accuracy: 0.5469 - val_f1_score: 0.4724 - val_loss: 1.1809 - val_precision: 0.6960 - val_recall: 0.3575\n",
      "Epoch 17/100\n",
      "\u001b[1m236/236\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m55s\u001b[0m 234ms/step - accuracy: 0.5420 - f1_score: 0.4659 - loss: 1.1911 - precision: 0.6952 - recall: 0.3504 - val_accuracy: 0.5433 - val_f1_score: 0.4459 - val_loss: 1.2154 - val_precision: 0.7076 - val_recall: 0.3255\n",
      "Epoch 18/100\n",
      "\u001b[1m236/236\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m55s\u001b[0m 234ms/step - accuracy: 0.5315 - f1_score: 0.4498 - loss: 1.2121 - precision: 0.6835 - recall: 0.3352 - val_accuracy: 0.5473 - val_f1_score: 0.4621 - val_loss: 1.1682 - val_precision: 0.7228 - val_recall: 0.3396\n",
      "Epoch 19/100\n",
      "\u001b[1m236/236\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m55s\u001b[0m 233ms/step - accuracy: 0.5482 - f1_score: 0.4813 - loss: 1.1673 - precision: 0.6965 - recall: 0.3677 - val_accuracy: 0.5641 - val_f1_score: 0.4827 - val_loss: 1.1233 - val_precision: 0.7374 - val_recall: 0.3587\n",
      "Epoch 20/100\n",
      "\u001b[1m236/236\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m55s\u001b[0m 231ms/step - accuracy: 0.5671 - f1_score: 0.4941 - loss: 1.1469 - precision: 0.6953 - recall: 0.3833 - val_accuracy: 0.5733 - val_f1_score: 0.5290 - val_loss: 1.1053 - val_precision: 0.6985 - val_recall: 0.4257\n",
      "Epoch 21/100\n",
      "\u001b[1m236/236\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m55s\u001b[0m 234ms/step - accuracy: 0.5652 - f1_score: 0.5008 - loss: 1.1263 - precision: 0.7037 - recall: 0.3888 - val_accuracy: 0.5850 - val_f1_score: 0.5355 - val_loss: 1.0734 - val_precision: 0.7152 - val_recall: 0.4280\n",
      "Epoch 22/100\n",
      "\u001b[1m236/236\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m56s\u001b[0m 237ms/step - accuracy: 0.5545 - f1_score: 0.5002 - loss: 1.1348 - precision: 0.7031 - recall: 0.3883 - val_accuracy: 0.6010 - val_f1_score: 0.5516 - val_loss: 1.0484 - val_precision: 0.7393 - val_recall: 0.4399\n",
      "Epoch 23/100\n",
      "\u001b[1m236/236\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m55s\u001b[0m 235ms/step - accuracy: 0.5682 - f1_score: 0.5126 - loss: 1.1160 - precision: 0.7060 - recall: 0.4026 - val_accuracy: 0.6041 - val_f1_score: 0.5611 - val_loss: 1.0255 - val_precision: 0.7391 - val_recall: 0.4522\n",
      "Epoch 24/100\n",
      "\u001b[1m236/236\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m55s\u001b[0m 232ms/step - accuracy: 0.5704 - f1_score: 0.5093 - loss: 1.1089 - precision: 0.7025 - recall: 0.3995 - val_accuracy: 0.6078 - val_f1_score: 0.5605 - val_loss: 1.0260 - val_precision: 0.7492 - val_recall: 0.4477\n",
      "Epoch 25/100\n",
      "\u001b[1m236/236\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m55s\u001b[0m 233ms/step - accuracy: 0.5785 - f1_score: 0.5198 - loss: 1.1047 - precision: 0.7099 - recall: 0.4101 - val_accuracy: 0.6103 - val_f1_score: 0.5589 - val_loss: 1.0261 - val_precision: 0.7509 - val_recall: 0.4450\n",
      "Epoch 26/100\n",
      "\u001b[1m236/236\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m55s\u001b[0m 234ms/step - accuracy: 0.5988 - f1_score: 0.5526 - loss: 1.0471 - precision: 0.7435 - recall: 0.4398 - val_accuracy: 0.6206 - val_f1_score: 0.5760 - val_loss: 1.0076 - val_precision: 0.7673 - val_recall: 0.4611\n",
      "Epoch 27/100\n",
      "\u001b[1m236/236\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m55s\u001b[0m 234ms/step - accuracy: 0.5943 - f1_score: 0.5452 - loss: 1.0543 - precision: 0.7277 - recall: 0.4360 - val_accuracy: 0.6061 - val_f1_score: 0.5621 - val_loss: 1.0130 - val_precision: 0.7517 - val_recall: 0.4489\n",
      "Epoch 28/100\n",
      "\u001b[1m236/236\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1371s\u001b[0m 6s/step - accuracy: 0.5957 - f1_score: 0.5479 - loss: 1.0567 - precision: 0.7257 - recall: 0.4401 - val_accuracy: 0.5988 - val_f1_score: 0.5339 - val_loss: 1.0462 - val_precision: 0.7683 - val_recall: 0.4091\n",
      "Epoch 29/100\n",
      "\u001b[1m236/236\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 145ms/step - accuracy: 0.5931 - f1_score: 0.5421 - loss: 1.0642 - precision: 0.7259 - recall: 0.4326 - val_accuracy: 0.6252 - val_f1_score: 0.5936 - val_loss: 0.9768 - val_precision: 0.7468 - val_recall: 0.4926\n",
      "Epoch 30/100\n",
      "\u001b[1m236/236\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 122ms/step - accuracy: 0.6187 - f1_score: 0.5729 - loss: 1.0096 - precision: 0.7414 - recall: 0.4668 - val_accuracy: 0.6415 - val_f1_score: 0.6113 - val_loss: 0.9394 - val_precision: 0.7712 - val_recall: 0.5062\n",
      "Epoch 31/100\n",
      "\u001b[1m236/236\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 119ms/step - accuracy: 0.6066 - f1_score: 0.5651 - loss: 1.0210 - precision: 0.7476 - recall: 0.4542 - val_accuracy: 0.6364 - val_f1_score: 0.6160 - val_loss: 0.9580 - val_precision: 0.7447 - val_recall: 0.5252\n",
      "Epoch 32/100\n",
      "\u001b[1m236/236\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 118ms/step - accuracy: 0.6164 - f1_score: 0.5814 - loss: 0.9945 - precision: 0.7400 - recall: 0.4789 - val_accuracy: 0.6528 - val_f1_score: 0.6061 - val_loss: 0.9298 - val_precision: 0.8059 - val_recall: 0.4857\n",
      "Epoch 33/100\n",
      "\u001b[1m236/236\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 122ms/step - accuracy: 0.6240 - f1_score: 0.5807 - loss: 1.0073 - precision: 0.7497 - recall: 0.4742 - val_accuracy: 0.6593 - val_f1_score: 0.6384 - val_loss: 0.8932 - val_precision: 0.7700 - val_recall: 0.5453\n",
      "Epoch 34/100\n",
      "\u001b[1m236/236\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 130ms/step - accuracy: 0.6407 - f1_score: 0.6021 - loss: 0.9482 - precision: 0.7630 - recall: 0.4974 - val_accuracy: 0.6624 - val_f1_score: 0.6211 - val_loss: 0.9143 - val_precision: 0.7982 - val_recall: 0.5084\n",
      "Epoch 35/100\n",
      "\u001b[1m236/236\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 130ms/step - accuracy: 0.6269 - f1_score: 0.5851 - loss: 0.9771 - precision: 0.7547 - recall: 0.4778 - val_accuracy: 0.6389 - val_f1_score: 0.6189 - val_loss: 0.9447 - val_precision: 0.7355 - val_recall: 0.5343\n",
      "Epoch 36/100\n",
      "\u001b[1m236/236\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 126ms/step - accuracy: 0.6336 - f1_score: 0.5895 - loss: 0.9606 - precision: 0.7612 - recall: 0.4811 - val_accuracy: 0.6726 - val_f1_score: 0.6402 - val_loss: 0.8760 - val_precision: 0.7948 - val_recall: 0.5360\n",
      "Epoch 37/100\n",
      "\u001b[1m236/236\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 128ms/step - accuracy: 0.6646 - f1_score: 0.6278 - loss: 0.9128 - precision: 0.7795 - recall: 0.5255 - val_accuracy: 0.6711 - val_f1_score: 0.6442 - val_loss: 0.8739 - val_precision: 0.7802 - val_recall: 0.5486\n",
      "Epoch 38/100\n",
      "\u001b[1m236/236\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 124ms/step - accuracy: 0.6390 - f1_score: 0.6104 - loss: 0.9384 - precision: 0.7645 - recall: 0.5081 - val_accuracy: 0.6625 - val_f1_score: 0.6415 - val_loss: 0.8834 - val_precision: 0.7781 - val_recall: 0.5457\n",
      "Epoch 39/100\n",
      "\u001b[1m236/236\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 140ms/step - accuracy: 0.6452 - f1_score: 0.6123 - loss: 0.9379 - precision: 0.7622 - recall: 0.5118 - val_accuracy: 0.6662 - val_f1_score: 0.6401 - val_loss: 0.8758 - val_precision: 0.7907 - val_recall: 0.5377\n",
      "Epoch 40/100\n",
      "\u001b[1m236/236\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 124ms/step - accuracy: 0.6496 - f1_score: 0.6104 - loss: 0.9245 - precision: 0.7628 - recall: 0.5088 - val_accuracy: 0.6934 - val_f1_score: 0.6578 - val_loss: 0.8428 - val_precision: 0.8143 - val_recall: 0.5518\n",
      "Epoch 41/100\n",
      "\u001b[1m236/236\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 124ms/step - accuracy: 0.6568 - f1_score: 0.6229 - loss: 0.9083 - precision: 0.7625 - recall: 0.5265 - val_accuracy: 0.6999 - val_f1_score: 0.6567 - val_loss: 0.8270 - val_precision: 0.8215 - val_recall: 0.5470\n",
      "Epoch 42/100\n",
      "\u001b[1m236/236\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 126ms/step - accuracy: 0.6721 - f1_score: 0.6554 - loss: 0.8587 - precision: 0.7841 - recall: 0.5630 - val_accuracy: 0.6891 - val_f1_score: 0.6482 - val_loss: 0.8319 - val_precision: 0.8101 - val_recall: 0.5402\n",
      "Epoch 43/100\n",
      "\u001b[1m236/236\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 124ms/step - accuracy: 0.6519 - f1_score: 0.6219 - loss: 0.9059 - precision: 0.7761 - recall: 0.5190 - val_accuracy: 0.7132 - val_f1_score: 0.6805 - val_loss: 0.7868 - val_precision: 0.8360 - val_recall: 0.5738\n",
      "Epoch 44/100\n",
      "\u001b[1m236/236\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 126ms/step - accuracy: 0.6630 - f1_score: 0.6364 - loss: 0.8923 - precision: 0.7783 - recall: 0.5383 - val_accuracy: 0.6949 - val_f1_score: 0.6726 - val_loss: 0.8159 - val_precision: 0.8032 - val_recall: 0.5786\n",
      "Epoch 45/100\n",
      "\u001b[1m236/236\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 126ms/step - accuracy: 0.6725 - f1_score: 0.6373 - loss: 0.8911 - precision: 0.7789 - recall: 0.5394 - val_accuracy: 0.7169 - val_f1_score: 0.6903 - val_loss: 0.7726 - val_precision: 0.8294 - val_recall: 0.5912\n",
      "Epoch 46/100\n",
      "\u001b[1m236/236\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 127ms/step - accuracy: 0.6809 - f1_score: 0.6503 - loss: 0.8516 - precision: 0.7826 - recall: 0.5562 - val_accuracy: 0.6921 - val_f1_score: 0.6514 - val_loss: 0.8358 - val_precision: 0.8089 - val_recall: 0.5453\n",
      "Epoch 47/100\n",
      "\u001b[1m236/236\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 126ms/step - accuracy: 0.6731 - f1_score: 0.6415 - loss: 0.8670 - precision: 0.7714 - recall: 0.5492 - val_accuracy: 0.7260 - val_f1_score: 0.6981 - val_loss: 0.7485 - val_precision: 0.8375 - val_recall: 0.5985\n",
      "Epoch 48/100\n",
      "\u001b[1m236/236\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 125ms/step - accuracy: 0.6698 - f1_score: 0.6413 - loss: 0.8589 - precision: 0.7871 - recall: 0.5415 - val_accuracy: 0.7023 - val_f1_score: 0.6782 - val_loss: 0.8125 - val_precision: 0.8202 - val_recall: 0.5782\n",
      "Epoch 49/100\n",
      "\u001b[1m236/236\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 127ms/step - accuracy: 0.6907 - f1_score: 0.6695 - loss: 0.8221 - precision: 0.7950 - recall: 0.5783 - val_accuracy: 0.7358 - val_f1_score: 0.7076 - val_loss: 0.7333 - val_precision: 0.8439 - val_recall: 0.6093\n",
      "Epoch 50/100\n",
      "\u001b[1m236/236\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 127ms/step - accuracy: 0.6928 - f1_score: 0.6699 - loss: 0.8219 - precision: 0.7909 - recall: 0.5811 - val_accuracy: 0.7347 - val_f1_score: 0.7077 - val_loss: 0.7340 - val_precision: 0.8396 - val_recall: 0.6117\n",
      "Epoch 51/100\n",
      "\u001b[1m236/236\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 126ms/step - accuracy: 0.6974 - f1_score: 0.6754 - loss: 0.8244 - precision: 0.7967 - recall: 0.5862 - val_accuracy: 0.7219 - val_f1_score: 0.7021 - val_loss: 0.7450 - val_precision: 0.8285 - val_recall: 0.6091\n",
      "Epoch 52/100\n",
      "\u001b[1m236/236\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 126ms/step - accuracy: 0.6870 - f1_score: 0.6598 - loss: 0.8381 - precision: 0.7831 - recall: 0.5702 - val_accuracy: 0.7274 - val_f1_score: 0.6972 - val_loss: 0.7548 - val_precision: 0.8345 - val_recall: 0.5986\n",
      "Epoch 53/100\n",
      "\u001b[1m236/236\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 131ms/step - accuracy: 0.6989 - f1_score: 0.6804 - loss: 0.8040 - precision: 0.8015 - recall: 0.5911 - val_accuracy: 0.7302 - val_f1_score: 0.7111 - val_loss: 0.7329 - val_precision: 0.8150 - val_recall: 0.6306\n",
      "Epoch 54/100\n",
      "\u001b[1m236/236\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 128ms/step - accuracy: 0.6981 - f1_score: 0.6857 - loss: 0.8010 - precision: 0.8011 - recall: 0.5995 - val_accuracy: 0.7180 - val_f1_score: 0.6930 - val_loss: 0.7662 - val_precision: 0.8132 - val_recall: 0.6038\n",
      "Epoch 55/100\n",
      "\u001b[1m236/236\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 128ms/step - accuracy: 0.6970 - f1_score: 0.6665 - loss: 0.8222 - precision: 0.7994 - recall: 0.5715 - val_accuracy: 0.7256 - val_f1_score: 0.7113 - val_loss: 0.7407 - val_precision: 0.8104 - val_recall: 0.6338\n",
      "Epoch 56/100\n",
      "\u001b[1m236/236\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 129ms/step - accuracy: 0.7063 - f1_score: 0.6863 - loss: 0.7841 - precision: 0.8041 - recall: 0.5987 - val_accuracy: 0.7479 - val_f1_score: 0.7294 - val_loss: 0.6945 - val_precision: 0.8434 - val_recall: 0.6426\n",
      "Epoch 57/100\n",
      "\u001b[1m236/236\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 138ms/step - accuracy: 0.7055 - f1_score: 0.6829 - loss: 0.7802 - precision: 0.7975 - recall: 0.5973 - val_accuracy: 0.7411 - val_f1_score: 0.7308 - val_loss: 0.7026 - val_precision: 0.8279 - val_recall: 0.6541\n",
      "Epoch 58/100\n",
      "\u001b[1m236/236\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 127ms/step - accuracy: 0.7033 - f1_score: 0.6809 - loss: 0.7927 - precision: 0.7919 - recall: 0.5972 - val_accuracy: 0.7481 - val_f1_score: 0.7261 - val_loss: 0.6966 - val_precision: 0.8412 - val_recall: 0.6387\n",
      "Epoch 59/100\n",
      "\u001b[1m236/236\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 125ms/step - accuracy: 0.7124 - f1_score: 0.6888 - loss: 0.7941 - precision: 0.8017 - recall: 0.6039 - val_accuracy: 0.7544 - val_f1_score: 0.7382 - val_loss: 0.6730 - val_precision: 0.8436 - val_recall: 0.6561\n",
      "Epoch 60/100\n",
      "\u001b[1m236/236\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 128ms/step - accuracy: 0.7125 - f1_score: 0.6965 - loss: 0.7766 - precision: 0.8060 - recall: 0.6132 - val_accuracy: 0.7349 - val_f1_score: 0.7135 - val_loss: 0.7193 - val_precision: 0.8393 - val_recall: 0.6206\n",
      "Epoch 61/100\n",
      "\u001b[1m236/236\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 127ms/step - accuracy: 0.7049 - f1_score: 0.6826 - loss: 0.7918 - precision: 0.8015 - recall: 0.5944 - val_accuracy: 0.7189 - val_f1_score: 0.7110 - val_loss: 0.7435 - val_precision: 0.8018 - val_recall: 0.6386\n",
      "Epoch 62/100\n",
      "\u001b[1m236/236\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 126ms/step - accuracy: 0.6928 - f1_score: 0.6740 - loss: 0.7914 - precision: 0.7876 - recall: 0.5891 - val_accuracy: 0.7501 - val_f1_score: 0.7278 - val_loss: 0.6800 - val_precision: 0.8426 - val_recall: 0.6405\n",
      "Epoch 63/100\n",
      "\u001b[1m236/236\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 127ms/step - accuracy: 0.7135 - f1_score: 0.6930 - loss: 0.7701 - precision: 0.8054 - recall: 0.6082 - val_accuracy: 0.7610 - val_f1_score: 0.7454 - val_loss: 0.6621 - val_precision: 0.8493 - val_recall: 0.6642\n",
      "Epoch 64/100\n",
      "\u001b[1m236/236\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 128ms/step - accuracy: 0.7273 - f1_score: 0.7078 - loss: 0.7462 - precision: 0.8125 - recall: 0.6271 - val_accuracy: 0.7475 - val_f1_score: 0.7181 - val_loss: 0.7003 - val_precision: 0.8475 - val_recall: 0.6229\n",
      "Epoch 65/100\n",
      "\u001b[1m236/236\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 128ms/step - accuracy: 0.7273 - f1_score: 0.7110 - loss: 0.7397 - precision: 0.8140 - recall: 0.6312 - val_accuracy: 0.7540 - val_f1_score: 0.7392 - val_loss: 0.6756 - val_precision: 0.8506 - val_recall: 0.6536\n",
      "Epoch 66/100\n",
      "\u001b[1m236/236\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 131ms/step - accuracy: 0.7327 - f1_score: 0.7106 - loss: 0.7323 - precision: 0.8179 - recall: 0.6282 - val_accuracy: 0.7404 - val_f1_score: 0.7229 - val_loss: 0.7023 - val_precision: 0.8339 - val_recall: 0.6379\n",
      "Epoch 67/100\n",
      "\u001b[1m236/236\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 128ms/step - accuracy: 0.7280 - f1_score: 0.7132 - loss: 0.7357 - precision: 0.8138 - recall: 0.6348 - val_accuracy: 0.7565 - val_f1_score: 0.7475 - val_loss: 0.6648 - val_precision: 0.8409 - val_recall: 0.6727\n",
      "Epoch 68/100\n",
      "\u001b[1m236/236\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 132ms/step - accuracy: 0.7313 - f1_score: 0.7129 - loss: 0.7293 - precision: 0.8179 - recall: 0.6319 - val_accuracy: 0.7472 - val_f1_score: 0.7346 - val_loss: 0.6885 - val_precision: 0.8291 - val_recall: 0.6595\n",
      "Epoch 69/100\n",
      "\u001b[1m236/236\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 131ms/step - accuracy: 0.7257 - f1_score: 0.7072 - loss: 0.7523 - precision: 0.8141 - recall: 0.6252 - val_accuracy: 0.7643 - val_f1_score: 0.7527 - val_loss: 0.6394 - val_precision: 0.8244 - val_recall: 0.6925\n",
      "Epoch 70/100\n",
      "\u001b[1m236/236\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 129ms/step - accuracy: 0.7329 - f1_score: 0.7183 - loss: 0.7203 - precision: 0.8091 - recall: 0.6461 - val_accuracy: 0.7596 - val_f1_score: 0.7459 - val_loss: 0.6624 - val_precision: 0.8419 - val_recall: 0.6695\n",
      "Epoch 71/100\n",
      "\u001b[1m236/236\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 129ms/step - accuracy: 0.7193 - f1_score: 0.7097 - loss: 0.7295 - precision: 0.8127 - recall: 0.6300 - val_accuracy: 0.7576 - val_f1_score: 0.7480 - val_loss: 0.6711 - val_precision: 0.8333 - val_recall: 0.6784\n",
      "Epoch 72/100\n",
      "\u001b[1m236/236\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 130ms/step - accuracy: 0.7415 - f1_score: 0.7185 - loss: 0.7158 - precision: 0.8161 - recall: 0.6417 - val_accuracy: 0.7727 - val_f1_score: 0.7558 - val_loss: 0.6409 - val_precision: 0.8521 - val_recall: 0.6791\n",
      "Epoch 73/100\n",
      "\u001b[1m236/236\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 131ms/step - accuracy: 0.7370 - f1_score: 0.7196 - loss: 0.7117 - precision: 0.8195 - recall: 0.6414 - val_accuracy: 0.7691 - val_f1_score: 0.7539 - val_loss: 0.6462 - val_precision: 0.8411 - val_recall: 0.6831\n",
      "Epoch 74/100\n",
      "\u001b[1m236/236\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 135ms/step - accuracy: 0.7355 - f1_score: 0.7172 - loss: 0.7217 - precision: 0.8168 - recall: 0.6394 - val_accuracy: 0.7762 - val_f1_score: 0.7670 - val_loss: 0.6155 - val_precision: 0.8402 - val_recall: 0.7055\n",
      "Epoch 75/100\n",
      "\u001b[1m236/236\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 131ms/step - accuracy: 0.7524 - f1_score: 0.7356 - loss: 0.6768 - precision: 0.8236 - recall: 0.6646 - val_accuracy: 0.7823 - val_f1_score: 0.7702 - val_loss: 0.6101 - val_precision: 0.8516 - val_recall: 0.7030\n",
      "Epoch 76/100\n",
      "\u001b[1m236/236\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 137ms/step - accuracy: 0.7342 - f1_score: 0.7217 - loss: 0.7106 - precision: 0.8157 - recall: 0.6471 - val_accuracy: 0.7698 - val_f1_score: 0.7548 - val_loss: 0.6282 - val_precision: 0.8553 - val_recall: 0.6755\n",
      "Epoch 77/100\n",
      "\u001b[1m236/236\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 132ms/step - accuracy: 0.7347 - f1_score: 0.7228 - loss: 0.7131 - precision: 0.8196 - recall: 0.6464 - val_accuracy: 0.7734 - val_f1_score: 0.7642 - val_loss: 0.6170 - val_precision: 0.8493 - val_recall: 0.6945\n",
      "Epoch 78/100\n",
      "\u001b[1m236/236\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 133ms/step - accuracy: 0.7410 - f1_score: 0.7241 - loss: 0.6909 - precision: 0.8129 - recall: 0.6528 - val_accuracy: 0.7831 - val_f1_score: 0.7737 - val_loss: 0.6120 - val_precision: 0.8453 - val_recall: 0.7132\n",
      "Epoch 79/100\n",
      "\u001b[1m236/236\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 131ms/step - accuracy: 0.7321 - f1_score: 0.7199 - loss: 0.7239 - precision: 0.8168 - recall: 0.6436 - val_accuracy: 0.7853 - val_f1_score: 0.7720 - val_loss: 0.6080 - val_precision: 0.8490 - val_recall: 0.7078\n",
      "Epoch 80/100\n",
      "\u001b[1m236/236\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 160ms/step - accuracy: 0.7558 - f1_score: 0.7358 - loss: 0.6875 - precision: 0.8234 - recall: 0.6651 - val_accuracy: 0.7877 - val_f1_score: 0.7693 - val_loss: 0.5886 - val_precision: 0.8719 - val_recall: 0.6884\n",
      "Epoch 81/100\n",
      "\u001b[1m236/236\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 93ms/step - accuracy: 0.7454 - f1_score: 0.7270 - loss: 0.6907 - precision: 0.8226 - recall: 0.6514 - val_accuracy: 0.7982 - val_f1_score: 0.7825 - val_loss: 0.5771 - val_precision: 0.8639 - val_recall: 0.7152\n",
      "Epoch 82/100\n",
      "\u001b[1m236/236\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 85ms/step - accuracy: 0.7539 - f1_score: 0.7442 - loss: 0.6646 - precision: 0.8293 - recall: 0.6750 - val_accuracy: 0.7841 - val_f1_score: 0.7766 - val_loss: 0.5904 - val_precision: 0.8529 - val_recall: 0.7128\n",
      "Epoch 83/100\n",
      "\u001b[1m236/236\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 89ms/step - accuracy: 0.7539 - f1_score: 0.7414 - loss: 0.6639 - precision: 0.8263 - recall: 0.6724 - val_accuracy: 0.7845 - val_f1_score: 0.7702 - val_loss: 0.5937 - val_precision: 0.8586 - val_recall: 0.6984\n",
      "Epoch 84/100\n",
      "\u001b[1m236/236\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 83ms/step - accuracy: 0.7469 - f1_score: 0.7347 - loss: 0.6883 - precision: 0.8261 - recall: 0.6616 - val_accuracy: 0.7979 - val_f1_score: 0.7810 - val_loss: 0.5765 - val_precision: 0.8700 - val_recall: 0.7084\n",
      "Epoch 85/100\n",
      "\u001b[1m236/236\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 79ms/step - accuracy: 0.7458 - f1_score: 0.7356 - loss: 0.6754 - precision: 0.8262 - recall: 0.6629 - val_accuracy: 0.7929 - val_f1_score: 0.7776 - val_loss: 0.5956 - val_precision: 0.8616 - val_recall: 0.7084\n",
      "Epoch 86/100\n",
      "\u001b[1m236/236\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 141ms/step - accuracy: 0.7557 - f1_score: 0.7405 - loss: 0.6738 - precision: 0.8273 - recall: 0.6702 - val_accuracy: 0.8012 - val_f1_score: 0.7916 - val_loss: 0.5678 - val_precision: 0.8728 - val_recall: 0.7242\n",
      "Epoch 87/100\n",
      "\u001b[1m236/236\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 135ms/step - accuracy: 0.7606 - f1_score: 0.7473 - loss: 0.6428 - precision: 0.8299 - recall: 0.6797 - val_accuracy: 0.8074 - val_f1_score: 0.7953 - val_loss: 0.5490 - val_precision: 0.8727 - val_recall: 0.7306\n",
      "Epoch 88/100\n",
      "\u001b[1m236/236\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 139ms/step - accuracy: 0.7622 - f1_score: 0.7515 - loss: 0.6441 - precision: 0.8285 - recall: 0.6878 - val_accuracy: 0.7904 - val_f1_score: 0.7754 - val_loss: 0.5829 - val_precision: 0.8652 - val_recall: 0.7025\n",
      "Epoch 89/100\n",
      "\u001b[1m236/236\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 140ms/step - accuracy: 0.7558 - f1_score: 0.7440 - loss: 0.6551 - precision: 0.8277 - recall: 0.6757 - val_accuracy: 0.7969 - val_f1_score: 0.7870 - val_loss: 0.5694 - val_precision: 0.8752 - val_recall: 0.7149\n",
      "Epoch 90/100\n",
      "\u001b[1m236/236\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 139ms/step - accuracy: 0.7706 - f1_score: 0.7505 - loss: 0.6463 - precision: 0.8284 - recall: 0.6860 - val_accuracy: 0.7909 - val_f1_score: 0.7879 - val_loss: 0.5656 - val_precision: 0.8507 - val_recall: 0.7338\n",
      "Epoch 91/100\n",
      "\u001b[1m236/236\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 139ms/step - accuracy: 0.7641 - f1_score: 0.7521 - loss: 0.6452 - precision: 0.8359 - recall: 0.6836 - val_accuracy: 0.8156 - val_f1_score: 0.8036 - val_loss: 0.5302 - val_precision: 0.8764 - val_recall: 0.7419\n",
      "Epoch 92/100\n",
      "\u001b[1m236/236\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 142ms/step - accuracy: 0.7570 - f1_score: 0.7565 - loss: 0.6340 - precision: 0.8372 - recall: 0.6899 - val_accuracy: 0.8152 - val_f1_score: 0.8080 - val_loss: 0.5247 - val_precision: 0.8823 - val_recall: 0.7452\n",
      "Epoch 93/100\n",
      "\u001b[1m236/236\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 140ms/step - accuracy: 0.7622 - f1_score: 0.7559 - loss: 0.6271 - precision: 0.8443 - recall: 0.6844 - val_accuracy: 0.8194 - val_f1_score: 0.8033 - val_loss: 0.5247 - val_precision: 0.8854 - val_recall: 0.7351\n",
      "Epoch 94/100\n",
      "\u001b[1m236/236\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 139ms/step - accuracy: 0.7738 - f1_score: 0.7628 - loss: 0.6263 - precision: 0.8444 - recall: 0.6956 - val_accuracy: 0.8036 - val_f1_score: 0.7971 - val_loss: 0.5447 - val_precision: 0.8650 - val_recall: 0.7391\n",
      "Epoch 95/100\n",
      "\u001b[1m236/236\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 142ms/step - accuracy: 0.7762 - f1_score: 0.7633 - loss: 0.6250 - precision: 0.8403 - recall: 0.6992 - val_accuracy: 0.7990 - val_f1_score: 0.7922 - val_loss: 0.5499 - val_precision: 0.8671 - val_recall: 0.7293\n",
      "Epoch 96/100\n",
      "\u001b[1m236/236\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 140ms/step - accuracy: 0.7629 - f1_score: 0.7567 - loss: 0.6408 - precision: 0.8345 - recall: 0.6921 - val_accuracy: 0.8213 - val_f1_score: 0.8104 - val_loss: 0.5191 - val_precision: 0.8876 - val_recall: 0.7456\n",
      "Epoch 97/100\n",
      "\u001b[1m236/236\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 140ms/step - accuracy: 0.7682 - f1_score: 0.7518 - loss: 0.6400 - precision: 0.8331 - recall: 0.6851 - val_accuracy: 0.8177 - val_f1_score: 0.8065 - val_loss: 0.5257 - val_precision: 0.8849 - val_recall: 0.7408\n",
      "Epoch 98/100\n",
      "\u001b[1m236/236\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 141ms/step - accuracy: 0.7718 - f1_score: 0.7644 - loss: 0.6170 - precision: 0.8490 - recall: 0.6951 - val_accuracy: 0.8136 - val_f1_score: 0.8073 - val_loss: 0.5213 - val_precision: 0.8780 - val_recall: 0.7471\n",
      "Epoch 99/100\n",
      "\u001b[1m236/236\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 145ms/step - accuracy: 0.7819 - f1_score: 0.7734 - loss: 0.5919 - precision: 0.8440 - recall: 0.7138 - val_accuracy: 0.7999 - val_f1_score: 0.7865 - val_loss: 0.5594 - val_precision: 0.8637 - val_recall: 0.7220\n",
      "Epoch 100/100\n",
      "\u001b[1m236/236\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 142ms/step - accuracy: 0.7770 - f1_score: 0.7669 - loss: 0.6133 - precision: 0.8385 - recall: 0.7065 - val_accuracy: 0.8119 - val_f1_score: 0.8073 - val_loss: 0.5275 - val_precision: 0.8667 - val_recall: 0.7556\n"
     ]
    }
   ],
   "source": [
    "# Train the model\n",
    "history = cnn_lstm.fit(\n",
    "    x=training_set,\n",
    "    validation_data=validation_set,\n",
    "    epochs=100\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c88f9034-e021-48c0-b112-e33d77dfdb90",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save Loss plot\n",
    "plt.figure()\n",
    "plt.plot(history.history['loss'], label='Train Loss')\n",
    "plt.plot(history.history['val_loss'], label='Validation Loss')\n",
    "plt.legend()\n",
    "plt.title(\"Loss\")\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.savefig('loss_plot.png')  # Save the plot as a PNG file\n",
    "plt.close()  # Close the figure to avoid memory issues\n",
    "\n",
    "# Save Accuracy plot\n",
    "plt.figure()\n",
    "plt.plot(history.history['accuracy'], label='Train Accuracy')\n",
    "plt.plot(history.history['val_accuracy'], label='Validation Accuracy')\n",
    "plt.legend()\n",
    "plt.title(\"Accuracy\")\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.savefig('accuracy_plot.png')  # Save the plot as a PNG file\n",
    "plt.close()  # Close the figure\n",
    "\n",
    "# Save Precision plot\n",
    "plt.figure()\n",
    "plt.plot(history.history['precision'], label='Train Precision')\n",
    "plt.plot(history.history['val_precision'], label='Validation Precision')\n",
    "plt.legend()\n",
    "plt.title(\"Precision\")\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Precision')\n",
    "plt.savefig('precision_plot.png')  # Save the plot as a PNG file\n",
    "plt.close()  # Close the figure\n",
    "\n",
    "# Save Recall plot\n",
    "plt.figure()\n",
    "plt.plot(history.history['recall'], label='Train Recall')\n",
    "plt.plot(history.history['val_recall'], label='Validation Recall')\n",
    "plt.legend()\n",
    "plt.title(\"Recall\")\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Recall')\n",
    "plt.savefig('recall_plot.png')  # Save the plot as a PNG file\n",
    "plt.close()  # Close the figure\n",
    "\n",
    "# Save F1 Score plot\n",
    "plt.figure()\n",
    "plt.plot(history.history['f1_score'], label='Train F1 Score')\n",
    "plt.plot(history.history['val_f1_score'], label='Validation F1 Score')\n",
    "plt.legend()\n",
    "plt.title(\"F1 Score\")\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('F1 Score')\n",
    "plt.savefig('f1_score_plot.png')  # Save the plot as a PNG file\n",
    "plt.close()  # Close the figure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "cc933f95-c51c-44fb-ab3e-e3e50e99de98",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                         </span>┃<span style=\"font-weight: bold\"> Output Shape                </span>┃<span style=\"font-weight: bold\">         Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
       "│ flatten (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)                    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">12288</span>)               │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ reshape (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Reshape</span>)                    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">768</span>)             │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ lstm (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)                  │         <span style=\"color: #00af00; text-decoration-color: #00af00\">213,248</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)                 │           <span style=\"color: #00af00; text-decoration-color: #00af00\">8,320</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">6</span>)                   │             <span style=\"color: #00af00; text-decoration-color: #00af00\">774</span> │\n",
       "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
       "│ flatten (\u001b[38;5;33mFlatten\u001b[0m)                    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m12288\u001b[0m)               │               \u001b[38;5;34m0\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ reshape (\u001b[38;5;33mReshape\u001b[0m)                    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m768\u001b[0m)             │               \u001b[38;5;34m0\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ lstm (\u001b[38;5;33mLSTM\u001b[0m)                          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)                  │         \u001b[38;5;34m213,248\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense (\u001b[38;5;33mDense\u001b[0m)                        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)                 │           \u001b[38;5;34m8,320\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)                      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m6\u001b[0m)                   │             \u001b[38;5;34m774\u001b[0m │\n",
       "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">667,028</span> (2.54 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m667,028\u001b[0m (2.54 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">222,342</span> (868.52 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m222,342\u001b[0m (868.52 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Optimizer params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">444,686</span> (1.70 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Optimizer params: \u001b[0m\u001b[38;5;34m444,686\u001b[0m (1.70 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "cnn_lstm.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14986664-b62d-4463-b20e-7877b0f84504",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

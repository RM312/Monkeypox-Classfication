{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "879bc68d-0e5b-4ee1-bda0-c5f9e926940d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.compat.v1 import ConfigProto\n",
    "from tensorflow.compat.v1 import InteractiveSession\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "69491595-f8d8-4a82-9b1a-9523a1b7c8fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# GPU Configuration\n",
    "config = ConfigProto()\n",
    "config.gpu_options.per_process_gpu_memory_fraction = 0.5\n",
    "config.gpu_options.allow_growth = True\n",
    "session = InteractiveSession(config=config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e37462f3-721a-4045-8677-e30b9cd02590",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data Augmentation for Training\n",
    "train_datagen = ImageDataGenerator(rescale=1./255,\n",
    "                                   shear_range=0.2,\n",
    "                                   zoom_range=0.2,\n",
    "                                   horizontal_flip=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "205d1ef8-ad8b-44f0-a305-43dde77a048a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 7336 images belonging to 6 classes.\n"
     ]
    }
   ],
   "source": [
    "training_set = train_datagen.flow_from_directory(\n",
    "    \"Monkeypox/archive (60)/Augmented Images/Augmented Images/FOLDS_AUG/fold4_AUG/Train/\",\n",
    "    target_size=(64, 64),\n",
    "    batch_size=32,\n",
    "    class_mode='categorical',  # Use 'categorical' for one-hot encoded labels\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b3ab8cda-080f-465d-b355-e2a22883bf3e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 7336 images belonging to 6 classes.\n"
     ]
    }
   ],
   "source": [
    "test_datagen = ImageDataGenerator(rescale=1./255)\n",
    "validation_set = test_datagen.flow_from_directory(\n",
    "    \"C:/Users/KIIT/Music/Monkeypox/archive (60)/Augmented Images/Augmented Images/FOLDS_AUG/fold4_AUG/Train/\",\n",
    "    target_size=(64, 64),\n",
    "    batch_size=32,\n",
    "    class_mode='categorical',  # Use 'categorical' for one-hot encoded labels\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "02dceaa8-a096-483b-85cd-12d5c554d5b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Custom F1 Score Metric\n",
    "class F1Score(tf.keras.metrics.Metric):\n",
    "    def __init__(self, name='f1_score', **kwargs):\n",
    "        super(F1Score, self).__init__(name=name, **kwargs)\n",
    "        self.precision = tf.keras.metrics.Precision()\n",
    "        self.recall = tf.keras.metrics.Recall()\n",
    "\n",
    "    def update_state(self, y_true, y_pred, sample_weight=None):\n",
    "        # Update the precision and recall for each batch\n",
    "        self.precision.update_state(y_true, y_pred, sample_weight)\n",
    "        self.recall.update_state(y_true, y_pred, sample_weight)\n",
    "\n",
    "    def result(self):\n",
    "        # Calculate F1 score as the harmonic mean of precision and recall\n",
    "        precision = self.precision.result()\n",
    "        recall = self.recall.result()\n",
    "        return 2 * (precision * recall) / (precision + recall + tf.keras.backend.epsilon())\n",
    "\n",
    "    def reset_states(self):\n",
    "        self.precision.reset_states()\n",
    "        self.recall.reset_states()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3c32a35b-1d3d-4827-9a28-80960b842daf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build the CNN-LSTM Model\n",
    "cnn_lstm = tf.keras.models.Sequential()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f4264273-5d43-4dea-8ef0-015036c79653",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\KIIT\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\layers\\convolutional\\base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "# CNN Layers for Feature Extraction\n",
    "cnn_lstm.add(tf.keras.layers.Conv2D(filters=32, kernel_size=3, activation='relu', strides=2, padding=\"same\", input_shape=[64, 64, 3]))\n",
    "cnn_lstm.add(tf.keras.layers.MaxPool2D(pool_size=2, strides=2))\n",
    "cnn_lstm.add(tf.keras.layers.Conv2D(filters=64, kernel_size=3, activation='relu', padding='same'))\n",
    "cnn_lstm.add(tf.keras.layers.MaxPool2D(pool_size=2, strides=2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9a87370d-bd07-4cf3-bfd8-1d709a89424c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Flatten and Reshape for LSTM\n",
    "cnn_lstm.add(tf.keras.layers.Flatten())\n",
    "cnn_lstm.add(tf.keras.layers.Reshape((16, -1)))  # Reshape to (time_steps, features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "395b7fcb-0708-4e3f-be3d-4330722135f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# LSTM Layer\n",
    "cnn_lstm.add(tf.keras.layers.LSTM(units=64, activation='tanh', return_sequences=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "49c83227-b82c-4ed1-91e7-cf67ed17e845",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fully Connected Layers\n",
    "cnn_lstm.add(tf.keras.layers.Dense(units=128, activation='relu'))\n",
    "cnn_lstm.add(tf.keras.layers.Dense(6, activation='softmax'))  # 6 classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "626203ef-bf03-48fe-b422-b8eee9f908e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile the model with Precision, Recall, and F1 Score\n",
    "cnn_lstm.compile(\n",
    "    optimizer='adam',\n",
    "    loss='categorical_crossentropy',  # Use categorical_crossentropy for one-hot encoded labels\n",
    "    metrics=[\n",
    "        'accuracy',\n",
    "        tf.keras.metrics.Precision(name='precision'),\n",
    "        tf.keras.metrics.Recall(name='recall'),\n",
    "        F1Score(name='f1_score')  # Add custom F1 score metric\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6df6af2c-7934-4972-bb6c-9f5ad9c33fb8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\KIIT\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\trainers\\data_adapters\\py_dataset_adapter.py:121: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
      "  self._warn_if_super_not_called()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "\u001b[1m230/230\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 154ms/step - accuracy: 0.3719 - f1_score: 0.0099 - loss: 1.6275 - precision: 0.1908 - recall: 0.0051"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\KIIT\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\trainers\\data_adapters\\py_dataset_adapter.py:121: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
      "  self._warn_if_super_not_called()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m230/230\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m51s\u001b[0m 206ms/step - accuracy: 0.3719 - f1_score: 0.0101 - loss: 1.6274 - precision: 0.1923 - recall: 0.0052 - val_accuracy: 0.3987 - val_f1_score: 0.0697 - val_loss: 1.5439 - val_precision: 0.6601 - val_recall: 0.0368\n",
      "Epoch 2/100\n",
      "\u001b[1m230/230\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 149ms/step - accuracy: 0.4257 - f1_score: 0.1724 - loss: 1.5078 - precision: 0.5353 - recall: 0.1031 - val_accuracy: 0.4160 - val_f1_score: 0.3145 - val_loss: 1.5056 - val_precision: 0.5538 - val_recall: 0.2196\n",
      "Epoch 3/100\n",
      "\u001b[1m230/230\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 145ms/step - accuracy: 0.4620 - f1_score: 0.3152 - loss: 1.4126 - precision: 0.5930 - recall: 0.2149 - val_accuracy: 0.4985 - val_f1_score: 0.3489 - val_loss: 1.3154 - val_precision: 0.6778 - val_recall: 0.2349\n",
      "Epoch 4/100\n",
      "\u001b[1m230/230\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 132ms/step - accuracy: 0.5017 - f1_score: 0.3750 - loss: 1.3050 - precision: 0.6412 - recall: 0.2652 - val_accuracy: 0.5391 - val_f1_score: 0.4636 - val_loss: 1.1839 - val_precision: 0.6953 - val_recall: 0.3477\n",
      "Epoch 5/100\n",
      "\u001b[1m230/230\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 131ms/step - accuracy: 0.5257 - f1_score: 0.4330 - loss: 1.2262 - precision: 0.6633 - recall: 0.3221 - val_accuracy: 0.5836 - val_f1_score: 0.5309 - val_loss: 1.0880 - val_precision: 0.7030 - val_recall: 0.4265\n",
      "Epoch 6/100\n",
      "\u001b[1m230/230\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 136ms/step - accuracy: 0.5637 - f1_score: 0.5036 - loss: 1.1274 - precision: 0.7000 - recall: 0.3933 - val_accuracy: 0.6076 - val_f1_score: 0.5559 - val_loss: 1.0220 - val_precision: 0.7120 - val_recall: 0.4560\n",
      "Epoch 7/100\n",
      "\u001b[1m230/230\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 133ms/step - accuracy: 0.6079 - f1_score: 0.5549 - loss: 1.0243 - precision: 0.7068 - recall: 0.4569 - val_accuracy: 0.6557 - val_f1_score: 0.6412 - val_loss: 0.9072 - val_precision: 0.7340 - val_recall: 0.5692\n",
      "Epoch 8/100\n",
      "\u001b[1m230/230\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 132ms/step - accuracy: 0.6410 - f1_score: 0.6069 - loss: 0.9329 - precision: 0.7495 - recall: 0.5100 - val_accuracy: 0.6540 - val_f1_score: 0.6208 - val_loss: 0.9136 - val_precision: 0.7644 - val_recall: 0.5226\n",
      "Epoch 9/100\n",
      "\u001b[1m230/230\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 132ms/step - accuracy: 0.6670 - f1_score: 0.6421 - loss: 0.8672 - precision: 0.7567 - recall: 0.5578 - val_accuracy: 0.7054 - val_f1_score: 0.6853 - val_loss: 0.7699 - val_precision: 0.8007 - val_recall: 0.5990\n",
      "Epoch 10/100\n",
      "\u001b[1m230/230\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 131ms/step - accuracy: 0.6893 - f1_score: 0.6691 - loss: 0.7945 - precision: 0.7859 - recall: 0.5826 - val_accuracy: 0.7375 - val_f1_score: 0.7219 - val_loss: 0.6949 - val_precision: 0.8347 - val_recall: 0.6359\n",
      "Epoch 11/100\n",
      "\u001b[1m230/230\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 131ms/step - accuracy: 0.7124 - f1_score: 0.6906 - loss: 0.7507 - precision: 0.7977 - recall: 0.6089 - val_accuracy: 0.7450 - val_f1_score: 0.7202 - val_loss: 0.6670 - val_precision: 0.8366 - val_recall: 0.6322\n",
      "Epoch 12/100\n",
      "\u001b[1m230/230\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 136ms/step - accuracy: 0.7292 - f1_score: 0.7152 - loss: 0.6985 - precision: 0.8119 - recall: 0.6392 - val_accuracy: 0.7732 - val_f1_score: 0.7652 - val_loss: 0.6025 - val_precision: 0.8437 - val_recall: 0.7000\n",
      "Epoch 13/100\n",
      "\u001b[1m230/230\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 132ms/step - accuracy: 0.7680 - f1_score: 0.7614 - loss: 0.6270 - precision: 0.8341 - recall: 0.7004 - val_accuracy: 0.7874 - val_f1_score: 0.7777 - val_loss: 0.5821 - val_precision: 0.8536 - val_recall: 0.7143\n",
      "Epoch 14/100\n",
      "\u001b[1m230/230\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 133ms/step - accuracy: 0.7772 - f1_score: 0.7672 - loss: 0.6097 - precision: 0.8355 - recall: 0.7093 - val_accuracy: 0.8285 - val_f1_score: 0.8240 - val_loss: 0.4727 - val_precision: 0.8825 - val_recall: 0.7728\n",
      "Epoch 15/100\n",
      "\u001b[1m230/230\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 137ms/step - accuracy: 0.7924 - f1_score: 0.7894 - loss: 0.5619 - precision: 0.8450 - recall: 0.7406 - val_accuracy: 0.8321 - val_f1_score: 0.8237 - val_loss: 0.4789 - val_precision: 0.8829 - val_recall: 0.7719\n",
      "Epoch 16/100\n",
      "\u001b[1m230/230\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 134ms/step - accuracy: 0.8122 - f1_score: 0.8027 - loss: 0.5280 - precision: 0.8556 - recall: 0.7559 - val_accuracy: 0.8323 - val_f1_score: 0.8303 - val_loss: 0.4743 - val_precision: 0.8723 - val_recall: 0.7921\n",
      "Epoch 17/100\n",
      "\u001b[1m230/230\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 133ms/step - accuracy: 0.8179 - f1_score: 0.8180 - loss: 0.4868 - precision: 0.8634 - recall: 0.7773 - val_accuracy: 0.8321 - val_f1_score: 0.8339 - val_loss: 0.4405 - val_precision: 0.8720 - val_recall: 0.7989\n",
      "Epoch 18/100\n",
      "\u001b[1m230/230\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 133ms/step - accuracy: 0.8257 - f1_score: 0.8184 - loss: 0.4893 - precision: 0.8641 - recall: 0.7773 - val_accuracy: 0.8417 - val_f1_score: 0.8446 - val_loss: 0.4290 - val_precision: 0.8787 - val_recall: 0.8130\n",
      "Epoch 19/100\n",
      "\u001b[1m230/230\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 134ms/step - accuracy: 0.8342 - f1_score: 0.8306 - loss: 0.4466 - precision: 0.8717 - recall: 0.7932 - val_accuracy: 0.8591 - val_f1_score: 0.8579 - val_loss: 0.3860 - val_precision: 0.8968 - val_recall: 0.8222\n",
      "Epoch 20/100\n",
      "\u001b[1m230/230\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 134ms/step - accuracy: 0.8533 - f1_score: 0.8523 - loss: 0.4077 - precision: 0.8898 - recall: 0.8179 - val_accuracy: 0.8582 - val_f1_score: 0.8601 - val_loss: 0.3823 - val_precision: 0.8889 - val_recall: 0.8332\n",
      "Epoch 21/100\n",
      "\u001b[1m230/230\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 134ms/step - accuracy: 0.8311 - f1_score: 0.8334 - loss: 0.4570 - precision: 0.8734 - recall: 0.7969 - val_accuracy: 0.8758 - val_f1_score: 0.8749 - val_loss: 0.3450 - val_precision: 0.9150 - val_recall: 0.8382\n",
      "Epoch 22/100\n",
      "\u001b[1m230/230\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 133ms/step - accuracy: 0.8605 - f1_score: 0.8595 - loss: 0.3786 - precision: 0.8985 - recall: 0.8238 - val_accuracy: 0.8873 - val_f1_score: 0.8904 - val_loss: 0.3005 - val_precision: 0.9161 - val_recall: 0.8661\n",
      "Epoch 23/100\n",
      "\u001b[1m230/230\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 136ms/step - accuracy: 0.8761 - f1_score: 0.8745 - loss: 0.3496 - precision: 0.9054 - recall: 0.8456 - val_accuracy: 0.8949 - val_f1_score: 0.8941 - val_loss: 0.2936 - val_precision: 0.9241 - val_recall: 0.8660\n",
      "Epoch 24/100\n",
      "\u001b[1m230/230\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 135ms/step - accuracy: 0.8819 - f1_score: 0.8772 - loss: 0.3419 - precision: 0.9042 - recall: 0.8518 - val_accuracy: 0.9054 - val_f1_score: 0.9048 - val_loss: 0.2772 - val_precision: 0.9332 - val_recall: 0.8781\n",
      "Epoch 25/100\n",
      "\u001b[1m230/230\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 134ms/step - accuracy: 0.8773 - f1_score: 0.8781 - loss: 0.3483 - precision: 0.9074 - recall: 0.8506 - val_accuracy: 0.9111 - val_f1_score: 0.9131 - val_loss: 0.2468 - val_precision: 0.9305 - val_recall: 0.8963\n",
      "Epoch 26/100\n",
      "\u001b[1m230/230\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 134ms/step - accuracy: 0.8765 - f1_score: 0.8800 - loss: 0.3167 - precision: 0.9066 - recall: 0.8548 - val_accuracy: 0.9109 - val_f1_score: 0.9095 - val_loss: 0.2546 - val_precision: 0.9304 - val_recall: 0.8896\n",
      "Epoch 27/100\n",
      "\u001b[1m230/230\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 135ms/step - accuracy: 0.8857 - f1_score: 0.8876 - loss: 0.3033 - precision: 0.9118 - recall: 0.8648 - val_accuracy: 0.8957 - val_f1_score: 0.8974 - val_loss: 0.2825 - val_precision: 0.9196 - val_recall: 0.8762\n",
      "Epoch 28/100\n",
      "\u001b[1m230/230\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 135ms/step - accuracy: 0.8911 - f1_score: 0.8913 - loss: 0.3161 - precision: 0.9155 - recall: 0.8684 - val_accuracy: 0.9110 - val_f1_score: 0.9113 - val_loss: 0.2416 - val_precision: 0.9300 - val_recall: 0.8933\n",
      "Epoch 29/100\n",
      "\u001b[1m230/230\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 135ms/step - accuracy: 0.9013 - f1_score: 0.9005 - loss: 0.2764 - precision: 0.9209 - recall: 0.8811 - val_accuracy: 0.9109 - val_f1_score: 0.9104 - val_loss: 0.2482 - val_precision: 0.9293 - val_recall: 0.8923\n",
      "Epoch 30/100\n",
      "\u001b[1m230/230\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 139ms/step - accuracy: 0.8926 - f1_score: 0.8942 - loss: 0.2961 - precision: 0.9197 - recall: 0.8702 - val_accuracy: 0.9228 - val_f1_score: 0.9235 - val_loss: 0.2197 - val_precision: 0.9425 - val_recall: 0.9053\n",
      "Epoch 31/100\n",
      "\u001b[1m230/230\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 140ms/step - accuracy: 0.9036 - f1_score: 0.9043 - loss: 0.2603 - precision: 0.9223 - recall: 0.8870 - val_accuracy: 0.9079 - val_f1_score: 0.9092 - val_loss: 0.2567 - val_precision: 0.9278 - val_recall: 0.8914\n",
      "Epoch 32/100\n",
      "\u001b[1m230/230\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 137ms/step - accuracy: 0.9081 - f1_score: 0.9085 - loss: 0.2613 - precision: 0.9262 - recall: 0.8915 - val_accuracy: 0.9396 - val_f1_score: 0.9398 - val_loss: 0.1798 - val_precision: 0.9577 - val_recall: 0.9226\n",
      "Epoch 33/100\n",
      "\u001b[1m230/230\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 136ms/step - accuracy: 0.9203 - f1_score: 0.9231 - loss: 0.2223 - precision: 0.9421 - recall: 0.9050 - val_accuracy: 0.9234 - val_f1_score: 0.9254 - val_loss: 0.2109 - val_precision: 0.9413 - val_recall: 0.9100\n",
      "Epoch 34/100\n",
      "\u001b[1m230/230\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 135ms/step - accuracy: 0.9140 - f1_score: 0.9127 - loss: 0.2380 - precision: 0.9289 - recall: 0.8971 - val_accuracy: 0.9363 - val_f1_score: 0.9345 - val_loss: 0.1871 - val_precision: 0.9487 - val_recall: 0.9207\n",
      "Epoch 35/100\n",
      "\u001b[1m230/230\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 138ms/step - accuracy: 0.9048 - f1_score: 0.9057 - loss: 0.2563 - precision: 0.9241 - recall: 0.8880 - val_accuracy: 0.9462 - val_f1_score: 0.9451 - val_loss: 0.1559 - val_precision: 0.9570 - val_recall: 0.9336\n",
      "Epoch 36/100\n",
      "\u001b[1m230/230\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 137ms/step - accuracy: 0.9151 - f1_score: 0.9148 - loss: 0.2311 - precision: 0.9307 - recall: 0.8994 - val_accuracy: 0.9335 - val_f1_score: 0.9336 - val_loss: 0.1882 - val_precision: 0.9450 - val_recall: 0.9226\n",
      "Epoch 37/100\n",
      "\u001b[1m230/230\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 137ms/step - accuracy: 0.9185 - f1_score: 0.9196 - loss: 0.2276 - precision: 0.9339 - recall: 0.9057 - val_accuracy: 0.9511 - val_f1_score: 0.9519 - val_loss: 0.1444 - val_precision: 0.9608 - val_recall: 0.9432\n",
      "Epoch 38/100\n",
      "\u001b[1m230/230\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 137ms/step - accuracy: 0.9317 - f1_score: 0.9332 - loss: 0.1921 - precision: 0.9459 - recall: 0.9209 - val_accuracy: 0.9288 - val_f1_score: 0.9315 - val_loss: 0.1944 - val_precision: 0.9460 - val_recall: 0.9174\n",
      "Epoch 39/100\n",
      "\u001b[1m230/230\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 139ms/step - accuracy: 0.9331 - f1_score: 0.9353 - loss: 0.1942 - precision: 0.9483 - recall: 0.9227 - val_accuracy: 0.9572 - val_f1_score: 0.9579 - val_loss: 0.1359 - val_precision: 0.9669 - val_recall: 0.9490\n",
      "Epoch 40/100\n",
      "\u001b[1m230/230\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 138ms/step - accuracy: 0.9282 - f1_score: 0.9308 - loss: 0.1987 - precision: 0.9430 - recall: 0.9189 - val_accuracy: 0.9502 - val_f1_score: 0.9502 - val_loss: 0.1418 - val_precision: 0.9625 - val_recall: 0.9382\n",
      "Epoch 41/100\n",
      "\u001b[1m230/230\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m60s\u001b[0m 261ms/step - accuracy: 0.9261 - f1_score: 0.9267 - loss: 0.1973 - precision: 0.9388 - recall: 0.9150 - val_accuracy: 0.9603 - val_f1_score: 0.9611 - val_loss: 0.1181 - val_precision: 0.9709 - val_recall: 0.9515\n",
      "Epoch 42/100\n",
      "\u001b[1m230/230\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m59s\u001b[0m 255ms/step - accuracy: 0.9346 - f1_score: 0.9344 - loss: 0.1903 - precision: 0.9449 - recall: 0.9242 - val_accuracy: 0.9445 - val_f1_score: 0.9460 - val_loss: 0.1558 - val_precision: 0.9554 - val_recall: 0.9368\n",
      "Epoch 43/100\n",
      "\u001b[1m230/230\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m59s\u001b[0m 256ms/step - accuracy: 0.9239 - f1_score: 0.9233 - loss: 0.2237 - precision: 0.9369 - recall: 0.9101 - val_accuracy: 0.9601 - val_f1_score: 0.9610 - val_loss: 0.1120 - val_precision: 0.9712 - val_recall: 0.9511\n",
      "Epoch 44/100\n",
      "\u001b[1m230/230\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m60s\u001b[0m 259ms/step - accuracy: 0.9394 - f1_score: 0.9393 - loss: 0.1723 - precision: 0.9493 - recall: 0.9295 - val_accuracy: 0.9477 - val_f1_score: 0.9478 - val_loss: 0.1526 - val_precision: 0.9597 - val_recall: 0.9361\n",
      "Epoch 45/100\n",
      "\u001b[1m230/230\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m59s\u001b[0m 257ms/step - accuracy: 0.9418 - f1_score: 0.9424 - loss: 0.1616 - precision: 0.9524 - recall: 0.9325 - val_accuracy: 0.9552 - val_f1_score: 0.9557 - val_loss: 0.1287 - val_precision: 0.9642 - val_recall: 0.9474\n",
      "Epoch 46/100\n",
      "\u001b[1m230/230\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m60s\u001b[0m 259ms/step - accuracy: 0.9400 - f1_score: 0.9396 - loss: 0.1705 - precision: 0.9498 - recall: 0.9297 - val_accuracy: 0.9715 - val_f1_score: 0.9717 - val_loss: 0.0886 - val_precision: 0.9780 - val_recall: 0.9655\n",
      "Epoch 47/100\n",
      "\u001b[1m230/230\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m59s\u001b[0m 258ms/step - accuracy: 0.9467 - f1_score: 0.9476 - loss: 0.1503 - precision: 0.9558 - recall: 0.9397 - val_accuracy: 0.9423 - val_f1_score: 0.9425 - val_loss: 0.1557 - val_precision: 0.9520 - val_recall: 0.9332\n",
      "Epoch 48/100\n",
      "\u001b[1m230/230\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m60s\u001b[0m 262ms/step - accuracy: 0.9385 - f1_score: 0.9375 - loss: 0.1747 - precision: 0.9467 - recall: 0.9284 - val_accuracy: 0.9584 - val_f1_score: 0.9587 - val_loss: 0.1186 - val_precision: 0.9666 - val_recall: 0.9509\n",
      "Epoch 49/100\n",
      "\u001b[1m230/230\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m60s\u001b[0m 259ms/step - accuracy: 0.9381 - f1_score: 0.9393 - loss: 0.1632 - precision: 0.9495 - recall: 0.9292 - val_accuracy: 0.9470 - val_f1_score: 0.9474 - val_loss: 0.1493 - val_precision: 0.9544 - val_recall: 0.9406\n",
      "Epoch 50/100\n",
      "\u001b[1m230/230\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m60s\u001b[0m 261ms/step - accuracy: 0.9469 - f1_score: 0.9477 - loss: 0.1490 - precision: 0.9548 - recall: 0.9407 - val_accuracy: 0.9561 - val_f1_score: 0.9579 - val_loss: 0.1187 - val_precision: 0.9673 - val_recall: 0.9486\n",
      "Epoch 51/100\n",
      "\u001b[1m230/230\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m60s\u001b[0m 262ms/step - accuracy: 0.9450 - f1_score: 0.9449 - loss: 0.1592 - precision: 0.9552 - recall: 0.9348 - val_accuracy: 0.9535 - val_f1_score: 0.9535 - val_loss: 0.1363 - val_precision: 0.9615 - val_recall: 0.9457\n",
      "Epoch 52/100\n",
      "\u001b[1m230/230\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m59s\u001b[0m 257ms/step - accuracy: 0.9489 - f1_score: 0.9507 - loss: 0.1437 - precision: 0.9592 - recall: 0.9423 - val_accuracy: 0.9515 - val_f1_score: 0.9511 - val_loss: 0.1345 - val_precision: 0.9578 - val_recall: 0.9445\n",
      "Epoch 53/100\n",
      "\u001b[1m230/230\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m59s\u001b[0m 257ms/step - accuracy: 0.9496 - f1_score: 0.9523 - loss: 0.1358 - precision: 0.9593 - recall: 0.9454 - val_accuracy: 0.9697 - val_f1_score: 0.9698 - val_loss: 0.0917 - val_precision: 0.9769 - val_recall: 0.9628\n",
      "Epoch 54/100\n",
      "\u001b[1m230/230\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m59s\u001b[0m 257ms/step - accuracy: 0.9542 - f1_score: 0.9539 - loss: 0.1251 - precision: 0.9612 - recall: 0.9466 - val_accuracy: 0.9573 - val_f1_score: 0.9586 - val_loss: 0.1179 - val_precision: 0.9660 - val_recall: 0.9513\n",
      "Epoch 55/100\n",
      "\u001b[1m230/230\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m59s\u001b[0m 258ms/step - accuracy: 0.9433 - f1_score: 0.9443 - loss: 0.1582 - precision: 0.9516 - recall: 0.9371 - val_accuracy: 0.9609 - val_f1_score: 0.9619 - val_loss: 0.1139 - val_precision: 0.9668 - val_recall: 0.9571\n",
      "Epoch 56/100\n",
      "\u001b[1m230/230\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m59s\u001b[0m 258ms/step - accuracy: 0.9468 - f1_score: 0.9471 - loss: 0.1458 - precision: 0.9554 - recall: 0.9390 - val_accuracy: 0.9562 - val_f1_score: 0.9563 - val_loss: 0.1221 - val_precision: 0.9644 - val_recall: 0.9483\n",
      "Epoch 57/100\n",
      "\u001b[1m230/230\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m60s\u001b[0m 260ms/step - accuracy: 0.9527 - f1_score: 0.9532 - loss: 0.1261 - precision: 0.9603 - recall: 0.9463 - val_accuracy: 0.9557 - val_f1_score: 0.9551 - val_loss: 0.1248 - val_precision: 0.9613 - val_recall: 0.9489\n",
      "Epoch 58/100\n",
      "\u001b[1m230/230\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m60s\u001b[0m 261ms/step - accuracy: 0.9564 - f1_score: 0.9576 - loss: 0.1271 - precision: 0.9633 - recall: 0.9520 - val_accuracy: 0.9706 - val_f1_score: 0.9709 - val_loss: 0.0808 - val_precision: 0.9743 - val_recall: 0.9676\n",
      "Epoch 59/100\n",
      "\u001b[1m230/230\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m59s\u001b[0m 258ms/step - accuracy: 0.9514 - f1_score: 0.9518 - loss: 0.1348 - precision: 0.9570 - recall: 0.9467 - val_accuracy: 0.9757 - val_f1_score: 0.9755 - val_loss: 0.0747 - val_precision: 0.9810 - val_recall: 0.9701\n",
      "Epoch 60/100\n",
      "\u001b[1m230/230\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m59s\u001b[0m 257ms/step - accuracy: 0.9569 - f1_score: 0.9557 - loss: 0.1309 - precision: 0.9622 - recall: 0.9494 - val_accuracy: 0.9789 - val_f1_score: 0.9780 - val_loss: 0.0635 - val_precision: 0.9837 - val_recall: 0.9723\n",
      "Epoch 61/100\n",
      "\u001b[1m230/230\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m60s\u001b[0m 263ms/step - accuracy: 0.9703 - f1_score: 0.9697 - loss: 0.0872 - precision: 0.9771 - recall: 0.9623 - val_accuracy: 0.9553 - val_f1_score: 0.9554 - val_loss: 0.1286 - val_precision: 0.9624 - val_recall: 0.9485\n",
      "Epoch 62/100\n",
      "\u001b[1m230/230\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m60s\u001b[0m 262ms/step - accuracy: 0.9585 - f1_score: 0.9573 - loss: 0.1189 - precision: 0.9633 - recall: 0.9513 - val_accuracy: 0.9643 - val_f1_score: 0.9645 - val_loss: 0.1066 - val_precision: 0.9706 - val_recall: 0.9586\n",
      "Epoch 63/100\n",
      "\u001b[1m230/230\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m60s\u001b[0m 261ms/step - accuracy: 0.9586 - f1_score: 0.9600 - loss: 0.1168 - precision: 0.9654 - recall: 0.9546 - val_accuracy: 0.9678 - val_f1_score: 0.9682 - val_loss: 0.0935 - val_precision: 0.9745 - val_recall: 0.9621\n",
      "Epoch 64/100\n",
      "\u001b[1m230/230\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m59s\u001b[0m 256ms/step - accuracy: 0.9541 - f1_score: 0.9541 - loss: 0.1310 - precision: 0.9596 - recall: 0.9486 - val_accuracy: 0.9782 - val_f1_score: 0.9784 - val_loss: 0.0661 - val_precision: 0.9832 - val_recall: 0.9736\n",
      "Epoch 65/100\n",
      "\u001b[1m230/230\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m60s\u001b[0m 262ms/step - accuracy: 0.9692 - f1_score: 0.9700 - loss: 0.0920 - precision: 0.9755 - recall: 0.9645 - val_accuracy: 0.9826 - val_f1_score: 0.9831 - val_loss: 0.0554 - val_precision: 0.9859 - val_recall: 0.9804\n",
      "Epoch 66/100\n",
      "\u001b[1m230/230\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m59s\u001b[0m 257ms/step - accuracy: 0.9686 - f1_score: 0.9697 - loss: 0.0925 - precision: 0.9748 - recall: 0.9647 - val_accuracy: 0.9726 - val_f1_score: 0.9726 - val_loss: 0.0805 - val_precision: 0.9766 - val_recall: 0.9685\n",
      "Epoch 67/100\n",
      "\u001b[1m230/230\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m59s\u001b[0m 256ms/step - accuracy: 0.9580 - f1_score: 0.9587 - loss: 0.1144 - precision: 0.9646 - recall: 0.9529 - val_accuracy: 0.9695 - val_f1_score: 0.9695 - val_loss: 0.0944 - val_precision: 0.9743 - val_recall: 0.9647\n",
      "Epoch 68/100\n",
      "\u001b[1m230/230\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m59s\u001b[0m 255ms/step - accuracy: 0.9651 - f1_score: 0.9639 - loss: 0.1005 - precision: 0.9696 - recall: 0.9583 - val_accuracy: 0.9701 - val_f1_score: 0.9706 - val_loss: 0.0880 - val_precision: 0.9741 - val_recall: 0.9671\n",
      "Epoch 69/100\n",
      "\u001b[1m230/230\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m59s\u001b[0m 257ms/step - accuracy: 0.9623 - f1_score: 0.9630 - loss: 0.1022 - precision: 0.9675 - recall: 0.9585 - val_accuracy: 0.9686 - val_f1_score: 0.9690 - val_loss: 0.0913 - val_precision: 0.9738 - val_recall: 0.9641\n",
      "Epoch 70/100\n",
      "\u001b[1m230/230\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m59s\u001b[0m 256ms/step - accuracy: 0.9638 - f1_score: 0.9634 - loss: 0.1104 - precision: 0.9675 - recall: 0.9594 - val_accuracy: 0.9442 - val_f1_score: 0.9467 - val_loss: 0.1606 - val_precision: 0.9549 - val_recall: 0.9385\n",
      "Epoch 71/100\n",
      "\u001b[1m230/230\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 258ms/step - accuracy: 0.9588 - f1_score: 0.9606 - loss: 0.1159 - precision: 0.9669 - recall: 0.9544 - val_accuracy: 0.9823 - val_f1_score: 0.9824 - val_loss: 0.0566 - val_precision: 0.9860 - val_recall: 0.9789\n",
      "Epoch 72/100\n",
      "\u001b[1m230/230\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m59s\u001b[0m 255ms/step - accuracy: 0.9702 - f1_score: 0.9701 - loss: 0.0864 - precision: 0.9740 - recall: 0.9662 - val_accuracy: 0.9785 - val_f1_score: 0.9792 - val_loss: 0.0609 - val_precision: 0.9814 - val_recall: 0.9770\n",
      "Epoch 73/100\n",
      "\u001b[1m230/230\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m59s\u001b[0m 256ms/step - accuracy: 0.9691 - f1_score: 0.9697 - loss: 0.0892 - precision: 0.9737 - recall: 0.9657 - val_accuracy: 0.9691 - val_f1_score: 0.9687 - val_loss: 0.0910 - val_precision: 0.9738 - val_recall: 0.9636\n",
      "Epoch 74/100\n",
      "\u001b[1m230/230\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m59s\u001b[0m 255ms/step - accuracy: 0.9645 - f1_score: 0.9644 - loss: 0.0990 - precision: 0.9699 - recall: 0.9589 - val_accuracy: 0.9816 - val_f1_score: 0.9823 - val_loss: 0.0548 - val_precision: 0.9851 - val_recall: 0.9796\n",
      "Epoch 75/100\n",
      "\u001b[1m230/230\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m58s\u001b[0m 254ms/step - accuracy: 0.9737 - f1_score: 0.9734 - loss: 0.0808 - precision: 0.9775 - recall: 0.9694 - val_accuracy: 0.9873 - val_f1_score: 0.9876 - val_loss: 0.0401 - val_precision: 0.9887 - val_recall: 0.9865\n",
      "Epoch 76/100\n",
      "\u001b[1m230/230\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m58s\u001b[0m 253ms/step - accuracy: 0.9709 - f1_score: 0.9712 - loss: 0.0806 - precision: 0.9755 - recall: 0.9670 - val_accuracy: 0.9704 - val_f1_score: 0.9714 - val_loss: 0.0769 - val_precision: 0.9742 - val_recall: 0.9685\n",
      "Epoch 77/100\n",
      "\u001b[1m230/230\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m58s\u001b[0m 251ms/step - accuracy: 0.9712 - f1_score: 0.9704 - loss: 0.0846 - precision: 0.9740 - recall: 0.9669 - val_accuracy: 0.9652 - val_f1_score: 0.9653 - val_loss: 0.1020 - val_precision: 0.9697 - val_recall: 0.9609\n",
      "Epoch 78/100\n",
      "\u001b[1m230/230\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m59s\u001b[0m 255ms/step - accuracy: 0.9621 - f1_score: 0.9637 - loss: 0.1063 - precision: 0.9690 - recall: 0.9584 - val_accuracy: 0.9887 - val_f1_score: 0.9885 - val_loss: 0.0380 - val_precision: 0.9907 - val_recall: 0.9864\n",
      "Epoch 79/100\n",
      "\u001b[1m230/230\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m58s\u001b[0m 250ms/step - accuracy: 0.9721 - f1_score: 0.9722 - loss: 0.0774 - precision: 0.9760 - recall: 0.9683 - val_accuracy: 0.9771 - val_f1_score: 0.9773 - val_loss: 0.0682 - val_precision: 0.9806 - val_recall: 0.9740\n",
      "Epoch 80/100\n",
      "\u001b[1m230/230\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m58s\u001b[0m 254ms/step - accuracy: 0.9665 - f1_score: 0.9666 - loss: 0.0962 - precision: 0.9710 - recall: 0.9623 - val_accuracy: 0.9757 - val_f1_score: 0.9766 - val_loss: 0.0680 - val_precision: 0.9798 - val_recall: 0.9734\n",
      "Epoch 81/100\n",
      "\u001b[1m230/230\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m58s\u001b[0m 251ms/step - accuracy: 0.9669 - f1_score: 0.9671 - loss: 0.0925 - precision: 0.9702 - recall: 0.9640 - val_accuracy: 0.9836 - val_f1_score: 0.9832 - val_loss: 0.0469 - val_precision: 0.9859 - val_recall: 0.9805\n",
      "Epoch 82/100\n",
      "\u001b[1m230/230\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m59s\u001b[0m 256ms/step - accuracy: 0.9680 - f1_score: 0.9683 - loss: 0.0947 - precision: 0.9714 - recall: 0.9651 - val_accuracy: 0.9756 - val_f1_score: 0.9753 - val_loss: 0.0760 - val_precision: 0.9777 - val_recall: 0.9730\n",
      "Epoch 83/100\n",
      "\u001b[1m230/230\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m59s\u001b[0m 256ms/step - accuracy: 0.9740 - f1_score: 0.9732 - loss: 0.0816 - precision: 0.9762 - recall: 0.9703 - val_accuracy: 0.9745 - val_f1_score: 0.9739 - val_loss: 0.0734 - val_precision: 0.9780 - val_recall: 0.9697\n",
      "Epoch 84/100\n",
      "\u001b[1m230/230\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m58s\u001b[0m 254ms/step - accuracy: 0.9664 - f1_score: 0.9667 - loss: 0.0977 - precision: 0.9704 - recall: 0.9630 - val_accuracy: 0.9809 - val_f1_score: 0.9815 - val_loss: 0.0551 - val_precision: 0.9856 - val_recall: 0.9774\n",
      "Epoch 85/100\n",
      "\u001b[1m230/230\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m59s\u001b[0m 254ms/step - accuracy: 0.9704 - f1_score: 0.9697 - loss: 0.0803 - precision: 0.9730 - recall: 0.9664 - val_accuracy: 0.9786 - val_f1_score: 0.9782 - val_loss: 0.0642 - val_precision: 0.9823 - val_recall: 0.9742\n",
      "Epoch 86/100\n",
      "\u001b[1m230/230\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m59s\u001b[0m 255ms/step - accuracy: 0.9742 - f1_score: 0.9733 - loss: 0.0694 - precision: 0.9763 - recall: 0.9704 - val_accuracy: 0.9820 - val_f1_score: 0.9818 - val_loss: 0.0487 - val_precision: 0.9852 - val_recall: 0.9785\n",
      "Epoch 87/100\n",
      "\u001b[1m230/230\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m58s\u001b[0m 251ms/step - accuracy: 0.9808 - f1_score: 0.9812 - loss: 0.0562 - precision: 0.9830 - recall: 0.9793 - val_accuracy: 0.9877 - val_f1_score: 0.9883 - val_loss: 0.0386 - val_precision: 0.9900 - val_recall: 0.9865\n",
      "Epoch 88/100\n",
      "\u001b[1m230/230\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m58s\u001b[0m 251ms/step - accuracy: 0.9747 - f1_score: 0.9749 - loss: 0.0720 - precision: 0.9772 - recall: 0.9727 - val_accuracy: 0.9635 - val_f1_score: 0.9642 - val_loss: 0.1023 - val_precision: 0.9676 - val_recall: 0.9607\n",
      "Epoch 89/100\n",
      "\u001b[1m230/230\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m58s\u001b[0m 251ms/step - accuracy: 0.9686 - f1_score: 0.9693 - loss: 0.0872 - precision: 0.9724 - recall: 0.9663 - val_accuracy: 0.9816 - val_f1_score: 0.9815 - val_loss: 0.0579 - val_precision: 0.9845 - val_recall: 0.9785\n",
      "Epoch 90/100\n",
      "\u001b[1m230/230\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m58s\u001b[0m 252ms/step - accuracy: 0.9727 - f1_score: 0.9728 - loss: 0.0784 - precision: 0.9755 - recall: 0.9702 - val_accuracy: 0.9831 - val_f1_score: 0.9829 - val_loss: 0.0511 - val_precision: 0.9852 - val_recall: 0.9805\n",
      "Epoch 91/100\n",
      "\u001b[1m230/230\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m59s\u001b[0m 257ms/step - accuracy: 0.9767 - f1_score: 0.9766 - loss: 0.0663 - precision: 0.9789 - recall: 0.9742 - val_accuracy: 0.9779 - val_f1_score: 0.9781 - val_loss: 0.0631 - val_precision: 0.9807 - val_recall: 0.9755\n",
      "Epoch 92/100\n",
      "\u001b[1m230/230\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m59s\u001b[0m 256ms/step - accuracy: 0.9735 - f1_score: 0.9743 - loss: 0.0709 - precision: 0.9775 - recall: 0.9712 - val_accuracy: 0.9787 - val_f1_score: 0.9794 - val_loss: 0.0613 - val_precision: 0.9818 - val_recall: 0.9770\n",
      "Epoch 93/100\n",
      "\u001b[1m230/230\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m59s\u001b[0m 255ms/step - accuracy: 0.9808 - f1_score: 0.9811 - loss: 0.0513 - precision: 0.9837 - recall: 0.9785 - val_accuracy: 0.9812 - val_f1_score: 0.9811 - val_loss: 0.0531 - val_precision: 0.9837 - val_recall: 0.9785\n",
      "Epoch 94/100\n",
      "\u001b[1m230/230\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m59s\u001b[0m 257ms/step - accuracy: 0.9640 - f1_score: 0.9642 - loss: 0.1015 - precision: 0.9675 - recall: 0.9609 - val_accuracy: 0.9839 - val_f1_score: 0.9842 - val_loss: 0.0459 - val_precision: 0.9876 - val_recall: 0.9808\n",
      "Epoch 95/100\n",
      "\u001b[1m230/230\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m59s\u001b[0m 256ms/step - accuracy: 0.9774 - f1_score: 0.9777 - loss: 0.0643 - precision: 0.9804 - recall: 0.9749 - val_accuracy: 0.9678 - val_f1_score: 0.9686 - val_loss: 0.0897 - val_precision: 0.9715 - val_recall: 0.9658\n",
      "Epoch 96/100\n",
      "\u001b[1m230/230\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m59s\u001b[0m 259ms/step - accuracy: 0.9670 - f1_score: 0.9672 - loss: 0.0977 - precision: 0.9711 - recall: 0.9633 - val_accuracy: 0.9796 - val_f1_score: 0.9795 - val_loss: 0.0599 - val_precision: 0.9836 - val_recall: 0.9753\n",
      "Epoch 97/100\n",
      "\u001b[1m230/230\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m60s\u001b[0m 259ms/step - accuracy: 0.9777 - f1_score: 0.9769 - loss: 0.0647 - precision: 0.9821 - recall: 0.9718 - val_accuracy: 0.9888 - val_f1_score: 0.9894 - val_loss: 0.0341 - val_precision: 0.9916 - val_recall: 0.9872\n",
      "Epoch 98/100\n",
      "\u001b[1m230/230\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m59s\u001b[0m 256ms/step - accuracy: 0.9834 - f1_score: 0.9838 - loss: 0.0528 - precision: 0.9868 - recall: 0.9807 - val_accuracy: 0.9700 - val_f1_score: 0.9697 - val_loss: 0.1014 - val_precision: 0.9739 - val_recall: 0.9656\n",
      "Epoch 99/100\n",
      "\u001b[1m230/230\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m59s\u001b[0m 255ms/step - accuracy: 0.9760 - f1_score: 0.9761 - loss: 0.0718 - precision: 0.9784 - recall: 0.9739 - val_accuracy: 0.9865 - val_f1_score: 0.9863 - val_loss: 0.0415 - val_precision: 0.9881 - val_recall: 0.9846\n",
      "Epoch 100/100\n",
      "\u001b[1m230/230\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m59s\u001b[0m 255ms/step - accuracy: 0.9748 - f1_score: 0.9758 - loss: 0.0675 - precision: 0.9798 - recall: 0.9719 - val_accuracy: 0.9887 - val_f1_score: 0.9884 - val_loss: 0.0329 - val_precision: 0.9906 - val_recall: 0.9862\n"
     ]
    }
   ],
   "source": [
    "# Train the model\n",
    "history = cnn_lstm.fit(\n",
    "    x=training_set,\n",
    "    validation_data=validation_set,\n",
    "    epochs=100\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "3c03fa68-1a74-49d5-86af-70ae4d69d09d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save Loss plot\n",
    "plt.figure()\n",
    "plt.plot(history.history['loss'], label='Train Loss')\n",
    "plt.plot(history.history['val_loss'], label='Validation Loss')\n",
    "plt.legend()\n",
    "plt.title(\"Loss\")\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.savefig('loss_plot.png')  # Save the plot as a PNG file\n",
    "plt.close()  # Close the figure to avoid memory issues\n",
    "\n",
    "# Save Accuracy plot\n",
    "plt.figure()\n",
    "plt.plot(history.history['accuracy'], label='Train Accuracy')\n",
    "plt.plot(history.history['val_accuracy'], label='Validation Accuracy')\n",
    "plt.legend()\n",
    "plt.title(\"Accuracy\")\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.savefig('accuracy_plot.png')  # Save the plot as a PNG file\n",
    "plt.close()  # Close the figure\n",
    "\n",
    "# Save Precision plot\n",
    "plt.figure()\n",
    "plt.plot(history.history['precision'], label='Train Precision')\n",
    "plt.plot(history.history['val_precision'], label='Validation Precision')\n",
    "plt.legend()\n",
    "plt.title(\"Precision\")\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Precision')\n",
    "plt.savefig('precision_plot.png')  # Save the plot as a PNG file\n",
    "plt.close()  # Close the figure\n",
    "\n",
    "# Save Recall plot\n",
    "plt.figure()\n",
    "plt.plot(history.history['recall'], label='Train Recall')\n",
    "plt.plot(history.history['val_recall'], label='Validation Recall')\n",
    "plt.legend()\n",
    "plt.title(\"Recall\")\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Recall')\n",
    "plt.savefig('recall_plot.png')  # Save the plot as a PNG file\n",
    "plt.close()  # Close the figure\n",
    "\n",
    "# Save F1 Score plot\n",
    "plt.figure()\n",
    "plt.plot(history.history['f1_score'], label='Train F1 Score')\n",
    "plt.plot(history.history['val_f1_score'], label='Validation F1 Score')\n",
    "plt.legend()\n",
    "plt.title(\"F1 Score\")\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('F1 Score')\n",
    "plt.savefig('f1_score_plot.png')  # Save the plot as a PNG file\n",
    "plt.close()  # Close the figure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f7afcf3c-6194-4473-a22c-8da9a3b422d1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                         </span>┃<span style=\"font-weight: bold\"> Output Shape                </span>┃<span style=\"font-weight: bold\">         Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
       "│ conv2d (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)          │             <span style=\"color: #00af00; text-decoration-color: #00af00\">896</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ max_pooling2d (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)          │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ conv2d_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)          │          <span style=\"color: #00af00; text-decoration-color: #00af00\">18,496</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ max_pooling2d_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)            │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ flatten (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)                    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4096</span>)                │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ reshape (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Reshape</span>)                    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)             │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ lstm (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)                  │          <span style=\"color: #00af00; text-decoration-color: #00af00\">82,176</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)                 │           <span style=\"color: #00af00; text-decoration-color: #00af00\">8,320</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">6</span>)                   │             <span style=\"color: #00af00; text-decoration-color: #00af00\">774</span> │\n",
       "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
       "│ conv2d (\u001b[38;5;33mConv2D\u001b[0m)                      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m)          │             \u001b[38;5;34m896\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ max_pooling2d (\u001b[38;5;33mMaxPooling2D\u001b[0m)         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m32\u001b[0m)          │               \u001b[38;5;34m0\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ conv2d_1 (\u001b[38;5;33mConv2D\u001b[0m)                    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m64\u001b[0m)          │          \u001b[38;5;34m18,496\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ max_pooling2d_1 (\u001b[38;5;33mMaxPooling2D\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m64\u001b[0m)            │               \u001b[38;5;34m0\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ flatten (\u001b[38;5;33mFlatten\u001b[0m)                    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4096\u001b[0m)                │               \u001b[38;5;34m0\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ reshape (\u001b[38;5;33mReshape\u001b[0m)                    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m256\u001b[0m)             │               \u001b[38;5;34m0\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ lstm (\u001b[38;5;33mLSTM\u001b[0m)                          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)                  │          \u001b[38;5;34m82,176\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense (\u001b[38;5;33mDense\u001b[0m)                        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)                 │           \u001b[38;5;34m8,320\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)                      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m6\u001b[0m)                   │             \u001b[38;5;34m774\u001b[0m │\n",
       "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">331,988</span> (1.27 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m331,988\u001b[0m (1.27 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">110,662</span> (432.27 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m110,662\u001b[0m (432.27 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Optimizer params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">221,326</span> (864.56 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Optimizer params: \u001b[0m\u001b[38;5;34m221,326\u001b[0m (864.56 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "cnn_lstm.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4be27f07-b55a-42f1-91cf-e278556d05b0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
